{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 1. Install audio tools (Quietly)\n!apt-get install -y -qq ffmpeg\n\n# 2. Install Python libraries (Quietly)\n!pip install -qq google-adk google-generativeai Pillow requests beautifulsoup4 PyPDF2 python-docx nbformat SpeechRecognition pydub librosa soundfile","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T13:17:26.500657Z","iopub.execute_input":"2025-11-24T13:17:26.501281Z","iopub.status.idle":"2025-11-24T13:17:39.987891Z","shell.execute_reply.started":"2025-11-24T13:17:26.501253Z","shell.execute_reply":"2025-11-24T13:17:39.986833Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m319.9/319.9 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.5 which is incompatible.\nray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# ============================================================================\n# CELL 2: IMPORTS & SETUP\n# ============================================================================\n\nimport os\nimport asyncio\nimport json\nimport logging\nimport time\nimport re\nimport traceback \nimport base64\nimport io\nfrom collections import deque, defaultdict\nfrom dataclasses import dataclass, field\nfrom typing import List, Dict, Any, Optional\nfrom datetime import datetime\n\n# Image processing\nfrom PIL import Image\n\n# Audio processing\nimport speech_recognition as sr\n\n# Document processing\nimport requests\nfrom bs4 import BeautifulSoup\nimport PyPDF2\n\n# Google AI\nimport google.generativeai as genai\n\n# ADK imports\nfrom google.adk.agents import Agent\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.sessions import InMemorySessionService\nfrom google.adk.tools import FunctionTool\n\nprint(\"âœ… All imports loaded\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T13:17:39.989721Z","iopub.execute_input":"2025-11-24T13:17:39.990056Z","iopub.status.idle":"2025-11-24T13:18:23.754081Z","shell.execute_reply.started":"2025-11-24T13:17:39.990027Z","shell.execute_reply":"2025-11-24T13:18:23.753273Z"}},"outputs":[{"name":"stdout","text":"âœ… All imports loaded\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"FALSE\"\n    \n    genai.configure(api_key=GOOGLE_API_KEY)\n    \n    print(\"âœ… Gemini API key setup complete.\")\nexcept Exception as e:\n    print(f\"ğŸ”‘ Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T13:18:23.754891Z","iopub.execute_input":"2025-11-24T13:18:23.755599Z","iopub.status.idle":"2025-11-24T13:18:24.003987Z","shell.execute_reply.started":"2025-11-24T13:18:23.755568Z","shell.execute_reply":"2025-11-24T13:18:24.003078Z"}},"outputs":[{"name":"stdout","text":"âœ… Gemini API key setup complete.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n    handlers=[logging.StreamHandler()]\n)\nlogger = logging.getLogger(\"Mindmate\")\n\n# ============================================================================\n# FILE VALIDATION UTILITY (NEW - ADD THIS)\n# ============================================================================\n\ndef safe_file_read(file_path: str, expected_extensions: list = None) -> Dict:\n    \"\"\"\n    Safely validate and read file with comprehensive error handling.\n    \n    Returns: {\"status\": \"success/error\", \"path\": str, \"error\": str}\n    \"\"\"\n    try:\n        # Check if path exists\n        if not file_path or not os.path.exists(file_path):\n            return {\n                \"status\": \"error\",\n                \"error\": f\"File not found: {file_path}\",\n                \"path\": None\n            }\n        \n        # Check if it's a file\n        if not os.path.isfile(file_path):\n            return {\n                \"status\": \"error\", \n                \"error\": f\"Path is not a file: {file_path}\",\n                \"path\": None\n            }\n        \n        # Check extension if specified\n        if expected_extensions:\n            ext = os.path.splitext(file_path)[1].lower()\n            if ext not in expected_extensions:\n                return {\n                    \"status\": \"error\",\n                    \"error\": f\"Invalid file type {ext}. Expected: {expected_extensions}\",\n                    \"path\": None\n                }\n        \n        # Check file size (limit to 50MB)\n        size = os.path.getsize(file_path)\n        if size > 50 * 1024 * 1024:\n            return {\n                \"status\": \"error\",\n                \"error\": f\"File too large: {size / (1024*1024):.1f}MB (max 50MB)\",\n                \"path\": None\n            }\n        \n        if size == 0:\n            return {\n                \"status\": \"error\",\n                \"error\": \"File is empty\",\n                \"path\": None\n            }\n        \n        return {\"status\": \"success\", \"path\": file_path, \"error\": None}\n        \n    except Exception as e:\n        return {\n            \"status\": \"error\",\n            \"error\": f\"File validation error: {str(e)}\",\n            \"path\": None\n        }\n\nprint(\"âœ… File validation utility ready\")\n\n# Metrics\nmetrics = defaultdict(int)\nlatencies = defaultdict(list)\n\ndef metric_inc(name: str, amt: int = 1):\n    metrics[name] += amt\n\ndef metric_time(name: str, duration: float):\n    latencies[name].append(duration)\n\nprint(\"âœ… Setup complete\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T13:18:24.005897Z","iopub.execute_input":"2025-11-24T13:18:24.006196Z","iopub.status.idle":"2025-11-24T13:18:24.017796Z","shell.execute_reply.started":"2025-11-24T13:18:24.006173Z","shell.execute_reply":"2025-11-24T13:18:24.016939Z"}},"outputs":[{"name":"stdout","text":"âœ… File validation utility ready\nâœ… Setup complete\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# ============================================================================\n# CELL 3: USER DATA STRUCTURES\n# ============================================================================\n\n@dataclass\nclass UserJourney:\n    \"\"\"Tracks user's complete journey through MindMate.\"\"\"\n    user_id: str\n    name: str\n    created_at: float = field(default_factory=time.time)\n    emotion_history: List[Dict] = field(default_factory=list)\n    stress_history: List[int] = field(default_factory=list)\n    streaks: Dict[str, int] = field(default_factory=lambda: {\n        \"nutrition\": 0, \"tasks\": 0, \"games\": 0, \n        \"meditation\": 0, \"communication\": 0\n    })\n    badges: List[str] = field(default_factory=list)\n    total_points: int = 0\n    last_interaction: float = 0.0\n    game_scores: Dict = field(default_factory=dict)\n    communication_history: List[Dict] = field(default_factory=list)\n    meal_preferences: Dict = field(default_factory=dict)\n\n@dataclass  \nclass ConversationContext:\n    \"\"\"Tracks conversation context for MCP.\"\"\"\n    user_id: str\n    session_id: str\n    history: List[Dict] = field(default_factory=list)\n    emotional_state: Dict = field(default_factory=dict)\n    recent_topics: List[str] = field(default_factory=list)\n    last_agent: str = \"\"\n\n# Global stores\nuser_journeys: Dict[str, UserJourney] = {}\nconversation_contexts: Dict[str, ConversationContext] = {}\n\ndef get_user(user_id: str, name: str = \"Friend\") -> UserJourney:\n    \"\"\"Get or create user journey.\"\"\"\n    if user_id not in user_journeys:\n        user_journeys[user_id] = UserJourney(user_id=user_id, name=name)\n        metric_inc(\"new_users\")\n        logger.info(f\"New user created: {user_id}\")\n    return user_journeys[user_id]\n\ndef get_context(user_id: str, session_id: str = \"default\") -> ConversationContext:\n    \"\"\"Get or create conversation context.\"\"\"\n    key = f\"{user_id}_{session_id}\"\n    if key not in conversation_contexts:\n        conversation_contexts[key] = ConversationContext(user_id=user_id, session_id=session_id)\n    return conversation_contexts[key]\n\ndef get_greeting(user_id: str) -> str:\n    \"\"\"Generate personalized greeting.\"\"\"\n    user = get_user(user_id)\n    hour = datetime.now().hour\n    \n    if hour < 12:\n        time_greet = \"Good morning\"\n    elif hour < 17:\n        time_greet = \"Good afternoon\"\n    else:\n        time_greet = \"Good evening\"\n    \n    # Check if returning user\n    if user.last_interaction > 0:\n        time_since = time.time() - user.last_interaction\n        if time_since > 86400:  # More than a day\n            greeting = f\"{time_greet}, {user.name}! Welcome back ğŸ’™\"\n        else:\n            greeting = f\"{time_greet}, {user.name}!\"\n    else:\n        greeting = f\"{time_greet}, {user.name}! I'm MindMate, your wellness companion ğŸ’™\"\n    \n    user.last_interaction = time.time()\n    return greeting\n\nprint(\"âœ… User data structures ready\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T13:18:24.018779Z","iopub.execute_input":"2025-11-24T13:18:24.019143Z","iopub.status.idle":"2025-11-24T13:18:24.048373Z","shell.execute_reply.started":"2025-11-24T13:18:24.019114Z","shell.execute_reply":"2025-11-24T13:18:24.047537Z"}},"outputs":[{"name":"stdout","text":"âœ… User data structures ready\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"\n# ============================================================================\n# CELL 4: AGENT 1 - MOOD AGENT\n# ============================================================================\n\ndef analyze_mood(user_id: str, message: str, stress_level: int = 5) -> Dict:\n    \"\"\"\n    Analyze user's emotional state and provide personalized support.\n    \n    Parameters:\n    - user_id: User identifier\n    - message: User's message expressing how they feel\n    - stress_level: Self-reported stress (1-10)\n    \n    Returns: Mood analysis with coping strategies\n    \"\"\"\n    start = time.time()\n    user = get_user(user_id)\n    lower = message.lower()\n    \n    # Emotion detection\n    emotion_map = {\n        \"distressed\": (2, [\"depressed\", \"hopeless\", \"terrible\", \"suicidal\", \"can't go on\"]),\n        \"anxious\": (3, [\"anxious\", \"stressed\", \"worried\", \"overwhelmed\", \"panic\"]),\n        \"sad\": (4, [\"sad\", \"down\", \"lonely\", \"upset\", \"disappointed\"]),\n        \"neutral\": (5, [\"okay\", \"meh\", \"alright\", \"so-so\"]),\n        \"stable\": (6, [\"fine\", \"decent\", \"not bad\"]),\n        \"positive\": (7, [\"good\", \"better\", \"nice\", \"pleased\"]),\n        \"very_positive\": (8, [\"great\", \"happy\", \"amazing\", \"wonderful\", \"fantastic\"]),\n        \"excellent\": (9, [\"excellent\", \"thrilled\", \"ecstatic\", \"best\"])\n    }\n    \n    score = 5\n    emotion = \"neutral\"\n    \n    for emo, (emo_score, keywords) in emotion_map.items():\n        if any(w in lower for w in keywords):\n            score = emo_score\n            emotion = emo\n            break\n    \n    # Adjust for stress level\n    score = max(1, min(10, score - (stress_level - 5) // 2))\n    \n    # Update user history\n    user.emotion_history.append({\n        \"timestamp\": time.time(),\n        \"emotion\": emotion,\n        \"score\": score,\n        \"stress\": stress_level\n    })\n    user.stress_history.append(stress_level)\n    \n    # Keep last 20 entries\n    if len(user.emotion_history) > 20:\n        user.emotion_history = user.emotion_history[-20:]\n    if len(user.stress_history) > 20:\n        user.stress_history = user.stress_history[-20:]\n    \n    # Generate coping strategy based on score\n    if score <= 2:\n        coping = f\"ğŸ’™ {user.name}, I hear you're going through a really tough time. Please remember you're not alone. Consider reaching out to a mental health professional or crisis line. Would you like some grounding exercises?\"\n        assessment = \"needs_immediate_support\"\n    elif score <= 4:\n        coping = f\"ğŸ’™ {user.name}, try this: 4-7-8 breathing - inhale 4 seconds, hold 7, exhale 8. Repeat 4 times. Would you like a stress relief game?\"\n        assessment = \"needs_support\"\n    elif score <= 6:\n        coping = f\"{user.name}, you're managing okay. A short walk or talking to someone you trust might help lift your mood.\"\n        assessment = \"stable\"\n    else:\n        coping = f\"Wonderful, {user.name}! Keep doing what's working for you. Gratitude journaling can help maintain this positive state.\"\n        assessment = \"thriving\"\n    \n    # Calculate trend\n    if len(user.emotion_history) >= 3:\n        recent_scores = [e[\"score\"] for e in user.emotion_history[-3:]]\n        if recent_scores[-1] > recent_scores[0]:\n            trend = \"improving ğŸ“ˆ\"\n        elif recent_scores[-1] < recent_scores[0]:\n            trend = \"declining ğŸ“‰\"\n        else:\n            trend = \"stable â¡ï¸\"\n    else:\n        trend = \"not enough data\"\n    \n    # Award points\n    user.total_points += 5\n    metric_inc(\"mood_analyses\")\n    metric_time(\"mood_agent\", time.time() - start)\n    \n    return {\n        \"mood_score\": score,\n        \"emotion\": emotion,\n        \"stress_level\": stress_level,\n        \"assessment\": assessment,\n        \"coping_strategy\": coping,\n        \"trend\": trend,\n        \"points_earned\": 5,\n        \"total_points\": user.total_points,\n        \"greeting\": get_greeting(user_id)\n    }\n\nprint(\"âœ… Agent 1: Mood Agent ready\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T13:18:24.049294Z","iopub.execute_input":"2025-11-24T13:18:24.049559Z","iopub.status.idle":"2025-11-24T13:18:24.075178Z","shell.execute_reply.started":"2025-11-24T13:18:24.049538Z","shell.execute_reply":"2025-11-24T13:18:24.074274Z"}},"outputs":[{"name":"stdout","text":"âœ… Agent 1: Mood Agent ready\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"\n# ============================================================================\n# CELL 5: AGENT 2 - STRESS BUSTER (GAMES)\n# ============================================================================\n\ndef play_stress_game(user_id: str, game_type: str = \"random\") -> Dict:\n    \"\"\"\n    Provide fun mental break games for stress relief.\n    \n    Parameters:\n    - user_id: User identifier\n    - game_type: \"riddle\", \"trivia\", \"brain_teaser\", \"pattern\", \"detective\", \"random\"\n    \n    Returns: Game content with question and answer\n    \"\"\"\n    import random\n    start = time.time()\n    user = get_user(user_id)\n    \n    games = {\n        \"riddle\": [\n            {\"q\": f\"ğŸ¤” {user.name}, I speak without a mouth and hear without ears. I have no body, but I come alive with the wind. What am I?\", \"a\": \"An ECHO! ğŸ”Š\"},\n            {\"q\": f\"ğŸ¤” {user.name}, what has keys but no locks, space but no room, and you can enter but can't go inside?\", \"a\": \"A KEYBOARD! âŒ¨ï¸\"},\n            {\"q\": \"ğŸ¤” The more you take, the more you leave behind. What am I?\", \"a\": \"FOOTSTEPS! ğŸ‘£\"},\n            {\"q\": \"ğŸ¤” I have cities, but no houses live there. I have mountains, but no trees grow. I have water, but no fish swim. What am I?\", \"a\": \"A MAP! ğŸ—ºï¸\"},\n            {\"q\": \"ğŸ¤” What can travel around the world while staying in a corner?\", \"a\": \"A STAMP! ğŸ“®\"},\n        ],\n        \"trivia\": [\n            {\"q\": \"ğŸ¬ In Stranger Things, what tabletop game do the kids play?\", \"opts\": [\"A) Monopoly\", \"B) Dungeons & Dragons\", \"C) Risk\", \"D) Chess\"], \"a\": \"B) Dungeons & Dragons âœ…\", \"fact\": \"The Duffer Brothers are huge D&D fans!\"},\n            {\"q\": \"ğŸ¬ What is the highest-grossing film of all time (adjusted)?\", \"opts\": [\"A) Titanic\", \"B) Avatar\", \"C) Avengers: Endgame\", \"D) Gone with the Wind\"], \"a\": \"D) Gone with the Wind âœ…\", \"fact\": \"When adjusted for inflation, it beats all modern films!\"},\n            {\"q\": \"ğŸµ Which artist has the most Grammy Awards?\", \"opts\": [\"A) BeyoncÃ©\", \"B) Taylor Swift\", \"C) Adele\", \"D) Stevie Wonder\"], \"a\": \"A) BeyoncÃ© âœ…\", \"fact\": \"She has 32 Grammy Awards!\"},\n            {\"q\": \"ğŸŒ What is the smallest country in the world?\", \"opts\": [\"A) Monaco\", \"B) Vatican City\", \"C) San Marino\", \"D) Liechtenstein\"], \"a\": \"B) Vatican City âœ…\", \"fact\": \"It's only 0.44 square kilometers!\"},\n        ],\n        \"brain_teaser\": [\n            {\"q\": f\"ğŸ§  {user.name}, a bus driver goes the wrong way down a one-way street, passes 10 police officers, but doesn't get a ticket. Why?\", \"a\": \"He was WALKING! ğŸš¶\"},\n            {\"q\": \"ğŸ§  What can you hold in your right hand but never in your left hand?\", \"a\": \"Your LEFT HAND! ğŸ¤š\"},\n            {\"q\": \"ğŸ§  A man lives on the 10th floor. Every day he takes the elevator down to go to work. When he returns, he takes the elevator to the 7th floor and walks up 3 flights. Why?\", \"a\": \"He's too SHORT to reach the 10th floor button! ğŸ“\"},\n            {\"q\": \"ğŸ§  If you have me, you want to share me. If you share me, you no longer have me. What am I?\", \"a\": \"A SECRET! ğŸ¤«\"},\n        ],\n        \"pattern\": [\n            {\"q\": \"ğŸ”¢ What comes next? 2, 4, 8, 16, ?\", \"a\": \"32 (each number doubles)\"},\n            {\"q\": \"ğŸ”¢ What comes next? 1, 1, 2, 3, 5, 8, ?\", \"a\": \"13 (Fibonacci sequence - add previous two)\"},\n            {\"q\": \"ğŸ”¢ What comes next? 1, 4, 9, 16, 25, ?\", \"a\": \"36 (square numbers: 1Â², 2Â², 3Â²...)\"},\n            {\"q\": \"ğŸ”¢ What comes next? A, C, F, J, ?\", \"a\": \"O (gaps increase: +2, +3, +4, +5)\"},\n        ],\n        \"detective\": [\n            {\"q\": f\"ğŸ” {user.name}, a man is found dead in a locked room with only a puddle of water and broken glass. How did he die?\", \"hint\": \"Think about what was IN the glass...\", \"a\": \"ğŸ¯ He was a fish! The glass was his fishbowl that broke!\"},\n            {\"q\": \"ğŸ” A woman shoots her husband, then holds him underwater for 5 minutes, then hangs him. Later, they go out for dinner. How?\", \"hint\": \"Think photography...\", \"a\": \"ğŸ¯ She's a PHOTOGRAPHER! She shot a photo, developed it in water, and hung it to dry!\"},\n        ]\n    }\n    \n    # Select game type\n    if game_type == \"random\" or game_type not in games:\n        # Avoid repeating recent games\n        recent = user.game_scores.get(\"recent_types\", [])\n        available = [t for t in games.keys() if t not in recent[-2:]]\n        game_type = random.choice(available if available else list(games.keys()))\n    \n    # Select random game from category\n    selected = random.choice(games[game_type])\n    \n    # Build response\n    result = {\n        \"game_type\": game_type,\n        \"question\": selected[\"q\"],\n        \"answer\": selected[\"a\"],\n        \"hint\": selected.get(\"hint\"),\n        \"options\": selected.get(\"opts\", []),\n        \"fun_fact\": selected.get(\"fact\"),\n    }\n    \n    # Update user stats\n    user.streaks[\"games\"] = user.streaks.get(\"games\", 0) + 1\n    user.total_points += 10\n    \n    if \"recent_types\" not in user.game_scores:\n        user.game_scores[\"recent_types\"] = []\n    user.game_scores[\"recent_types\"].append(game_type)\n    \n    total_played = user.game_scores.get(\"total_played\", 0) + 1\n    user.game_scores[\"total_played\"] = total_played\n    \n    # Award badges\n    if total_played == 5 and \"ğŸ® Game Starter\" not in user.badges:\n        user.badges.append(\"ğŸ® Game Starter\")\n        result[\"new_badge\"] = \"ğŸ® Game Starter\"\n    elif total_played == 20 and \"ğŸ®ğŸ® Game Master\" not in user.badges:\n        user.badges.append(\"ğŸ®ğŸ® Game Master\")\n        result[\"new_badge\"] = \"ğŸ®ğŸ® Game Master\"\n    elif total_played == 50 and \"ğŸ®ğŸ®ğŸ® Game Legend\" not in user.badges:\n        user.badges.append(\"ğŸ®ğŸ®ğŸ® Game Legend\")\n        result[\"new_badge\"] = \"ğŸ®ğŸ®ğŸ® Game Legend\"\n    \n    result[\"stats\"] = {\n        \"streak\": user.streaks[\"games\"],\n        \"total_games\": total_played,\n        \"points_earned\": 10,\n        \"total_points\": user.total_points\n    }\n    result[\"message\"] = f\"ğŸ¯ Game #{total_played}! Take a brain break, {user.name}! ğŸ§ âœ¨\"\n    \n    metric_inc(\"games_played\")\n    metric_time(\"stress_buster\", time.time() - start)\n    \n    return result\n\nprint(\"âœ… Agent 2: Stress Buster ready\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T13:18:24.076193Z","iopub.execute_input":"2025-11-24T13:18:24.076474Z","iopub.status.idle":"2025-11-24T13:18:24.097887Z","shell.execute_reply.started":"2025-11-24T13:18:24.076445Z","shell.execute_reply":"2025-11-24T13:18:24.096955Z"}},"outputs":[{"name":"stdout","text":"âœ… Agent 2: Stress Buster ready\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# ============================================================================\n# CELL 6: AGENT 3 - INTERPERSONAL COACH (Text + FULL Audio Analysis)\n# ============================================================================\n\ndef analyze_audio_features(audio_path: str) -> Dict:\n    \"\"\"\n    Analyze vocal characteristics: tone, pace, volume, clarity, pitch.\n    Uses librosa for advanced audio analysis.\n    \"\"\"\n    try:\n        import librosa\n        import numpy as np\n        \n        # Load audio\n        y, sr_rate = librosa.load(audio_path, sr=None)\n        duration = librosa.get_duration(y=y, sr=sr_rate)\n        \n        if duration < 0.5:\n            return {\"status\": \"error\", \"message\": \"Audio too short (min 0.5 seconds)\"}\n        \n        # 1. VOLUME/ENERGY ANALYSIS\n        rms = librosa.feature.rms(y=y)[0]\n        avg_volume = float(np.mean(rms))\n        volume_variation = float(np.std(rms))\n        \n        if avg_volume > 0.15:\n            volume_level = \"loud\"\n            volume_note = \"Speaking loudly - may come across as aggressive\"\n        elif avg_volume < 0.03:\n            volume_level = \"soft\"\n            volume_note = \"Speaking softly - may seem unconfident or passive\"\n        else:\n            volume_level = \"moderate\"\n            volume_note = \"Good volume - clear and audible\"\n        \n        volume_consistency = \"varied\" if volume_variation > 0.05 else \"steady\"\n        \n        # 2. SPEAKING PACE ANALYSIS\n        onset_frames = librosa.onset.onset_detect(y=y, sr=sr_rate, backtrack=False)\n        num_onsets = len(onset_frames)\n        pace_per_sec = num_onsets / duration if duration > 0 else 0\n        \n        if pace_per_sec > 4:\n            pace_level = \"fast\"\n            pace_note = \"Speaking quickly - may indicate nervousness or excitement\"\n        elif pace_per_sec < 2:\n            pace_level = \"slow\"\n            pace_note = \"Speaking slowly - sounds thoughtful but may lose attention\"\n        else:\n            pace_level = \"moderate\"\n            pace_note = \"Good speaking pace - easy to follow\"\n        \n        # 3. PITCH ANALYSIS\n        pitches, magnitudes = librosa.piptrack(y=y, sr=sr_rate)\n        pitch_values = pitches[magnitudes > np.median(magnitudes)]\n        \n        if len(pitch_values) > 0:\n            avg_pitch = float(np.mean(pitch_values))\n            pitch_variation = float(np.std(pitch_values))\n            \n            if avg_pitch > 220:\n                pitch_level = \"high\"\n                pitch_note = \"Higher pitch - may indicate stress or excitement\"\n            elif avg_pitch < 100:\n                pitch_level = \"low\"\n                pitch_note = \"Lower pitch - sounds calm and authoritative\"\n            else:\n                pitch_level = \"medium\"\n                pitch_note = \"Natural pitch range\"\n            \n            if pitch_variation > 50:\n                pitch_variety = \"expressive\"\n                pitch_variety_note = \"Good vocal variety - engaging to listen to\"\n            else:\n                pitch_variety = \"monotone\"\n                pitch_variety_note = \"Monotone delivery - may sound disengaged\"\n        else:\n            avg_pitch = 0\n            pitch_level = \"unclear\"\n            pitch_note = \"Could not analyze pitch\"\n            pitch_variety = \"unclear\"\n            pitch_variety_note = \"\"\n        \n        # 4. CLARITY ANALYSIS (based on zero-crossing rate)\n        zcr = librosa.feature.zero_crossing_rate(y)[0]\n        avg_zcr = float(np.mean(zcr))\n        \n        if avg_zcr > 0.15:\n            clarity_level = \"clear\"\n            clarity_note = \"Clear enunciation - easy to understand\"\n        elif avg_zcr < 0.05:\n            clarity_level = \"unclear\"\n            clarity_note = \"Mumbled or unclear speech - work on articulation\"\n        else:\n            clarity_level = \"moderate\"\n            clarity_note = \"Acceptable clarity - could improve enunciation\"\n        \n        # 5. PAUSES ANALYSIS (silence detection)\n        intervals = librosa.effects.split(y, top_db=30)\n        num_segments = len(intervals)\n        pause_count = num_segments - 1\n        avg_pause = (duration - sum((intervals[:, 1] - intervals[:, 0]) / sr_rate)) / max(pause_count, 1)\n        \n        if avg_pause > 1.5:\n            pause_level = \"many_long\"\n            pause_note = \"Long pauses - may indicate uncertainty or search for words\"\n        elif avg_pause > 0.5:\n            pause_level = \"natural\"\n            pause_note = \"Natural pausing - allows listener to process\"\n        else:\n            pause_level = \"few\"\n            pause_note = \"Few pauses - may sound rushed or nervous\"\n        \n        # 6. OVERALL CONFIDENCE SCORE (0-10)\n        confidence_score = 5  # baseline\n        \n        # Volume contributes\n        if volume_level == \"moderate\": confidence_score += 2\n        elif volume_level == \"loud\": confidence_score += 1\n        elif volume_level == \"soft\": confidence_score -= 2\n        \n        # Pace contributes\n        if pace_level == \"moderate\": confidence_score += 2\n        elif pace_level == \"fast\": confidence_score -= 1\n        elif pace_level == \"slow\": confidence_score -= 1\n        \n        # Pitch variety contributes\n        if pitch_variety == \"expressive\": confidence_score += 2\n        elif pitch_variety == \"monotone\": confidence_score -= 2\n        \n        # Clarity contributes\n        if clarity_level == \"clear\": confidence_score += 2\n        elif clarity_level == \"unclear\": confidence_score -= 2\n        \n        # Pauses contribute\n        if pause_level == \"natural\": confidence_score += 1\n        elif pause_level == \"many_long\": confidence_score -= 2\n        \n        confidence_score = max(1, min(10, confidence_score))\n        \n        # 7. EMOTIONAL TONE DETECTION (basic)\n        if avg_volume > 0.15 and pace_per_sec > 4:\n            emotional_tone = \"agitated/stressed\"\n        elif avg_volume < 0.05 and pitch_level == \"low\":\n            emotional_tone = \"calm/sad\"\n        elif pitch_variety == \"expressive\" and volume_level == \"moderate\":\n            emotional_tone = \"engaged/enthusiastic\"\n        elif pitch_variety == \"monotone\" and pace_level == \"slow\":\n            emotional_tone = \"bored/disengaged\"\n        else:\n            emotional_tone = \"neutral/controlled\"\n        \n        return {\n            \"status\": \"success\",\n            \"duration_seconds\": round(duration, 2),\n            \"volume\": {\n                \"level\": volume_level,\n                \"consistency\": volume_consistency,\n                \"note\": volume_note,\n                \"score\": 8 if volume_level == \"moderate\" else 5 if volume_level == \"loud\" else 4\n            },\n            \"pace\": {\n                \"level\": pace_level,\n                \"syllables_per_sec\": round(pace_per_sec, 2),\n                \"note\": pace_note,\n                \"score\": 8 if pace_level == \"moderate\" else 6\n            },\n            \"pitch\": {\n                \"level\": pitch_level,\n                \"variety\": pitch_variety,\n                \"note\": pitch_note,\n                \"variety_note\": pitch_variety_note,\n                \"score\": 8 if pitch_variety == \"expressive\" else 4\n            },\n            \"clarity\": {\n                \"level\": clarity_level,\n                \"note\": clarity_note,\n                \"score\": 9 if clarity_level == \"clear\" else 6 if clarity_level == \"moderate\" else 3\n            },\n            \"pauses\": {\n                \"level\": pause_level,\n                \"average_seconds\": round(avg_pause, 2),\n                \"note\": pause_note,\n                \"score\": 8 if pause_level == \"natural\" else 5\n            },\n            \"confidence_score\": confidence_score,\n            \"emotional_tone\": emotional_tone,\n            \"overall_score\": round((\n                (8 if volume_level == \"moderate\" else 5) +\n                (8 if pace_level == \"moderate\" else 6) +\n                (8 if pitch_variety == \"expressive\" else 4) +\n                (9 if clarity_level == \"clear\" else 6) +\n                (8 if pause_level == \"natural\" else 5)\n            ) / 5, 1)\n        }\n        \n    except ImportError:\n        return {\n            \"status\": \"limited\",\n            \"message\": \"librosa not available - only basic transcription provided\"\n        }\n    except Exception as e:\n        logger.error(f\"Audio feature analysis error: {e}\\n{traceback.format_exc()}\")\n        return {\n            \"status\": \"error\",\n            \"message\": f\"Could not analyze audio features: {str(e)}\"\n        }\n\n\ndef analyze_interpersonal(\n    user_id: str,\n    text: str = None,\n    audio_path: str = None,\n    relationship: str = \"colleague\"\n) -> Dict:\n    \"\"\"\n    Comprehensive interpersonal skills coach with FULL audio analysis.\n    Analyzes text OR audio (with transcription + vocal tone analysis).\n    \n    Parameters:\n    - user_id: User identifier\n    - text: Text to analyze (what user said or wants to say)\n    - audio_path: Path to audio file for FULL analysis (transcription + tone/pace/clarity)\n    - relationship: \"boss\", \"colleague\", \"partner\", \"family\", \"friend\"\n    \n    Returns: Communication analysis with coaching\n    \"\"\"\n    start = time.time()\n    user = get_user(user_id)\n    \n    # Audio analysis\n    transcript = None\n    audio_features = None\n    \n    if audio_path:\n        try:\n            # ============================================================\n            # CHANGE 1: Add file validation\n            # ============================================================\n            valid_audio_extensions = ['.wav', '.mp3', '.m4a', '.mp4', '.ogg', '.flac']\n            file_ext = os.path.splitext(audio_path)[1].lower()\n            \n            if file_ext not in valid_audio_extensions:\n                return {\n                    \"status\": \"error\",\n                    \"message\": f\"Unsupported audio format: {file_ext}. Please upload: WAV, MP3, M4A, MP4, OGG, or FLAC\"\n                }\n            \n            # Check if file exists and is readable\n            if not os.path.exists(audio_path):\n                return {\n                    \"status\": \"error\",\n                    \"message\": f\"Audio file not found: {audio_path}\"\n                }\n            \n            if os.path.getsize(audio_path) == 0:\n                return {\n                    \"status\": \"error\",\n                    \"message\": \"Audio file is empty. Please upload a valid audio recording.\"\n                }\n            \n            # File size limit (50MB)\n            if os.path.getsize(audio_path) > 50 * 1024 * 1024:\n                size_mb = os.path.getsize(audio_path) / (1024 * 1024)\n                return {\n                    \"status\": \"error\",\n                    \"message\": f\"Audio file too large ({size_mb:.1f}MB). Maximum size is 50MB.\"\n                }\n            \n            recognizer = sr.Recognizer()\n            \n            # ============================================================\n            # CHANGE 2: Improved audio conversion with better error handling\n            # ============================================================\n            if not audio_path.endswith('.wav'):\n                try:\n                    from pydub import AudioSegment\n                    import tempfile\n                    \n                    logger.info(f\"Converting audio file: {audio_path} ({file_ext})\")\n                    \n                    # Load audio file\n                    audio = AudioSegment.from_file(audio_path)\n                    \n                    # Create temporary wav file\n                    with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp:\n                        wav_path = tmp.name\n                    \n                    # Export to WAV format\n                    audio.export(wav_path, format=\"wav\")\n                    audio_path = wav_path\n                    \n                    logger.info(f\"Audio converted successfully to: {wav_path}\")\n                    \n                except Exception as e:\n                    logger.error(f\"Audio conversion failed: {e}\\n{traceback.format_exc()}\")\n                    \n                    # Provide helpful error message\n                    if \"ffmpeg\" in str(e).lower() or \"avconv\" in str(e).lower():\n                        return {\n                            \"status\": \"error\", \n                            \"message\": f\"Could not convert {file_ext} audio. FFmpeg is required for {file_ext} files. Please upload WAV format instead, or ensure FFmpeg is installed.\"\n                        }\n                    else:\n                        return {\n                            \"status\": \"error\", \n                            \"message\": f\"Audio conversion failed: {str(e)}. Please try uploading a WAV file instead, or type your message directly.\"\n                        }\n            \n            # ============================================================\n            # STEP 1: Transcribe speech to text\n            # ============================================================\n            try:\n                with sr.AudioFile(audio_path) as source:\n                    audio_data = recognizer.record(source)\n                    transcript = recognizer.recognize_google(audio_data)\n                    text = transcript\n                    logger.info(f\"Audio transcribed successfully: {len(text)} characters\")\n            except sr.UnknownValueError:\n                return {\n                    \"status\": \"error\", \n                    \"message\": \"Could not understand the audio. Please ensure: (1) Clear speech, (2) Minimal background noise, (3) Good microphone quality. Try recording again or type your message instead.\"\n                }\n            except sr.RequestError as e:\n                logger.error(f\"Speech recognition service error: {e}\")\n                return {\n                    \"status\": \"error\",\n                    \"message\": f\"Speech recognition service is temporarily unavailable. Please try again in a moment, or type your message instead.\"\n                }\n            \n            # ============================================================\n            # STEP 2: Analyze vocal features (tone, pace, clarity, etc.)\n            # ============================================================\n            audio_features = analyze_audio_features(audio_path)\n            \n            if audio_features.get(\"status\") == \"error\":\n                logger.warning(f\"Audio feature analysis failed: {audio_features.get('message')}\")\n                # Continue with just transcription, don't fail completely\n                audio_features = None\n            \n        except Exception as e:\n            logger.error(f\"Audio processing error: {e}\\n{traceback.format_exc()}\")\n            return {\n                \"status\": \"error\", \n                \"message\": f\"Audio processing failed. Please try uploading a WAV file or typing your message. Technical details: {str(e)}\"\n            }\n    \n    if not text:\n        return {\n            \"status\": \"needs_input\",\n            \"message\": f\"ğŸ¤ {user.name}, I can analyze your communication style!\",\n            \"features\": [\n                \"ğŸ“ TEXT: Analyze word choice, tone, assertiveness\",\n                \"ğŸ™ï¸ AUDIO: Analyze speech + volume + pace + clarity + pitch + confidence\"\n            ],\n            \"options\": [\n                \"Type: 'Analyze: [what you want to say]'\",\n                \"Upload audio file (WAV recommended, also supports MP3, M4A, MP4, OGG, FLAC)\"\n            ],\n            \"examples\": [\n                \"Analyze: You always ignore my suggestions\",\n                \"Analyze: I feel frustrated when meetings run late\"\n            ],\n            \"audio_tips\": \"ğŸ“Œ For best results with audio: Use WAV format, speak clearly, minimize background noise\"\n        }\n    \n    lower = text.lower()\n    \n    # Initialize analysis\n    analysis = {\n        \"style\": \"neutral\",\n        \"tone_score\": 6,\n        \"clarity_score\": 7,\n        \"confidence_score\": 6,\n        \"empathy_score\": 5,\n        \"issues\": [],\n        \"strengths\": [],\n        \"filler_words\": []\n    }\n    \n    # ========== PATTERN DETECTION ==========\n    \n    # Aggressive patterns\n    aggressive = {\n        r\"\\byou always\\b\": \"Absolute blame ('you always')\",\n        r\"\\byou never\\b\": \"Absolute blame ('you never')\",\n        r\"\\byou should\\b\": \"Commanding tone\",\n        r\"\\bwhy didn'?t you\\b\": \"Accusatory question\",\n        r\"\\bwhat'?s wrong with you\\b\": \"Personal attack\",\n        r\"\\byou need to\\b\": \"Demanding language\",\n        r\"\\byou'?re (being )?(stupid|lazy|useless)\\b\": \"Direct insult\",\n    }\n    \n    # Passive patterns\n    passive = {\n        r\"\\bmaybe we could\\b\": \"Overly tentative\",\n        r\"\\bi guess\\b\": \"Lacks confidence\",\n        r\"\\bsorry,? but\\b\": \"Unnecessary apologizing\",\n        r\"\\bif that'?s okay\\b\": \"Excessive permission-seeking\",\n        r\"\\bjust think\\b\": \"'Just' minimizes your opinion\",\n        r\"\\bi'?m no expert\\b\": \"Self-deprecating\",\n        r\"\\bkind of\\b|\\bsort of\\b\": \"Hedging language\",\n    }\n    \n    # Assertive patterns (positive!)\n    assertive = {\n        r\"\\bi feel\\b.*\\bwhen\\b\": \"âœ… Great 'I feel when' statement!\",\n        r\"\\bi think\\b\": \"âœ… Owning your opinion\",\n        r\"\\bi believe\\b\": \"âœ… Confident stance\",\n        r\"\\bi need\\b\": \"âœ… Clear need expression\",\n        r\"\\bi'?d like\\b\": \"âœ… Polite but direct\",\n        r\"\\blet'?s\\b\": \"âœ… Collaborative language\",\n        r\"\\bwhat do you think\\b\": \"âœ… Inviting dialogue\",\n    }\n    \n    # Empathetic patterns (positive!)\n    empathetic = {\n        r\"\\bi understand\\b\": \"ğŸ’™ Shows understanding\",\n        r\"\\bi hear you\\b\": \"ğŸ’™ Active listening\",\n        r\"\\bthat must be\\b\": \"ğŸ’™ Emotional validation\",\n        r\"\\bhow do you feel\\b\": \"ğŸ’™ Checking emotions\",\n        r\"\\bi appreciate\\b\": \"ğŸ’™ Showing gratitude\",\n    }\n    \n    # Count patterns\n    aggressive_count = 0\n    passive_count = 0\n    assertive_count = 0\n    empathetic_count = 0\n    \n    for pattern, desc in aggressive.items():\n        if re.search(pattern, lower):\n            analysis[\"issues\"].append(f\"âŒ {desc}\")\n            aggressive_count += 1\n    \n    for pattern, desc in passive.items():\n        if re.search(pattern, lower):\n            analysis[\"issues\"].append(f\"âš ï¸ {desc}\")\n            passive_count += 1\n    \n    for pattern, desc in assertive.items():\n        if re.search(pattern, lower):\n            analysis[\"strengths\"].append(desc)\n            assertive_count += 1\n    \n    for pattern, desc in empathetic.items():\n        if re.search(pattern, lower):\n            analysis[\"strengths\"].append(desc)\n            empathetic_count += 1\n    \n    # Check filler words in TEXT\n    fillers = [\"um\", \"uh\", \"like\", \"you know\", \"basically\", \"literally\", \"actually\", \"honestly\"]\n    found_fillers = [f for f in fillers if f\" {f} \" in f\" {lower} \"]\n    analysis[\"filler_words\"] = found_fillers\n    \n    # Determine style and scores\n    if aggressive_count >= 2:\n        analysis[\"style\"] = \"âŒ AGGRESSIVE\"\n        analysis[\"tone_score\"] = 3\n        analysis[\"confidence_score\"] = 7\n        analysis[\"empathy_score\"] = 2\n    elif aggressive_count == 1:\n        analysis[\"style\"] = \"âš ï¸ SOMEWHAT AGGRESSIVE\"\n        analysis[\"tone_score\"] = 5\n    elif passive_count >= 2:\n        analysis[\"style\"] = \"âš ï¸ PASSIVE\"\n        analysis[\"tone_score\"] = 5\n        analysis[\"confidence_score\"] = 3\n    elif assertive_count >= 2 and empathetic_count >= 1:\n        analysis[\"style\"] = \"âœ… ASSERTIVE & EMPATHETIC (Ideal!)\"\n        analysis[\"tone_score\"] = 9\n        analysis[\"confidence_score\"] = 8\n        analysis[\"empathy_score\"] = 8\n    elif assertive_count >= 1:\n        analysis[\"style\"] = \"âœ… ASSERTIVE\"\n        analysis[\"tone_score\"] = 8\n        analysis[\"confidence_score\"] = 7\n    \n    # Adjust clarity for fillers (text-based)\n    analysis[\"clarity_score\"] = max(3, 10 - len(found_fillers) * 2)\n    \n    # IF AUDIO: Override scores with vocal analysis\n    if audio_features and audio_features.get(\"status\") == \"success\":\n        # Use audio analysis for clarity, confidence, tone\n        analysis[\"clarity_score\"] = audio_features[\"clarity\"][\"score\"]\n        analysis[\"confidence_score\"] = audio_features[\"confidence_score\"]\n        \n        # Adjust tone based on emotional tone from voice\n        emotional_tone = audio_features.get(\"emotional_tone\", \"neutral\")\n        if \"agitated\" in emotional_tone or \"stressed\" in emotional_tone:\n            analysis[\"tone_score\"] = min(analysis[\"tone_score\"], 4)\n            analysis[\"issues\"].append(\"ğŸ™ï¸ Voice sounds agitated/stressed\")\n        elif \"calm\" in emotional_tone:\n            analysis[\"tone_score\"] = max(analysis[\"tone_score\"], 7)\n            analysis[\"strengths\"].append(\"ğŸ™ï¸ Calm vocal tone\")\n        elif \"engaged\" in emotional_tone or \"enthusiastic\" in emotional_tone:\n            analysis[\"strengths\"].append(\"ğŸ™ï¸ Engaged and enthusiastic voice\")\n    \n    # Overall score\n    analysis[\"overall_score\"] = round(\n        (analysis[\"tone_score\"] + analysis[\"clarity_score\"] + \n         analysis[\"confidence_score\"] + analysis[\"empathy_score\"]) / 4\n    )\n    \n    # ========== GENERATE COACHING ==========\n    \n    coaching = []\n    rewritten = text\n    \n    if \"AGGRESSIVE\" in analysis[\"style\"]:\n        coaching = [\n            f\"1ï¸âƒ£ {user.name}, replace 'You always/never' with 'When [situation]...'\",\n            \"2ï¸âƒ£ Pause 3 seconds before responding when upset\",\n            \"3ï¸âƒ£ Focus on behavior, not the person's character\",\n            \"4ï¸âƒ£ Use format: 'I feel [emotion] when [situation] because [reason]'\",\n        ]\n        # Rewrite aggressive message\n        rewritten = re.sub(r\"\\byou always\\b\", \"when this happens, I feel\", rewritten, flags=re.IGNORECASE)\n        rewritten = re.sub(r\"\\byou never\\b\", \"when this doesn't happen, I feel\", rewritten, flags=re.IGNORECASE)\n        rewritten = re.sub(r\"\\byou should\\b\", \"I'd appreciate if you could\", rewritten, flags=re.IGNORECASE)\n        rewritten = re.sub(r\"\\bwhy didn'?t you\\b\", \"I noticed\", rewritten, flags=re.IGNORECASE)\n        \n    elif \"PASSIVE\" in analysis[\"style\"]:\n        coaching = [\n            \"1ï¸âƒ£ Remove qualifiers: 'maybe' â†’ state directly\",\n            \"2ï¸âƒ£ Only apologize when you've done something wrong\",\n            \"3ï¸âƒ£ Replace 'I guess' with 'I think' or 'I believe'\",\n            f\"4ï¸âƒ£ {user.name}, your needs matter - state them clearly!\",\n        ]\n        rewritten = re.sub(r\"\\bi guess\\b\", \"I think\", rewritten, flags=re.IGNORECASE)\n        rewritten = re.sub(r\"\\bmaybe we could\\b\", \"I suggest we\", rewritten, flags=re.IGNORECASE)\n        rewritten = re.sub(r\"\\bsorry,? but\\b\", \"\", rewritten, flags=re.IGNORECASE)\n        \n    elif \"ASSERTIVE\" in analysis[\"style\"]:\n        coaching = [\n            f\"1ï¸âƒ£ Excellent work, {user.name}! Your 'I' statements are effective\",\n            \"2ï¸âƒ£ To enhance: Add clarifying questions like 'What's your perspective?'\",\n            \"3ï¸âƒ£ Validate others: 'I hear what you're saying, and...'\",\n        ]\n    \n    # ADD AUDIO-SPECIFIC COACHING\n    if audio_features and audio_features.get(\"status\") == \"success\":\n        audio_coaching = []\n        \n        # Volume coaching\n        if audio_features[\"volume\"][\"level\"] == \"loud\":\n            audio_coaching.append(\"ğŸ”Š Lower your volume slightly to sound less aggressive\")\n        elif audio_features[\"volume\"][\"level\"] == \"soft\":\n            audio_coaching.append(\"ğŸ”Š Speak louder to sound more confident\")\n        \n        # Pace coaching\n        if audio_features[\"pace\"][\"level\"] == \"fast\":\n            audio_coaching.append(\"â±ï¸ Slow down your speech - take breaths between sentences\")\n        elif audio_features[\"pace\"][\"level\"] == \"slow\":\n            audio_coaching.append(\"â±ï¸ Increase pace slightly to maintain listener engagement\")\n        \n        # Pitch coaching\n        if audio_features[\"pitch\"][\"variety\"] == \"monotone\":\n            audio_coaching.append(\"ğŸµ Vary your pitch - emphasize key words for impact\")\n        \n        # Clarity coaching\n        if audio_features[\"clarity\"][\"level\"] == \"unclear\":\n            audio_coaching.append(\"ğŸ—£ï¸ Enunciate clearly - open your mouth more when speaking\")\n        \n        # Pause coaching\n        if audio_features[\"pauses\"][\"level\"] == \"many_long\":\n            audio_coaching.append(\"â¸ï¸ Reduce long pauses - prepare your thoughts beforehand\")\n        elif audio_features[\"pauses\"][\"level\"] == \"few\":\n            audio_coaching.append(\"â¸ï¸ Add strategic pauses to let ideas sink in\")\n        \n        if audio_coaching:\n            coaching.extend([\"\", \"ğŸ™ï¸ VOCAL COACHING:\"] + audio_coaching)\n    \n    # Relationship-specific tips\n    relationship_tips = {\n        \"boss\": \"ğŸ’¼ With your boss: Lead with solutions, not just problems. 'I noticed X, I suggest Y.'\",\n        \"colleague\": \"ğŸ¤ With colleagues: Emphasize collaboration. 'How can we solve this together?'\",\n        \"partner\": \"ğŸ’• With your partner: Choose calm moments, avoid discussing issues when tired.\",\n        \"family\": \"ğŸ‘¨â€ğŸ‘©â€ğŸ‘§ With family: Acknowledge their perspective first, then share yours.\",\n        \"friend\": \"ğŸ‘‹ With friends: Be direct but kind. Good friends appreciate honesty.\",\n    }\n    \n    # Update user stats\n    user.streaks[\"communication\"] = user.streaks.get(\"communication\", 0) + 1\n    user.total_points += 15\n    user.communication_history.append({\n        \"timestamp\": time.time(),\n        \"score\": analysis[\"overall_score\"],\n        \"style\": analysis[\"style\"],\n        \"had_audio\": audio_path is not None\n    })\n    \n    # Build result\n    result = {\n        \"status\": \"analyzed\",\n        \"original_message\": text,\n        \"transcribed_from_audio\": transcript is not None,\n        \"analysis\": {\n            \"style\": analysis[\"style\"],\n            \"scores\": {\n                \"tone\": f\"{analysis['tone_score']}/10\",\n                \"clarity\": f\"{analysis['clarity_score']}/10\",\n                \"confidence\": f\"{analysis['confidence_score']}/10\",\n                \"empathy\": f\"{analysis['empathy_score']}/10\",\n                \"overall\": f\"{analysis['overall_score']}/10\"\n            },\n            \"issues\": analysis[\"issues\"],\n            \"strengths\": analysis[\"strengths\"],\n            \"filler_words\": analysis[\"filler_words\"]\n        },\n        \"coaching\": coaching,\n        \"rewritten_message\": rewritten if rewritten != text else None,\n        \"relationship_tip\": relationship_tips.get(relationship, \"\"),\n        \"stats\": {\n            \"streak\": user.streaks[\"communication\"],\n            \"points_earned\": 15,\n            \"total_points\": user.total_points\n        }\n    }\n    \n    # Add audio analysis if available\n    if audio_features and audio_features.get(\"status\") == \"success\":\n        result[\"vocal_analysis\"] = {\n            \"duration\": f\"{audio_features['duration_seconds']}s\",\n            \"volume\": {\n                \"level\": audio_features[\"volume\"][\"level\"],\n                \"note\": audio_features[\"volume\"][\"note\"],\n                \"score\": f\"{audio_features['volume']['score']}/10\"\n            },\n            \"pace\": {\n                \"level\": audio_features[\"pace\"][\"level\"],\n                \"rate\": f\"{audio_features['pace']['syllables_per_sec']} syllables/sec\",\n                \"note\": audio_features[\"pace\"][\"note\"],\n                \"score\": f\"{audio_features['pace']['score']}/10\"\n            },\n            \"pitch\": {\n                \"level\": audio_features[\"pitch\"][\"level\"],\n                \"variety\": audio_features[\"pitch\"][\"variety\"],\n                \"note\": audio_features[\"pitch\"][\"note\"],\n                \"score\": f\"{audio_features['pitch']['score']}/10\"\n            },\n            \"clarity\": {\n                \"level\": audio_features[\"clarity\"][\"level\"],\n                \"note\": audio_features[\"clarity\"][\"note\"],\n                \"score\": f\"{audio_features['clarity']['score']}/10\"\n            },\n            \"pauses\": {\n                \"pattern\": audio_features[\"pauses\"][\"level\"],\n                \"average\": f\"{audio_features['pauses']['average_seconds']}s\",\n                \"note\": audio_features[\"pauses\"][\"note\"]\n            },\n            \"confidence_score\": f\"{audio_features['confidence_score']}/10\",\n            \"emotional_tone\": audio_features[\"emotional_tone\"],\n            \"overall_vocal_score\": f\"{audio_features['overall_score']}/10\"\n        }\n        result[\"message\"] = f\"ğŸ™ï¸ Analyzed {audio_features['duration_seconds']}s of speech with full vocal analysis!\"\n    \n    if rewritten != text:\n        result[\"correction_example\"] = f\"\\nâŒ Original: '{text}'\\nâœ… Try: '{rewritten}'\"\n    \n    metric_inc(\"communication_analyses\")\n    metric_time(\"interpersonal_coach\", time.time() - start)\n    \n    return result\n\nprint(\"âœ… Agent 3: Interpersonal Coach with FULL audio analysis ready\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T13:18:24.099183Z","iopub.execute_input":"2025-11-24T13:18:24.099509Z","iopub.status.idle":"2025-11-24T13:18:24.158322Z","shell.execute_reply.started":"2025-11-24T13:18:24.099479Z","shell.execute_reply":"2025-11-24T13:18:24.157402Z"}},"outputs":[{"name":"stdout","text":"âœ… Agent 3: Interpersonal Coach with FULL audio analysis ready\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"\n# ============================================================================\n# CELL 7: AGENT 4 - MEAL PLANNER (with Image Support)\n# ============================================================================\n\ndef analyze_food_image(image_path: str) -> Dict:\n    \"\"\"Use Gemini Vision to detect food items in image with robust error handling.\"\"\"\n    try:\n        # CHANGE 1: Add validation first\n        validation = safe_file_read(image_path, ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp'])\n        if validation[\"status\"] == \"error\":\n            return {\"status\": \"error\", \"message\": validation[\"error\"], \"items\": []}\n        \n        # CHANGE 2: Add image verification\n        try:\n            image = Image.open(image_path)\n            image.verify()  # Verify it's actually an image\n            image = Image.open(image_path)  # Reopen after verify\n        except Exception as img_err:\n            return {\n                \"status\": \"error\", \n                \"message\": f\"Invalid image file: {str(img_err)}\", \n                \"items\": []\n            }\n        \n        # Rest remains the same\n        model = genai.GenerativeModel('gemini-2.5-flash')\n        \n        response = model.generate_content([\n            \"List all food items, ingredients, or groceries visible in this image. \"\n            \"Return ONLY a comma-separated list. Example: chicken, rice, broccoli. \"\n            \"If no food visible, return: none\",\n            image\n        ])\n        \n        result_text = response.text.strip().lower()\n        \n        if result_text == \"none\" or not result_text:\n            return {\"status\": \"no_food\", \"items\": []}\n        \n        items = [item.strip() for item in result_text.split(',') if item.strip()]\n        return {\"status\": \"success\", \"items\": items}\n        \n    except Exception as e:\n        logger.error(f\"Image analysis error: {e}\\n{traceback.format_exc()}\")  # CHANGE 3: Add traceback\n        return {\n            \"status\": \"error\", \n            \"message\": f\"Image processing failed: {str(e)}\", \n            \"items\": []\n        }\n\n\ndef plan_meals(\n    user_id: str,\n    ingredients: str = None,\n    image_path: str = None,\n    days: int = 3\n) -> Dict:\n    \"\"\"\n    Create meal plans from ingredients (text or image).\n    \n    Parameters:\n    - user_id: User identifier\n    - ingredients: Comma-separated list of ingredients\n    - image_path: Path to image of groceries/fridge\n    - days: Number of days to plan (1-7)\n    \n    Returns: Meal plans with recipes\n    \"\"\"\n    start = time.time()\n    user = get_user(user_id)\n    groceries = []\n    image_note = \"\"\n    \n    # Process image if provided\n    if image_path:\n        logger.info(f\"Processing food image: {image_path}\")\n        \n        # CHANGE: Add validation before analysis\n        validation = safe_file_read(image_path, ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp'])\n        if validation[\"status\"] == \"error\":\n            return {\n                \"status\": \"error\",\n                \"message\": f\"Image error: {validation['error']}\"\n            }\n        \n        image_result = analyze_food_image(image_path)\n        \n        if image_result[\"status\"] == \"success\":\n            groceries.extend(image_result[\"items\"])\n            image_note = f\"ğŸ“¸ Detected from image: {', '.join(image_result['items'])}\"\n        elif image_result[\"status\"] == \"no_food\":\n            image_note = \"ğŸ“¸ No food items detected in image\"\n        else:\n            image_note = f\"âš ï¸ Image error: {image_result.get('message', 'Unknown error')}\"\n    \n    # Process text ingredients\n    if ingredients:\n        text_items = [g.strip().lower() for g in re.split(r'[,;]', ingredients) if len(g.strip()) > 2]\n        groceries.extend(text_items)\n    \n    # Remove duplicates\n    groceries = list(set(groceries))\n    \n    if not groceries:\n        return {\n            \"status\": \"needs_input\",\n            \"message\": f\"ğŸ³ {user.name}, I need ingredients to plan meals!\",\n            \"image_note\": image_note if image_note else None,\n            \"options\": [\n                \"ğŸ“ List ingredients: 'Meal plan: chicken, rice, broccoli'\",\n                \"ğŸ“¸ Upload a photo of your fridge/groceries\",\n            ],\n            \"example\": \"Meal plan: chicken breast, rice, broccoli, eggs, onion\"\n        }\n    \n    # Categorize ingredients\n    categories = {\n        \"proteins\": [\"chicken\", \"beef\", \"pork\", \"fish\", \"salmon\", \"tuna\", \"shrimp\", \"egg\", \"tofu\", \"turkey\", \"lamb\"],\n        \"carbs\": [\"rice\", \"pasta\", \"bread\", \"potato\", \"noodle\", \"quinoa\", \"oat\", \"tortilla\"],\n        \"vegetables\": [\"broccoli\", \"spinach\", \"carrot\", \"tomato\", \"onion\", \"pepper\", \"lettuce\", \"cucumber\", \"mushroom\", \"garlic\", \"celery\", \"cabbage\"],\n        \"fruits\": [\"apple\", \"banana\", \"orange\", \"berry\", \"grape\", \"mango\", \"lemon\"],\n        \"dairy\": [\"milk\", \"cheese\", \"yogurt\", \"butter\", \"cream\"]\n    }\n    \n    categorized = {cat: [] for cat in categories}\n    for g in groceries:\n        for cat, keywords in categories.items():\n            if any(k in g for k in keywords):\n                categorized[cat].append(g)\n                break\n    \n    # Generate meal plans\n    meal_plans = []\n    days = min(max(1, days), 7)  # Clamp 1-7\n    \n    for day in range(1, days + 1):\n        day_meals = {\"day\": f\"Day {day}\", \"meals\": {}}\n        \n        # Breakfast\n        if categorized[\"proteins\"] or categorized[\"dairy\"]:\n            if \"egg\" in str(categorized[\"proteins\"]):\n                day_meals[\"meals\"][\"breakfast\"] = {\n                    \"dish\": f\"Scrambled eggs with {categorized['vegetables'][0] if categorized['vegetables'] else 'toast'}\",\n                    \"time\": \"15 min\", \"calories\": \"300-400\"\n                }\n            elif categorized[\"dairy\"]:\n                day_meals[\"meals\"][\"breakfast\"] = {\n                    \"dish\": f\"Greek yogurt with {categorized['fruits'][0] if categorized['fruits'] else 'granola'}\",\n                    \"time\": \"5 min\", \"calories\": \"250-350\"\n                }\n        \n        # Lunch\n        if categorized[\"proteins\"] and categorized[\"vegetables\"]:\n            p = categorized[\"proteins\"][day % len(categorized[\"proteins\"])]\n            v = categorized[\"vegetables\"][day % len(categorized[\"vegetables\"])]\n            day_meals[\"meals\"][\"lunch\"] = {\n                \"dish\": f\"Grilled {p} salad with {v}\",\n                \"time\": \"20 min\", \"calories\": \"400-500\"\n            }\n        \n        # Dinner\n        if categorized[\"proteins\"]:\n            p = categorized[\"proteins\"][(day + 1) % len(categorized[\"proteins\"])]\n            c = categorized[\"carbs\"][0] if categorized[\"carbs\"] else \"rice\"\n            v = categorized[\"vegetables\"][(day + 1) % len(categorized[\"vegetables\"])] if categorized[\"vegetables\"] else \"vegetables\"\n            day_meals[\"meals\"][\"dinner\"] = {\n                \"dish\": f\"{p.title()} stir-fry with {c} and {v}\",\n                \"time\": \"30 min\", \"calories\": \"500-600\"\n            }\n        \n        meal_plans.append(day_meals)\n    \n    # Generate detailed recipes\n    recipes = []\n    \n    if \"chicken\" in str(groceries):\n        recipes.append({\n            \"name\": \"ğŸ— Quick Chicken Stir-Fry\",\n            \"time\": \"25 min\",\n            \"servings\": 4,\n            \"ingredients\": [\n                \"2 chicken breasts, cubed\",\n                f\"2 cups {categorized['vegetables'][0] if categorized['vegetables'] else 'mixed vegetables'}\",\n                f\"1 cup {categorized['carbs'][0] if categorized['carbs'] else 'rice'}\",\n                \"2 tbsp oil, 2 cloves garlic, 3 tbsp soy sauce\"\n            ],\n            \"steps\": [\n                \"1ï¸âƒ£ Cook rice/carbs according to package\",\n                \"2ï¸âƒ£ Heat oil in wok over high heat\",\n                \"3ï¸âƒ£ Add chicken, cook 6-8 min until golden\",\n                \"4ï¸âƒ£ Add garlic and vegetables, stir 4-5 min\",\n                \"5ï¸âƒ£ Add soy sauce, toss and serve over rice\"\n            ]\n        })\n    \n    if \"egg\" in str(groceries):\n        recipes.append({\n            \"name\": \"ğŸ³ Veggie Omelette\",\n            \"time\": \"10 min\",\n            \"servings\": 1,\n            \"ingredients\": [\n                \"3 eggs\",\n                f\"1/4 cup diced {categorized['vegetables'][0] if categorized['vegetables'] else 'vegetables'}\",\n                \"2 tbsp cheese, salt, pepper, 1 tbsp butter\"\n            ],\n            \"steps\": [\n                \"1ï¸âƒ£ Beat eggs with salt and pepper\",\n                \"2ï¸âƒ£ Melt butter in pan over medium heat\",\n                \"3ï¸âƒ£ Pour eggs, let set 1-2 min\",\n                \"4ï¸âƒ£ Add veggies and cheese to half\",\n                \"5ï¸âƒ£ Fold and serve\"\n            ]\n        })\n    \n    # Shopping suggestions\n    missing = []\n    if not categorized[\"proteins\"]: missing.append(\"protein (chicken, fish, eggs, tofu)\")\n    if not categorized[\"carbs\"]: missing.append(\"carbs (rice, pasta, bread)\")\n    if not categorized[\"vegetables\"]: missing.append(\"vegetables\")\n    \n    # Update user stats\n    user.streaks[\"nutrition\"] = user.streaks.get(\"nutrition\", 0) + 1\n    user.total_points += 25\n    \n    metric_inc(\"meal_plans\")\n    metric_time(\"meal_planner\", time.time() - start)\n    \n    return {\n        \"status\": \"complete\",\n        \"ingredients_found\": groceries,\n        \"categories\": {k: v for k, v in categorized.items() if v},\n        \"meal_plans\": meal_plans,\n        \"recipes\": recipes,\n        \"days_planned\": days,\n        \"shopping_suggestions\": missing,\n        \"image_analysis\": image_note if image_note else None,\n        \"stats\": {\n            \"streak\": user.streaks[\"nutrition\"],\n            \"points_earned\": 25,\n            \"total_points\": user.total_points\n        }\n    }\n\nprint(\"âœ… Agent 4: Meal Planner ready\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T13:18:24.159402Z","iopub.execute_input":"2025-11-24T13:18:24.159701Z","iopub.status.idle":"2025-11-24T13:18:24.188835Z","shell.execute_reply.started":"2025-11-24T13:18:24.159675Z","shell.execute_reply":"2025-11-24T13:18:24.187991Z"}},"outputs":[{"name":"stdout","text":"âœ… Agent 4: Meal Planner ready\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"\n# ============================================================================\n# CELL 8: AGENT 5 - TASK PLANNER\n# ============================================================================\n\ndef plan_tasks(user_id: str, tasks_text: str) -> Dict:\n    \"\"\"\n    Organize and prioritize tasks with time estimates.\n    \n    Parameters:\n    - user_id: User identifier\n    - tasks_text: Comma-separated list of tasks\n    \n    Returns: Prioritized task list with estimates\n    \"\"\"\n    start = time.time()\n    user = get_user(user_id)\n    \n    # Parse tasks\n    tasks = [t.strip() for t in re.split(r'[,;]', tasks_text) if len(t.strip()) > 2]\n    \n    if not tasks:\n        return {\n            \"status\": \"needs_input\",\n            \"message\": f\"ğŸ“‹ {user.name}, please list your tasks!\",\n            \"example\": \"Tasks: finish report, call client, workout, send emails\"\n        }\n    \n    # Analyze and schedule tasks\n    scheduled = []\n    total_time = 0\n    \n    time_estimates = {\n        \"quick\": ([\"call\", \"email\", \"text\", \"message\", \"reply\"], 15),\n        \"medium\": ([\"meeting\", \"review\", \"check\", \"update\"], 30),\n        \"long\": ([\"write\", \"report\", \"presentation\", \"project\", \"analysis\"], 60),\n        \"extended\": ([\"research\", \"develop\", \"build\", \"create\", \"design\"], 90)\n    }\n    \n    for i, task in enumerate(tasks):\n        lower = task.lower()\n        \n        # Estimate time\n        est = 30  # default\n        for duration, (keywords, minutes) in time_estimates.items():\n            if any(k in lower for k in keywords):\n                est = minutes\n                break\n        \n        # Calculate priority\n        priority = 10 - i  # Base priority by order\n        if any(w in lower for w in [\"urgent\", \"asap\", \"important\", \"deadline\", \"critical\"]):\n            priority += 5\n        if any(w in lower for w in [\"optional\", \"maybe\", \"if time\"]):\n            priority -= 3\n        \n        scheduled.append({\n            \"task\": task,\n            \"estimate_min\": est,\n            \"priority\": max(1, min(15, priority)),\n            \"category\": \"urgent\" if priority > 10 else \"normal\" if priority > 5 else \"low\"\n        })\n        total_time += est\n    \n    # Sort by priority\n    scheduled.sort(key=lambda x: x[\"priority\"], reverse=True)\n    \n    # Generate strategy\n    if total_time > 240:  # > 4 hours\n        strategy = \"ğŸ… Pomodoro Technique: 25 min focused work â†’ 5 min break â†’ repeat\"\n        motivation = f\"{user.name}, that's {total_time//60}+ hours of work. Break it into sessions!\"\n    elif total_time > 120:  # > 2 hours\n        strategy = \"ğŸ“… Time Blocking: Schedule 90-min focus blocks with 15-min breaks\"\n        motivation = f\"Solid list! About {total_time//60} hours. You've got this!\"\n    else:\n        strategy = \"âš¡ Batch Processing: Group similar tasks together\"\n        motivation = f\"Quick wins ahead! About {total_time} minutes total.\"\n    \n    # Update user stats\n    user.streaks[\"tasks\"] = user.streaks.get(\"tasks\", 0) + 1\n    user.total_points += 15\n    \n    metric_inc(\"tasks_planned\")\n    metric_time(\"task_planner\", time.time() - start)\n    \n    return {\n        \"status\": \"planned\",\n        \"tasks\": scheduled,\n        \"summary\": {\n            \"total_tasks\": len(scheduled),\n            \"total_time\": f\"{total_time//60}h {total_time%60}m\" if total_time >= 60 else f\"{total_time}m\",\n            \"urgent_tasks\": len([t for t in scheduled if t[\"category\"] == \"urgent\"]),\n        },\n        \"top_3_priorities\": [t[\"task\"] for t in scheduled[:3]],\n        \"strategy\": strategy,\n        \"motivation\": motivation,\n        \"stats\": {\n            \"streak\": user.streaks[\"tasks\"],\n            \"points_earned\": 15,\n            \"total_points\": user.total_points\n        }\n    }\n\nprint(\"âœ… Agent 5: Task Planner ready\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T13:18:24.189831Z","iopub.execute_input":"2025-11-24T13:18:24.190460Z","iopub.status.idle":"2025-11-24T13:18:24.213841Z","shell.execute_reply.started":"2025-11-24T13:18:24.190436Z","shell.execute_reply":"2025-11-24T13:18:24.212940Z"}},"outputs":[{"name":"stdout","text":"âœ… Agent 5: Task Planner ready\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"\n# ============================================================================\n# CELL 9: AGENT 6 - NUTRITION ADVISOR\n# ============================================================================\n\ndef get_nutrition_advice(user_id: str, goal: str) -> Dict:\n    \"\"\"\n    Provide nutrition advice based on wellness goals.\n    \n    Parameters:\n    - user_id: User identifier\n    - goal: User's goal or concern (stress, energy, weight, sleep, etc.)\n    \n    Returns: Personalized nutrition guidance\n    \"\"\"\n    start = time.time()\n    user = get_user(user_id)\n    lower = goal.lower()\n    \n    # Detect goal from text\n    advice_db = {\n        \"stress\": {\n            \"keywords\": [\"stress\", \"anxiety\", \"anxious\", \"calm\", \"relax\", \"nervous\"],\n            \"goal_name\": \"Stress Management\",\n            \"foods\": [\"Dark chocolate (85%+)\", \"Walnuts\", \"Salmon\", \"Blueberries\", \"Green tea\", \"Chamomile tea\"],\n            \"tips\": [\n                \"ğŸ« Magnesium in dark chocolate helps reduce cortisol\",\n                \"ğŸŸ Omega-3s in salmon reduce inflammation and anxiety\",\n                \"ğŸ«– L-theanine in green tea promotes calm without drowsiness\",\n                \"ğŸ¥œ B-vitamins in nuts support nervous system health\"\n            ],\n            \"avoid\": [\"Excessive caffeine\", \"Alcohol\", \"Refined sugars\", \"Processed foods\"]\n        },\n        \"energy\": {\n            \"keywords\": [\"energy\", \"tired\", \"fatigue\", \"exhausted\", \"sluggish\", \"alert\"],\n            \"goal_name\": \"Energy Boost\",\n            \"foods\": [\"Oatmeal\", \"Eggs\", \"Bananas\", \"Greek yogurt\", \"Almonds\", \"Sweet potato\"],\n            \"tips\": [\n                \"ğŸ¥š Protein at breakfast sustains energy all morning\",\n                \"ğŸŒ Complex carbs provide steady fuel without crashes\",\n                \"ğŸ’§ Dehydration is a major cause of fatigue - drink more water!\",\n                \"ğŸ¥œ Healthy fats keep you satisfied and energized\"\n            ],\n            \"avoid\": [\"Sugar-heavy breakfast\", \"Skipping meals\", \"Energy drinks\", \"Large heavy lunches\"]\n        },\n        \"sleep\": {\n            \"keywords\": [\"sleep\", \"insomnia\", \"rest\", \"tired at night\", \"can't sleep\"],\n            \"goal_name\": \"Better Sleep\",\n            \"foods\": [\"Cherries\", \"Warm milk\", \"Turkey\", \"Kiwi\", \"Almonds\", \"Chamomile tea\"],\n            \"tips\": [\n                \"ğŸ’ Cherries are natural source of melatonin\",\n                \"ğŸ¥› Warm milk contains tryptophan for relaxation\",\n                \"ğŸ¥ Two kiwis before bed improves sleep quality\",\n                \"â° Avoid eating 2-3 hours before bedtime\"\n            ],\n            \"avoid\": [\"Caffeine after 2pm\", \"Alcohol before bed\", \"Heavy/spicy dinners\", \"Chocolate at night\"]\n        },\n        \"weight\": {\n            \"keywords\": [\"weight\", \"diet\", \"lose\", \"fat\", \"calories\", \"slim\"],\n            \"goal_name\": \"Weight Management\",\n            \"foods\": [\"Lean proteins\", \"Leafy greens\", \"Berries\", \"Legumes\", \"Whole grains\", \"Greek yogurt\"],\n            \"tips\": [\n                \"ğŸ¥— Fill half your plate with vegetables\",\n                \"ğŸ— Protein keeps you full longer - include at every meal\",\n                \"â±ï¸ Eat slowly - it takes 20 min to feel full\",\n                \"ğŸ’§ Drink water before meals to reduce overeating\"\n            ],\n            \"avoid\": [\"Liquid calories\", \"Processed snacks\", \"Large portions\", \"Eating while distracted\"]\n        },\n        \"focus\": {\n            \"keywords\": [\"focus\", \"concentrate\", \"brain\", \"memory\", \"think\", \"mental\"],\n            \"goal_name\": \"Mental Focus\",\n            \"foods\": [\"Fatty fish\", \"Blueberries\", \"Eggs\", \"Broccoli\", \"Pumpkin seeds\", \"Dark chocolate\"],\n            \"tips\": [\n                \"ğŸŸ DHA in fatty fish is essential for brain function\",\n                \"ğŸ« Antioxidants in blueberries improve memory\",\n                \"ğŸ¥š Choline in eggs supports neurotransmitter production\",\n                \"ğŸ¥¦ Vitamin K in broccoli enhances cognitive function\"\n            ],\n            \"avoid\": [\"Excessive sugar\", \"Trans fats\", \"Alcohol\", \"Highly processed foods\"]\n        }\n    }\n    \n    # Find matching goal\n    selected = None\n    for key, data in advice_db.items():\n        if any(kw in lower for kw in data[\"keywords\"]):\n            selected = data\n            break\n    \n    # Default to general wellness\n    if not selected:\n        selected = {\n            \"goal_name\": \"General Wellness\",\n            \"foods\": [\"Colorful vegetables\", \"Lean proteins\", \"Whole grains\", \"Healthy fats\", \"Water\"],\n            \"tips\": [\n                \"ğŸŒˆ Eat the rainbow - variety ensures all nutrients\",\n                \"ğŸ¥© Include protein at every meal\",\n                \"ğŸ’§ Aim for 8 glasses of water daily\",\n                \"ğŸ½ï¸ Practice mindful eating - no screens at meals\"\n            ],\n            \"avoid\": [\"Processed foods\", \"Excessive sugar\", \"Trans fats\", \"Skipping meals\"]\n        }\n    \n    # Update user stats\n    user.total_points += 10\n    \n    metric_inc(\"nutrition_advice\")\n    metric_time(\"nutrition_agent\", time.time() - start)\n    \n    return {\n        \"status\": \"success\",\n        \"goal\": selected[\"goal_name\"],\n        \"recommended_foods\": selected[\"foods\"],\n        \"tips\": selected[\"tips\"],\n        \"foods_to_limit\": selected.get(\"avoid\", []),\n        \"quick_meal\": f\"Try: {selected['foods'][0]} + {selected['foods'][1]} for your next meal\",\n        \"stats\": {\n            \"points_earned\": 10,\n            \"total_points\": user.total_points\n        },\n        \"encouragement\": f\"{user.name}, small changes lead to big results! ğŸ’ª\"\n    }\n\nprint(\"âœ… Agent 6: Nutrition Advisor ready\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T13:18:24.216516Z","iopub.execute_input":"2025-11-24T13:18:24.216838Z","iopub.status.idle":"2025-11-24T13:18:24.239600Z","shell.execute_reply.started":"2025-11-24T13:18:24.216819Z","shell.execute_reply":"2025-11-24T13:18:24.238702Z"}},"outputs":[{"name":"stdout","text":"âœ… Agent 6: Nutrition Advisor ready\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# ============================================================================\n# MODIFIED AGENT 7 - SUMMARIZER \n# ============================================================================\n\ndef extract_from_url(url: str) -> Dict:\n    \"\"\"Extract text from URL.\"\"\"\n    try:\n        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n        response = requests.get(url, headers=headers, timeout=15)\n        response.raise_for_status()\n        \n        soup = BeautifulSoup(response.content, 'html.parser')\n        for tag in soup(['script', 'style', 'nav', 'footer', 'header']):\n            tag.decompose()\n        \n        main = soup.find('main') or soup.find('article') or soup.find('body')\n        paragraphs = main.find_all(['p', 'h1', 'h2', 'h3', 'li']) if main else []\n        text = '\\n'.join([p.get_text().strip() for p in paragraphs if p.get_text().strip()])\n        \n        title = soup.find('title')\n        \n        return {\n            \"status\": \"success\", \"type\": \"url\", \"source\": url,\n            \"title\": title.get_text().strip() if title else \"Untitled\",\n            \"content\": text[:15000], \"word_count\": len(text.split())\n        }\n    except Exception as e:\n        return {\"status\": \"error\", \"message\": str(e)}\n\n\ndef extract_from_pdf(pdf_path: str) -> Dict:\n    \"\"\"Extract text from PDF with robust error handling.\"\"\"\n    try:\n        # Add validation\n        validation = safe_file_read(pdf_path, ['.pdf'])\n        if validation[\"status\"] == \"error\":\n            return {\"status\": \"error\", \"message\": validation[\"error\"]}\n        \n        text = \"\"\n        with open(pdf_path, 'rb') as f:\n            try:\n                reader = PyPDF2.PdfReader(f)\n                num_pages = len(reader.pages)\n                \n                # Check for empty PDF\n                if num_pages == 0:\n                    return {\"status\": \"error\", \"message\": \"PDF has no pages\"}\n                \n                # Limit to first 50 pages to avoid timeouts\n                for i, page in enumerate(reader.pages[:50]):\n                    try:\n                        page_text = page.extract_text()\n                        if page_text:\n                            text += page_text + \"\\n\"\n                    except Exception as page_err:\n                        logger.warning(f\"Could not extract page {i}: {page_err}\")\n                        continue\n                \n                # Check if any text was extracted\n                if not text.strip():\n                    return {\"status\": \"error\", \"message\": \"Could not extract any text from PDF\"}\n                \n                return {\n                    \"status\": \"success\", \n                    \"type\": \"pdf\", \n                    \"source\": pdf_path,\n                    \"content\": text[:15000], \n                    \"word_count\": len(text.split()),\n                    \"pages\": min(num_pages, 50)\n                }\n            except Exception as read_err:\n                return {\"status\": \"error\", \"message\": f\"PDF reading error: {str(read_err)}\"}\n                \n    except Exception as e:\n        logger.error(f\"PDF extraction error: {e}\\n{traceback.format_exc()}\")\n        return {\"status\": \"error\", \"message\": f\"PDF processing failed: {str(e)}\"}\n\n\ndef summarize_content(\n    user_id: str,\n    text: str = None,\n    url: str = None,\n    pdf_path: str = None,\n    output_format: str = \"all\"\n) -> Dict:\n    \"\"\"\n    Enhanced summarizer supporting TEXT, URL, and PDF only.\n    \n    REMOVED FORMATS: DOCX, IPYNB (not working reliably)\n    \n    Parameters:\n    - user_id: User identifier\n    - text: Text to analyze (direct input)\n    - url: URL to fetch and summarize\n    - pdf_path: Path to PDF file\n    - output_format: \"summary\", \"quiz\", \"findings\", \"mindmap\", \"all\"\n    \n    Returns: Comprehensive analysis with AI-generated insights\n    \"\"\"\n    start = time.time()\n    user = get_user(user_id)\n    \n    # Extract content from available sources\n    extracted = None\n    \n    if url:\n        extracted = extract_from_url(url)\n    elif pdf_path:\n        extracted = extract_from_pdf(pdf_path)\n    elif text and len(text) >= 50:\n        extracted = {\"status\": \"success\", \"type\": \"text\", \"content\": text, \"word_count\": len(text.split())}\n    else:\n        return {\n            \"status\": \"needs_input\",\n            \"message\": f\"ğŸ“„ {user.name}, I can summarize content in these formats:\",\n            \"supported_formats\": [\n                \"âœ… Direct text (paste or type)\",\n                \"âœ… URL (any website)\",\n                \"âœ… PDF (documents up to 50 pages)\"\n            ],\n            \"removed_formats\": [\n                \"âŒ DOCX (removed - not working)\",\n                \"âŒ IPYNB (removed - not working)\"\n            ],\n            \"examples\": [\n                \"Summarize: [paste your text here]\",\n                \"Summarize: https://example.com/article\",\n                \"Upload a PDF file\"\n            ]\n        }\n    \n    if extracted.get(\"status\") == \"error\":\n        return extracted\n    \n    content = extracted[\"content\"]\n    word_count = extracted.get(\"word_count\", 0)\n    \n    # Calculate reading time\n    reading_time = max(1, word_count // 200)  # Average 200 words per minute\n    \n    # Use Gemini for AI summarization\n    try:\n        model = genai.GenerativeModel('gemini-2.5-flash')\n        \n        # Enhanced prompt for general content\n        prompt = f\"\"\"Analyze this content comprehensively. Return ONLY valid JSON:\n{{\n    \"summary\": \"3-4 sentence summary\",\n    \"key_points\": [\"point1\", \"point2\", \"point3\", \"point4\", \"point5\"],\n    \"action_items\": [\"actionable task 1\", \"actionable task 2\"],\n    \"key_entities\": {{\n        \"people\": [\"person1\", \"person2\"],\n        \"organizations\": [\"org1\", \"org2\"],\n        \"locations\": [\"place1\", \"place2\"]\n    }},\n    \"sentiment\": \"positive/negative/neutral/mixed\",\n    \"main_topics\": [\"topic1\", \"topic2\", \"topic3\"],\n    \"difficulty_level\": \"easy/moderate/complex\",\n    \"mind_map\": {{\n        \"central_topic\": \"main topic\",\n        \"branches\": [\"subtopic1\", \"subtopic2\", \"subtopic3\"]\n    }},\n    \"quiz\": [\n        {{\"question\": \"What is the main idea?\", \"options\": [\"A) Option\", \"B) Option\", \"C) Option\", \"D) Option\"], \"answer\": \"A\"}},\n        {{\"question\": \"According to the text...\", \"options\": [\"A) Option\", \"B) Option\", \"C) Option\", \"D) Option\"], \"answer\": \"C\"}}\n    ],\n    \"key_findings\": [\"finding1\", \"finding2\", \"finding3\"]\n}}\n\nContent: {content[:8000]}\"\"\"\n        \n        # Add max_output_tokens to ensure complete JSON\n        response = model.generate_content(\n            prompt,\n            generation_config=genai.types.GenerationConfig(\n                max_output_tokens=2048,\n                temperature=0.3\n            )\n        )\n        response_text = response.text.strip()\n        \n        # Clean JSON from markdown\n        if '```json' in response_text:\n            response_text = response_text.split('```json')[1].split('```')[0]\n        elif '```' in response_text:\n            response_text = response_text.split('```')[1].split('```')[0]\n        \n        response_text = response_text.strip()\n        \n        # Try to parse JSON\n        try:\n            ai_result = json.loads(response_text)\n        except json.JSONDecodeError as je:\n            logger.error(f\"JSON parsing error: {je}\")\n            logger.error(f\"Response text: {response_text[:500]}\")\n            raise Exception(\"Invalid JSON from AI\")\n        \n    except Exception as e:\n        logger.error(f\"AI summarization failed: {e}\")\n        # Enhanced fallback\n        sentences = [s.strip() for s in content.split('.') if len(s.strip()) > 20]\n        \n        ai_result = {\n            \"summary\": '. '.join(sentences[:3]) + '.',\n            \"key_points\": sentences[:5],\n            \"main_topics\": [\"General content\"],\n            \"sentiment\": \"neutral\",\n            \"difficulty_level\": \"moderate\",\n            \"quiz\": [],\n            \"key_findings\": sentences[:3],\n            \"action_items\": [],\n            \"error_note\": \"Using fallback analysis\"\n        }\n    \n    # Build enhanced result\n    result = {\n        \"status\": \"complete\",\n        \"source_type\": extracted.get(\"type\"),\n        \"source\": extracted.get(\"source\", \"text input\"),\n        \"metadata\": {\n            \"word_count\": word_count,\n            \"reading_time\": f\"{reading_time} min\",\n            \"processing_time\": f\"{time.time() - start:.2f}s\",\n            \"difficulty\": ai_result.get(\"difficulty_level\", \"moderate\"),\n            \"sentiment\": ai_result.get(\"sentiment\", \"neutral\")\n        }\n    }\n    \n    # Add content based on output_format\n    if output_format in [\"summary\", \"all\"]:\n        result[\"summary\"] = ai_result.get(\"summary\")\n        result[\"key_points\"] = ai_result.get(\"key_points\", [])\n        result[\"main_topics\"] = ai_result.get(\"main_topics\", [])\n    \n    if output_format in [\"quiz\", \"all\"]:\n        result[\"quiz\"] = ai_result.get(\"quiz\", [])\n    \n    if output_format in [\"findings\", \"all\"]:\n        result[\"key_findings\"] = ai_result.get(\"key_findings\", [])\n    \n    if output_format in [\"mindmap\", \"all\"]:\n        result[\"mind_map\"] = ai_result.get(\"mind_map\", {})\n    \n    if output_format in [\"all\"]:\n        result[\"action_items\"] = ai_result.get(\"action_items\", [])\n        result[\"key_entities\"] = ai_result.get(\"key_entities\", {})\n    \n    # Update user stats\n    user.total_points += 30\n    \n    # Award badges for document processing\n    docs_processed = user_journeys[user_id].game_scores.get(\"docs_processed\", 0) + 1\n    user_journeys[user_id].game_scores[\"docs_processed\"] = docs_processed\n    \n    if docs_processed == 5 and \"ğŸ“š Knowledge Seeker\" not in user.badges:\n        user.badges.append(\"ğŸ“š Knowledge Seeker\")\n        result[\"new_badge\"] = \"ğŸ“š Knowledge Seeker\"\n    elif docs_processed == 20 and \"ğŸ“šğŸ“š Research Master\" not in user.badges:\n        user.badges.append(\"ğŸ“šğŸ“š Research Master\")\n        result[\"new_badge\"] = \"ğŸ“šğŸ“š Research Master\"\n    \n    metric_inc(\"summaries\")\n    metric_time(\"summarizer\", time.time() - start)\n    \n    result[\"stats\"] = {\n        \"points_earned\": 30,\n        \"total_points\": user.total_points,\n        \"documents_processed\": docs_processed\n    }\n    \n    return result\n\nprint(\"âœ… Agent 7: Summarizer (Text/URL/PDF only) ready\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T13:18:24.240869Z","iopub.execute_input":"2025-11-24T13:18:24.241140Z","iopub.status.idle":"2025-11-24T13:18:24.268895Z","shell.execute_reply.started":"2025-11-24T13:18:24.241121Z","shell.execute_reply":"2025-11-24T13:18:24.267979Z"}},"outputs":[{"name":"stdout","text":"âœ… Agent 7: Summarizer (Text/URL/PDF only) ready\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"\ndef safe_tool_wrapper(func):\n    \"\"\"Decorator to wrap tool functions with comprehensive error handling.\"\"\"\n    def wrapper(*args, **kwargs):\n        try:\n            result = func(*args, **kwargs)\n            # Check if result is an error dict\n            if isinstance(result, dict) and result.get(\"status\") == \"error\":\n                # Make error message more user-friendly\n                user_message = result.get(\"message\", \"An error occurred\")\n                return {\n                    \"status\": \"error\",\n                    \"message\": f\"I encountered an issue: {user_message}. Please try again or use a different format.\",\n                    \"original_error\": user_message\n                }\n            return result\n        except Exception as e:\n            logger.error(f\"Tool {func.__name__} error: {e}\\n{traceback.format_exc()}\")\n            return {\n                \"status\": \"error\",\n                \"message\": f\"I'm sorry, something went wrong while processing your request. Please try again.\",\n                \"function\": func.__name__\n            }\n    wrapper.__name__ = func.__name__\n    wrapper.__doc__ = func.__doc__\n    return wrapper\n\nprint(\"âœ… Safe tool wrapper defined\")\n\n# Create wrapped versions of all agent functions\nwrapped_analyze_mood = safe_tool_wrapper(analyze_mood)\nwrapped_play_stress_game = safe_tool_wrapper(play_stress_game)\nwrapped_analyze_interpersonal = safe_tool_wrapper(analyze_interpersonal)\nwrapped_plan_meals = safe_tool_wrapper(plan_meals)\nwrapped_plan_tasks = safe_tool_wrapper(plan_tasks)\nwrapped_get_nutrition_advice = safe_tool_wrapper(get_nutrition_advice)\nwrapped_summarize_content = safe_tool_wrapper(summarize_content)\n\nprint(\"âœ… All agent functions wrapped with error handlers\")\n\n# Create ADK FunctionTools from wrapped functions\nmood_tool = FunctionTool(wrapped_analyze_mood)\ngame_tool = FunctionTool(wrapped_play_stress_game)\ninterpersonal_tool = FunctionTool(wrapped_analyze_interpersonal)\nmeal_tool = FunctionTool(wrapped_plan_meals)\ntask_tool = FunctionTool(wrapped_plan_tasks)\nnutrition_tool = FunctionTool(wrapped_get_nutrition_advice)\nsummarize_tool = FunctionTool(wrapped_summarize_content)\n\nALL_TOOLS = [\n    mood_tool,\n    game_tool,\n    interpersonal_tool,\n    meal_tool,\n    task_tool,\n    nutrition_tool,\n    summarize_tool\n]\n\nprint(\"âœ… All 7 agents wrapped as ADK tools\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T13:18:24.269902Z","iopub.execute_input":"2025-11-24T13:18:24.270237Z","iopub.status.idle":"2025-11-24T13:18:24.290535Z","shell.execute_reply.started":"2025-11-24T13:18:24.270214Z","shell.execute_reply":"2025-11-24T13:18:24.289564Z"}},"outputs":[{"name":"stdout","text":"âœ… Safe tool wrapper defined\nâœ… All agent functions wrapped with error handlers\nâœ… All 7 agents wrapped as ADK tools\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# ============================================================================\n# CELL 12: CREATE ADK AGENT WITH SYSTEM INSTRUCTIONS\n# ============================================================================\n\nSYSTEM_INSTRUCTION = \"\"\"You are MindMate AI, a compassionate wellness companion with 7 specialized agents.\n\nğŸ”§ AVAILABLE TOOLS:\n\n1. analyze_mood(user_id, message, stress_level=5)\n   - Emotional support & mood tracking\n   - Use when user expresses feelings\n   \n2. play_stress_game(user_id, game_type=\"random\")\n   - Fun mental break games (riddles, trivia, brain teasers, patterns, detective)\n   - Use when user says: \"stressed\", \"overwhelmed\", \"need a break\", \"game\", \"refresh\"\n   \n3. analyze_interpersonal(user_id, text=None, audio_path=None, relationship=\"colleague\")\n   - Text OR audio communication analysis with interpersonal coaching\n   - Use when user says: \"Analyze:\", \"you always\", \"you never\", or uploads audio\n   - Relationships: boss, colleague, partner, family, friend\n   **FILE HANDLING**: Audio files are handled automatically when uploaded\n   \n4. plan_meals(user_id, ingredients=None, image_path=None, days=3)\n   - Create meal plans from ingredients (text or image)\n   - Use when user says: \"meal plan\", \"recipe\", \"groceries\", or uploads food image\n   **FILE HANDLING**: Images are handled automatically when uploaded\n   \n5. plan_tasks(user_id, tasks_text)\n   - Organize & prioritize to-do lists\n   - Use when user says: \"tasks:\", \"to do\", \"organize\"\n   \n6. get_nutrition_advice(user_id, goal)\n   - Dietary guidance for specific goals (stress, energy, sleep, weight, focus)\n   - Use when user asks: \"what should I eat\", \"nutrition for\", \"food for\"\n   \n7. summarize_content(user_id, text=None, url=None, pdf_path=None, output_format=\"all\")\n   - Summarize PDF, URL, or text with quiz & key findings\n   - Use when user says: \"summarize\", or provides URL/file path\n   **FILE HANDLING**: Document paths are handled automatically when uploaded\n\nğŸ¯ ROUTING LOGIC:\n- Emotional words â†’ analyze_mood\n- \"stressed\", \"break\", \"game\" â†’ play_stress_game\n- \"analyze:\", \"you always\" OR audio file â†’ analyze_interpersonal\n- \"meal plan:\", ingredients OR food image â†’ plan_meals\n- \"tasks:\" â†’ plan_tasks\n- \"what should I eat\" â†’ get_nutrition_advice\n- \"summarize\", URL/path OR document file â†’ summarize_content\n\nğŸ’™ ERROR HANDLING (CRITICAL):\n- If any tool returns status=\"error\", respond with empathy:\n  \"I'm sorry, I had trouble processing that [file/request]. [Suggest alternative]\"\n- NEVER show technical error details to users\n- Always offer alternatives (e.g., \"You can also try typing the information directly\")\n- Stay positive and supportive even when errors occur\n- Common issues: file format problems, file size limits, unclear audio\n\nğŸ’™ PERSONALITY:\n- Warm, empathetic, and supportive\n- Always use user's name when available\n- Celebrate progress with points/streaks\n- Provide encouragement\n- End responses mentioning earned points\n\nğŸš¨ URGENT PRIORITY:\nIf stress_level > 8 or user says \"overwhelmed\"/\"can't take it\", immediately offer play_stress_game.\n\nRemember: You're a supportive friend focused on wellness, not a therapist. Always encourage professional help for serious concerns. When things go wrong, reassure the user and help them find another way.\"\"\"\n\n# Create ADK Agent\nmindmate_agent = Agent(\n    name=\"mindmate\",\n    model=\"gemini-2.5-flash\",\n    description=\"MindMate AI - Your wellness companion with mood tracking, stress relief, meal planning, task organization, and more\",\n    instruction=SYSTEM_INSTRUCTION,\n    tools=ALL_TOOLS\n)\n\nprint(\"âœ… MindMate ADK Agent created\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T13:18:24.291560Z","iopub.execute_input":"2025-11-24T13:18:24.292023Z","iopub.status.idle":"2025-11-24T13:18:24.311898Z","shell.execute_reply.started":"2025-11-24T13:18:24.291992Z","shell.execute_reply":"2025-11-24T13:18:24.310811Z"}},"outputs":[{"name":"stdout","text":"âœ… MindMate ADK Agent created\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# ============================================================================\n# CELL 13: CREATE RUNNER & SESSION SERVICE\n# ============================================================================\n\nsession_service = InMemorySessionService()\nrunner = InMemoryRunner(agent=mindmate_agent, app_name=\"mindmate\")\n\nprint(\"âœ… ADK Runner ready\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T13:18:24.313060Z","iopub.execute_input":"2025-11-24T13:18:24.313342Z","iopub.status.idle":"2025-11-24T13:18:24.333283Z","shell.execute_reply.started":"2025-11-24T13:18:24.313321Z","shell.execute_reply":"2025-11-24T13:18:24.332529Z"}},"outputs":[{"name":"stdout","text":"âœ… ADK Runner ready\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"\n# ============================================================================\n# CELL 14: TESTING FUNCTIONS\n# ============================================================================\n\nasync def test_agent(message: str, user_id: str = \"test_user\", user_name: str = \"Alex\"):\n    \"\"\"Quick test function for the agent.\"\"\"\n    print(f\"\\n{'='*60}\")\n    print(f\"ğŸ“ Input: {message}\")\n    print(f\"{'='*60}\")\n    \n    # Create session\n    session = await session_service.create_session(\n        app_name=\"mindmate\",\n        user_id=user_id\n    )\n    \n    # Run agent\n    response = await runner.run(\n        user_id=user_id,\n        session_id=session.id,\n        new_message=message\n    )\n    \n    # Extract response\n    if hasattr(response, 'content'):\n        result = response.content\n    elif isinstance(response, list) and response:\n        result = response[-1]\n    else:\n        result = response\n    \n    print(f\"\\nğŸ¤– Response:\\n{result}\")\n    print(f\"{'='*60}\\n\")\n    return result\n\n\nasync def run_all_tests():\n    \"\"\"Run comprehensive tests on all agents.\"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"ğŸ§ª RUNNING COMPREHENSIVE TESTS\")\n    print(\"=\"*70)\n    \n    tests = [\n        (\"Mood Agent\", \"I'm feeling really anxious about my presentation tomorrow\"),\n        (\"Stress Buster\", \"I need a mental break, give me a game\"),\n        (\"Interpersonal Coach\", \"Analyze: You always ignore my suggestions in meetings\"),\n        (\"Meal Planner\", \"Meal plan: chicken, rice, broccoli, eggs, spinach\"),\n        (\"Task Planner\", \"Tasks: finish quarterly report, call 3 clients, workout, review budget, send team update\"),\n        (\"Nutrition Advisor\", \"What should I eat to reduce my stress levels?\"),\n        (\"Summarizer\", \"Summarize: Meditation has been scientifically proven to reduce stress by up to 30%. Research shows regular practice improves focus, emotional regulation, and overall well-being. Studies with over 10000 participants demonstrate significant benefits.\")\n    ]\n    \n    results = {}\n    for name, message in tests:\n        print(f\"\\n[TEST] {name}\")\n        try:\n            result = await test_agent(message, f\"test_{name.lower().replace(' ', '_')}\")\n            results[name] = \"âœ… PASS\"\n        except Exception as e:\n            results[name] = f\"âŒ FAIL: {e}\"\n            logger.error(f\"Test {name} failed: {e}\")\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"ğŸ“Š TEST RESULTS\")\n    print(\"=\"*70)\n    for name, status in results.items():\n        print(f\"  {name}: {status}\")\n    \n    passed = sum(1 for s in results.values() if \"PASS\" in s)\n    print(f\"\\nâœ… {passed}/{len(results)} tests passed\")\n    return results\n\nprint(\"âœ… Test functions ready\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T13:18:24.334192Z","iopub.execute_input":"2025-11-24T13:18:24.334475Z","iopub.status.idle":"2025-11-24T13:18:24.358529Z","shell.execute_reply.started":"2025-11-24T13:18:24.334456Z","shell.execute_reply":"2025-11-24T13:18:24.357771Z"}},"outputs":[{"name":"stdout","text":"âœ… Test functions ready\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# ============================================================================\n# CELL 15: DIRECT FUNCTION TESTS (Without ADK)\n# ============================================================================\n\ndef test_direct_functions():\n    \"\"\"Test all agent functions directly.\"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"ğŸ”§ DIRECT FUNCTION TESTS\")\n    print(\"=\"*70)\n    \n    test_user = \"direct_test\"\n    \n    print(\"\\n[1] Mood Agent\")\n    result = analyze_mood(test_user, \"I'm feeling stressed about deadlines\", 7)\n    print(f\"   âœ“ Score: {result['mood_score']}/10, Emotion: {result['emotion']}, Assessment: {result['assessment']}\")\n    \n    print(\"\\n[2] Stress Buster\")\n    result = play_stress_game(test_user, \"riddle\")\n    print(f\"   âœ“ Game: {result['game_type']}, Streak: {result['stats']['streak']}, Total: {result['stats']['total_games']}\")\n    \n    print(\"\\n[3] Interpersonal Coach\")\n    result = analyze_interpersonal(test_user, \"You never listen to what I say!\", relationship=\"partner\")\n    print(f\"   âœ“ Style: {result['analysis']['style']}, Overall: {result['analysis']['scores']['overall']}\")\n    \n    print(\"\\n[4] Meal Planner\")\n    result = plan_meals(test_user, \"chicken, rice, broccoli, eggs\", days=3)\n    print(f\"   âœ“ Status: {result['status']}, Days: {result['days_planned']}, Recipes: {len(result['recipes'])}\")\n    \n    print(\"\\n[5] Task Planner\")\n    result = plan_tasks(test_user, \"finish report, call client, workout, send emails\")\n    print(f\"   âœ“ Tasks: {result['summary']['total_tasks']}, Time: {result['summary']['total_time']}\")\n    \n    print(\"\\n[6] Nutrition Advisor\")\n    result = get_nutrition_advice(test_user, \"I need more energy during the day\")\n    print(f\"   âœ“ Goal: {result['goal']}, Foods: {len(result['recommended_foods'])}\")\n    \n    print(\"\\n[7] Summarizer\")\n    result = summarize_content(test_user, text=\"Artificial intelligence is transforming healthcare through machine learning algorithms that can detect diseases earlier than human doctors. Recent studies show AI can identify certain cancers with 95% accuracy. This technology is revolutionizing medical diagnostics and treatment planning.\")\n    # FIX: word_count is now in metadata\n    print(f\"   âœ“ Status: {result['status']}, Word Count: {result.get('metadata', {}).get('word_count', 0)}, Quiz Questions: {len(result.get('quiz', []))}\")\n    \n    print(\"\\nâœ… All direct function tests complete!\")\n\n\ndef test_document_processing():\n    \"\"\"Test document processing with error handling.\"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"ğŸ“„ DOCUMENT PROCESSING TEST\")\n    print(\"=\"*70)\n    \n    # Test 1: Text summarization\n    print(\"\\n[1] Text Summarization\")\n    test_text = \"\"\"\n    Artificial intelligence is revolutionizing healthcare. Machine learning algorithms \n    can now detect diseases earlier than human doctors. Recent studies show AI can \n    identify certain cancers with 95% accuracy. This technology is transforming medical \n    diagnostics and treatment planning. Doctors can now provide more personalized care.\n    \"\"\"\n    result = summarize_content(\"test_doc\", text=test_text)\n    print(f\"   âœ“ Status: {result.get('status')}\")\n    print(f\"   âœ“ Summary: {result.get('summary', 'N/A')[:100]}...\")\n    print(f\"   âœ“ Key Points: {len(result.get('key_points', []))}\")\n    print(f\"   âœ“ Quiz Questions: {len(result.get('quiz', []))}\")\n    print(f\"   âœ“ Reading Time: {result.get('metadata', {}).get('reading_time', 'N/A')}\")\n    print(f\"   âœ“ Sentiment: {result.get('metadata', {}).get('sentiment', 'N/A')}\")\n    print(f\"   âœ“ Difficulty: {result.get('metadata', {}).get('difficulty', 'N/A')}\")\n    \n    # Test 2: URL summarization\n    print(\"\\n[2] URL Summarization\")\n    try:\n        result = summarize_content(\"test_doc\", url=\"https://www.wikipedia.org\")\n        print(f\"   âœ“ Status: {result.get('status')}\")\n        print(f\"   âœ“ Word Count: {result.get('metadata', {}).get('word_count', 0)}\")\n    except Exception as e:\n        print(f\"   âš ï¸ URL test skipped: {e}\")\n    \n    print(\"\\nâœ… Document processing tests complete!\")\n\n\n# Call both test functions\ntest_direct_functions()\ntest_document_processing()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T13:18:24.359706Z","iopub.execute_input":"2025-11-24T13:18:24.360397Z","iopub.status.idle":"2025-11-24T13:18:49.250698Z","shell.execute_reply.started":"2025-11-24T13:18:24.360371Z","shell.execute_reply":"2025-11-24T13:18:49.249964Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nğŸ”§ DIRECT FUNCTION TESTS\n======================================================================\n\n[1] Mood Agent\n   âœ“ Score: 2/10, Emotion: anxious, Assessment: needs_immediate_support\n\n[2] Stress Buster\n   âœ“ Game: riddle, Streak: 1, Total: 1\n\n[3] Interpersonal Coach\n   âœ“ Style: âš ï¸ SOMEWHAT AGGRESSIVE, Overall: 6/10\n\n[4] Meal Planner\n   âœ“ Status: complete, Days: 3, Recipes: 2\n\n[5] Task Planner\n   âœ“ Tasks: 4, Time: 2h 0m\n\n[6] Nutrition Advisor\n   âœ“ Goal: Energy Boost, Foods: 6\n\n[7] Summarizer\n   âœ“ Status: complete, Word Count: 37, Quiz Questions: 2\n\nâœ… All direct function tests complete!\n\n======================================================================\nğŸ“„ DOCUMENT PROCESSING TEST\n======================================================================\n\n[1] Text Summarization\n   âœ“ Status: complete\n   âœ“ Summary: Artificial intelligence (AI) is profoundly transforming the healthcare sector. Machine learning algo...\n   âœ“ Key Points: 5\n   âœ“ Quiz Questions: 2\n   âœ“ Reading Time: 1 min\n   âœ“ Sentiment: positive\n   âœ“ Difficulty: easy\n\n[2] URL Summarization\n   âœ“ Status: complete\n   âœ“ Word Count: 212\n\nâœ… Document processing tests complete!\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# ============================================================================\n# CELL 16: SIMPLE CHAT INTERFACE\n# ============================================================================\n\nasync def chat(message: str, user_name: str = \"Friend\", stress_level: int = 5):\n    \"\"\"\n    Simple chat interface for MindMate.\n    \n    Usage:\n        await chat(\"I need a break\")\n        await chat(\"Meal plan: chicken, rice, broccoli\", \"Sarah\")\n    \"\"\"\n    user_id = f\"chat_{user_name.lower().replace(' ', '_')}\"\n    user = get_user(user_id, user_name)\n    \n    print(f\"\\n{get_greeting(user_id)}\")\n    print(f\"ğŸ“ You: {message}\\n\")\n    \n    # Create session\n    session = await session_service.create_session(app_name=\"mindmate\", user_id=user_id)\n    \n    # Run through ADK\n    response = await runner.run(user_id=user_id, session_id=session.id, new_message=message)\n    \n    # Extract response\n    if hasattr(response, 'content'):\n        result = response.content\n    elif isinstance(response, list) and response:\n        result = response[-1]\n    else:\n        result = str(response)\n    \n    print(f\"ğŸ¤– MindMate:\\n{result}\\n\")\n    print(f\"{'â”€'*40}\")\n    print(f\"ğŸ“Š Your stats: {user.total_points} points | {len(user.badges)} badges\")\n    \n    if user.badges:\n        print(f\"ğŸ† Badges: {', '.join(user.badges[-3:])}\")\n    \n    return result\n\nprint(\"âœ… Chat interface ready\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T13:18:49.251710Z","iopub.execute_input":"2025-11-24T13:18:49.252049Z","iopub.status.idle":"2025-11-24T13:18:49.260314Z","shell.execute_reply.started":"2025-11-24T13:18:49.252021Z","shell.execute_reply":"2025-11-24T13:18:49.259452Z"}},"outputs":[{"name":"stdout","text":"âœ… Chat interface ready\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"\n# ============================================================================\n# CELL 17: FILE UPLOAD WIDGETS\n# ============================================================================\n\ndef setup_image_upload():\n    \"\"\"Setup image upload widget for meal planning.\"\"\"\n    try:\n        from ipywidgets import FileUpload, Button, Output, VBox\n        from IPython.display import display\n        \n        upload = FileUpload(accept='image/*', multiple=False, description='Upload Food Image')\n        process_btn = Button(description='ğŸ“¸ Analyze Image', button_style='success')\n        output = Output()\n        \n        def process_image(btn):\n            with output:\n                output.clear_output()\n                if not upload.value:\n                    print(\"âš ï¸ Please upload an image first\")\n                    return\n                \n                file_info = list(upload.value.values())[0]\n                content = file_info['content']\n                \n                # Save temporarily\n                temp_path = \"/tmp/uploaded_food.jpg\"\n                with open(temp_path, 'wb') as f:\n                    f.write(content)\n                \n                print(\"ğŸ”„ Analyzing image...\")\n                result = plan_meals(\"widget_user\", image_path=temp_path, days=3)\n                \n                if result.get('status') == 'complete':\n                    print(f\"\\n{result.get('image_analysis', '')}\")\n                    print(f\"\\nğŸ“‹ MEAL PLANS:\")\n                    for plan in result.get('meal_plans', []):\n                        print(f\"\\n  {plan['day']}:\")\n                        for meal_type, dish in plan.get('meals', {}).items():\n                            print(f\"    â€¢ {meal_type}: {dish['dish']}\")\n                    print(f\"\\nğŸ† Points earned: {result['stats']['points_earned']}\")\n                else:\n                    print(result.get('message', 'Analysis failed'))\n        \n        process_btn.on_click(process_image)\n        display(VBox([upload, process_btn, output]))\n        return upload\n        \n    except ImportError:\n        print(\"âš ï¸ ipywidgets not available. Use direct function:\")\n        print(\"   plan_meals('user', image_path='/path/to/image.jpg')\")\n        return None\n\ndef setup_audio_upload():\n    \"\"\"Setup audio upload widget for communication analysis.\"\"\"\n    try:\n        from ipywidgets import FileUpload, Button, Output, VBox\n        from IPython.display import display\n        \n        upload = FileUpload(accept='audio/*', multiple=False, description='Upload Audio')\n        process_btn = Button(description='ğŸ¤ Analyze Audio', button_style='info')\n        output = Output()\n        \n        def process_audio(btn):\n            with output:\n                output.clear_output()\n                if not upload.value:\n                    print(\"âš ï¸ Please upload an audio file first\")\n                    return\n                \n                file_info = list(upload.value.values())[0]\n                content = file_info['content']\n                \n                # Save temporarily\n                temp_path = \"/tmp/uploaded_audio.wav\"\n                with open(temp_path, 'wb') as f:\n                    f.write(content)\n                \n                print(\"ğŸ”„ Transcribing and analyzing...\")\n                result = analyze_interpersonal(\"widget_user\", audio_path=temp_path)\n                \n                if result.get('status') == 'analyzed':\n                    print(f\"\\nğŸ“ Transcript: {result['original_message']}\")\n                    print(f\"\\nğŸ¤ ANALYSIS:\")\n                    print(f\"   Style: {result['analysis']['style']}\")\n                    print(f\"   Overall Score: {result['analysis']['scores']['overall']}\")\n                    if result.get('coaching'):\n                        print(f\"\\nğŸ’¡ COACHING:\")\n                        for tip in result['coaching'][:3]:\n                            print(f\"   {tip}\")\n                else:\n                    print(result.get('message', 'Analysis failed'))\n        \n        process_btn.on_click(process_audio)\n        display(VBox([upload, process_btn, output]))\n        return upload\n        \n    except ImportError:\n        print(\"âš ï¸ ipywidgets not available. Use direct function:\")\n        print(\"   analyze_interpersonal('user', audio_path='/path/to/audio.wav')\")\n        return None\n\ndef setup_document_upload():\n    \"\"\"Setup document upload widget for summarization (PDF only).\"\"\"\n    try:\n        from ipywidgets import FileUpload, Dropdown, Button, Output, VBox, HBox\n        from IPython.display import display\n        \n        upload = FileUpload(accept='.pdf,.txt', multiple=False, description='Upload Document')\n        format_dropdown = Dropdown(options=['all', 'summary', 'quiz', 'findings'], value='all', description='Output:')\n        process_btn = Button(description='ğŸ“„ Summarize', button_style='primary')\n        output = Output()\n        \n        def process_doc(btn):\n            with output:\n                output.clear_output()\n                if not upload.value:\n                    print(\"âš ï¸ Please upload a document first\")\n                    return\n                \n                import os\n                file_info = list(upload.value.values())[0]\n                filename = file_info['metadata']['name']\n                content = file_info['content']\n                ext = os.path.splitext(filename)[1].lower()\n                \n                # Save temporarily\n                temp_path = f\"/tmp/upload_{filename}\"\n                with open(temp_path, 'wb') as f:\n                    f.write(content)\n                \n                print(f\"ğŸ”„ Processing {filename}...\")\n                \n                # Call appropriate summarizer\n                kwargs = {\"user_id\": \"widget_user\", \"output_format\": format_dropdown.value}\n                if ext == '.pdf':\n                    kwargs[\"pdf_path\"] = temp_path\n                elif ext == '.txt':\n                    with open(temp_path, 'r') as f:\n                        kwargs[\"text\"] = f.read()\n                else:\n                    print(f\"âŒ Unsupported file type: {ext}. Supported: PDF, TXT\")\n                    return\n                \n                result = summarize_content(**kwargs)\n                \n                if result.get('status') == 'complete':\n                    print(f\"\\nğŸ“Š SUMMARY RESULTS\")\n                    print(f\"   Source: {result['source_type'].upper()}\")\n                    print(f\"   Words: {result['metadata']['word_count']}\")\n                    if result.get('summary'):\n                        print(f\"\\nğŸ“‹ SUMMARY:\\n   {result['summary']}\")\n                    if result.get('key_points'):\n                        print(f\"\\nğŸ”‘ KEY POINTS:\")\n                        for i, pt in enumerate(result['key_points'][:5], 1):\n                            print(f\"   {i}. {pt}\")\n                    if result.get('quiz'):\n                        print(f\"\\nâ“ QUIZ: {len(result['quiz'])} questions generated\")\n                else:\n                    print(result.get('message', 'Processing failed'))\n        \n        process_btn.on_click(process_doc)\n        display(VBox([HBox([upload, format_dropdown]), process_btn, output]))\n        return upload\n        \n    except ImportError:\n        print(\"âš ï¸ ipywidgets not available. Use direct functions instead.\")\n        return None\n\nprint(\"File upload widgets ready\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T13:18:49.261438Z","iopub.execute_input":"2025-11-24T13:18:49.261719Z","iopub.status.idle":"2025-11-24T13:18:49.290147Z","shell.execute_reply.started":"2025-11-24T13:18:49.261699Z","shell.execute_reply":"2025-11-24T13:18:49.289285Z"}},"outputs":[{"name":"stdout","text":"File upload widgets ready\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"\n# ============================================================================\n# CELL 19: SYSTEM STATUS & METRICS\n# ============================================================================\n\ndef get_system_status():\n    \"\"\"Get complete system status.\"\"\"\n    return {\n        \"status\": \"ğŸŸ¢ OPERATIONAL\",\n        \"version\": \"1.0 Final\",\n        \"agents\": {\n            \"1\": \"Mood Agent - Emotional support\",\n            \"2\": \"Stress Buster - Fun games\",\n            \"3\": \"Interpersonal Coach - Text + Audio analysis\",\n            \"4\": \"Meal Planner - Recipes + Image detection\",\n            \"5\": \"Task Planner - Organization\",\n            \"6\": \"Nutrition Advisor - Dietary guidance\",\n            \"7\": \"Summarizer - Text/URL/PDF only\"\n        },\n        \"features\": {\n            \"mood_tracking\": \"âœ… Emotion history & trends\",\n            \"stress_relief\": \"âœ… Immediate game triggers\",\n            \"communication_coaching\": \"âœ… Text + Audio file analysis\",\n            \"meal_planning\": \"âœ… Text ingredients + Image detection\",\n            \"task_management\": \"âœ… Priority & time estimates\",\n            \"nutrition_guidance\": \"âœ… Goal-based advice\",\n            \"content_summarization\": \"âœ… Text, URL, PDF\"\n        },\n        \"metrics\": {\n            \"total_users\": len(user_journeys),\n            \"total_requests\": metrics.get(\"total_requests\", 0),\n            \"mood_analyses\": metrics.get(\"mood_analyses\", 0),\n            \"games_played\": metrics.get(\"games_played\", 0),\n            \"communication_analyses\": metrics.get(\"communication_analyses\", 0),\n            \"meal_plans\": metrics.get(\"meal_plans\", 0),\n            \"tasks_planned\": metrics.get(\"tasks_planned\", 0),\n            \"nutrition_advice\": metrics.get(\"nutrition_advice\", 0),\n            \"summaries\": metrics.get(\"summaries\", 0)\n        },\n        \"gamification\": {\n            \"total_points_awarded\": sum(u.total_points for u in user_journeys.values()),\n            \"total_badges\": sum(len(u.badges) for u in user_journeys.values())\n        }\n    }\n\ndef display_status():\n    \"\"\"Display system status in formatted output.\"\"\"\n    status = get_system_status()\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"ğŸ“Š MINDMATE AI - SYSTEM STATUS\")\n    print(\"=\"*70)\n    print(f\"\\nğŸŸ¢ Status: {status['status']}\")\n    print(f\"ğŸ“¦ Version: {status['version']}\")\n    print(f\"ğŸ‘¥ Total Users: {status['metrics']['total_users']}\")\n    \n    print(f\"\\nğŸ¤– AGENTS ({len(status['agents'])}):\")\n    for num, desc in status['agents'].items():\n        print(f\"   {num}. {desc}\")\n    \n    print(f\"\\nğŸ“ˆ USAGE METRICS:\")\n    for metric, count in status['metrics'].items():\n        if metric != 'total_users':\n            print(f\"   {metric.replace('_', ' ').title()}: {count}\")\n    \n    print(f\"\\nğŸ® GAMIFICATION:\")\n    print(f\"   Total Points Awarded: {status['gamification']['total_points_awarded']}\")\n    print(f\"   Total Badges Earned: {status['gamification']['total_badges']}\")\n    \n    print(\"\\n\" + \"=\"*70)\n\ndisplay_status()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T13:18:49.291120Z","iopub.execute_input":"2025-11-24T13:18:49.291898Z","iopub.status.idle":"2025-11-24T13:18:49.314203Z","shell.execute_reply.started":"2025-11-24T13:18:49.291869Z","shell.execute_reply":"2025-11-24T13:18:49.313434Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nğŸ“Š MINDMATE AI - SYSTEM STATUS\n======================================================================\n\nğŸŸ¢ Status: ğŸŸ¢ OPERATIONAL\nğŸ“¦ Version: 1.0 Final\nğŸ‘¥ Total Users: 2\n\nğŸ¤– AGENTS (7):\n   1. Mood Agent - Emotional support\n   2. Stress Buster - Fun games\n   3. Interpersonal Coach - Text + Audio analysis\n   4. Meal Planner - Recipes + Image detection\n   5. Task Planner - Organization\n   6. Nutrition Advisor - Dietary guidance\n   7. Summarizer - Text/URL/PDF only\n\nğŸ“ˆ USAGE METRICS:\n   Total Requests: 0\n   Mood Analyses: 1\n   Games Played: 1\n   Communication Analyses: 1\n   Meal Plans: 1\n   Tasks Planned: 1\n   Nutrition Advice: 1\n   Summaries: 3\n\nğŸ® GAMIFICATION:\n   Total Points Awarded: 170\n   Total Badges Earned: 0\n\n======================================================================\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":" analyze_interpersonal(\"user1\", \"You never listen to me\", relationship=\"partner\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T13:27:40.051328Z","iopub.execute_input":"2025-11-24T13:27:40.051687Z","iopub.status.idle":"2025-11-24T13:27:40.059266Z","shell.execute_reply.started":"2025-11-24T13:27:40.051662Z","shell.execute_reply":"2025-11-24T13:27:40.058495Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"{'status': 'analyzed',\n 'original_message': 'You never listen to me',\n 'transcribed_from_audio': False,\n 'analysis': {'style': 'âš ï¸ SOMEWHAT AGGRESSIVE',\n  'scores': {'tone': '5/10',\n   'clarity': '10/10',\n   'confidence': '6/10',\n   'empathy': '5/10',\n   'overall': '6/10'},\n  'issues': [\"âŒ Absolute blame ('you never')\"],\n  'strengths': [],\n  'filler_words': []},\n 'coaching': [\"1ï¸âƒ£ Friend, replace 'You always/never' with 'When [situation]...'\",\n  '2ï¸âƒ£ Pause 3 seconds before responding when upset',\n  \"3ï¸âƒ£ Focus on behavior, not the person's character\",\n  \"4ï¸âƒ£ Use format: 'I feel [emotion] when [situation] because [reason]'\"],\n 'rewritten_message': \"when this doesn't happen, I feel listen to me\",\n 'relationship_tip': 'ğŸ’• With your partner: Choose calm moments, avoid discussing issues when tired.',\n 'stats': {'streak': 1, 'points_earned': 15, 'total_points': 15},\n 'correction_example': \"\\nâŒ Original: 'You never listen to me'\\nâœ… Try: 'when this doesn't happen, I feel listen to me'\"}"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":" play_stress_game(\"user1\", \"brain teaser\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T13:27:46.211223Z","iopub.execute_input":"2025-11-24T13:27:46.211514Z","iopub.status.idle":"2025-11-24T13:27:46.217617Z","shell.execute_reply.started":"2025-11-24T13:27:46.211493Z","shell.execute_reply":"2025-11-24T13:27:46.216762Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"{'game_type': 'pattern',\n 'question': 'ğŸ”¢ What comes next? 2, 4, 8, 16, ?',\n 'answer': '32 (each number doubles)',\n 'hint': None,\n 'options': [],\n 'fun_fact': None,\n 'stats': {'streak': 1,\n  'total_games': 1,\n  'points_earned': 10,\n  'total_points': 25},\n 'message': 'ğŸ¯ Game #1! Take a brain break, Friend! ğŸ§ âœ¨'}"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"plan_meals(\"user1\", \"chicken, cheese, mushroom\", days=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T13:27:48.851056Z","iopub.execute_input":"2025-11-24T13:27:48.851364Z","iopub.status.idle":"2025-11-24T13:27:48.859417Z","shell.execute_reply.started":"2025-11-24T13:27:48.851342Z","shell.execute_reply":"2025-11-24T13:27:48.858527Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"{'status': 'complete',\n 'ingredients_found': ['cheese', 'mushroom', 'chicken'],\n 'categories': {'proteins': ['chicken'],\n  'vegetables': ['mushroom'],\n  'dairy': ['cheese']},\n 'meal_plans': [{'day': 'Day 1',\n   'meals': {'breakfast': {'dish': 'Greek yogurt with granola',\n     'time': '5 min',\n     'calories': '250-350'},\n    'lunch': {'dish': 'Grilled chicken salad with mushroom',\n     'time': '20 min',\n     'calories': '400-500'},\n    'dinner': {'dish': 'Chicken stir-fry with rice and mushroom',\n     'time': '30 min',\n     'calories': '500-600'}}},\n  {'day': 'Day 2',\n   'meals': {'breakfast': {'dish': 'Greek yogurt with granola',\n     'time': '5 min',\n     'calories': '250-350'},\n    'lunch': {'dish': 'Grilled chicken salad with mushroom',\n     'time': '20 min',\n     'calories': '400-500'},\n    'dinner': {'dish': 'Chicken stir-fry with rice and mushroom',\n     'time': '30 min',\n     'calories': '500-600'}}},\n  {'day': 'Day 3',\n   'meals': {'breakfast': {'dish': 'Greek yogurt with granola',\n     'time': '5 min',\n     'calories': '250-350'},\n    'lunch': {'dish': 'Grilled chicken salad with mushroom',\n     'time': '20 min',\n     'calories': '400-500'},\n    'dinner': {'dish': 'Chicken stir-fry with rice and mushroom',\n     'time': '30 min',\n     'calories': '500-600'}}},\n  {'day': 'Day 4',\n   'meals': {'breakfast': {'dish': 'Greek yogurt with granola',\n     'time': '5 min',\n     'calories': '250-350'},\n    'lunch': {'dish': 'Grilled chicken salad with mushroom',\n     'time': '20 min',\n     'calories': '400-500'},\n    'dinner': {'dish': 'Chicken stir-fry with rice and mushroom',\n     'time': '30 min',\n     'calories': '500-600'}}},\n  {'day': 'Day 5',\n   'meals': {'breakfast': {'dish': 'Greek yogurt with granola',\n     'time': '5 min',\n     'calories': '250-350'},\n    'lunch': {'dish': 'Grilled chicken salad with mushroom',\n     'time': '20 min',\n     'calories': '400-500'},\n    'dinner': {'dish': 'Chicken stir-fry with rice and mushroom',\n     'time': '30 min',\n     'calories': '500-600'}}}],\n 'recipes': [{'name': 'ğŸ— Quick Chicken Stir-Fry',\n   'time': '25 min',\n   'servings': 4,\n   'ingredients': ['2 chicken breasts, cubed',\n    '2 cups mushroom',\n    '1 cup rice',\n    '2 tbsp oil, 2 cloves garlic, 3 tbsp soy sauce'],\n   'steps': ['1ï¸âƒ£ Cook rice/carbs according to package',\n    '2ï¸âƒ£ Heat oil in wok over high heat',\n    '3ï¸âƒ£ Add chicken, cook 6-8 min until golden',\n    '4ï¸âƒ£ Add garlic and vegetables, stir 4-5 min',\n    '5ï¸âƒ£ Add soy sauce, toss and serve over rice']}],\n 'days_planned': 5,\n 'shopping_suggestions': ['carbs (rice, pasta, bread)'],\n 'image_analysis': None,\n 'stats': {'streak': 1, 'points_earned': 25, 'total_points': 50}}"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"\"\"\"\nDEPLOYMENT UTILITIES\n- Generate ADK Web UI URL for Kaggle\n- Export deployment configuration\n\"\"\"\ndef get_adk_proxy_url():\n    \"\"\"Generate ADK Web UI URL for Kaggle\"\"\"\n    try:\n        from IPython.core.display import display, HTML\n        from jupyter_server.serverapp import list_running_servers\n        \n        PROXY_HOST = \"https://kkb-production.jupyter-proxy.kaggle.net\"\n        ADK_PORT = \"8000\"\n        \n        servers = list(list_running_servers())\n        if not servers:\n            print(\"âš ï¸ No Jupyter servers found\")\n            return None\n        \n        baseURL = servers[0]['base_url']\n        path_parts = baseURL.split('/')\n        kernel = path_parts[2]\n        token = path_parts[3]\n        \n        url_prefix = f\"/k/{kernel}/{token}/proxy/proxy/{ADK_PORT}\"\n        url = f\"{PROXY_HOST}{url_prefix}\"\n        \n        html = f\"\"\"\n        <div style=\"padding: 25px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); \n                    border-radius: 15px; box-shadow: 0 10px 25px rgba(0,0,0,0.2); margin: 25px 0;\">\n            <div style=\"color: white; font-size: 1.5em; font-weight: bold; margin-bottom: 15px;\">\n                ğŸ§  Mindmate AI - Launch Web Interface\n            </div>\n            <div style=\"color: #f0f0f0; margin-bottom: 20px; line-height: 1.8; font-size: 1.1em;\">\n                âœ… All 11 requirements met<br>\n                âœ… Personal & non-generic<br>\n                âœ… Stable & crash-proof<br>\n                âœ… Clean observability\n            </div>\n            <a href='{url}' target='_blank' style=\"\n                display: inline-block; background: white; color: #667eea; \n                padding: 15px 35px; text-decoration: none; border-radius: 30px; \n                font-weight: bold; font-size: 1.1em;\n                box-shadow: 0 5px 15px rgba(0,0,0,0.3);\">\n                Launch Web UI â†—\n            </a>\n        </div>\n        \"\"\"\n        display(HTML(html))\n        return url_prefix\n        \n    except Exception as e:\n        logger.error(f\"URL generation error: {e}\")\n        print(\"âš ï¸ Run in Kaggle notebook for Web UI access\")\n        return None\n\nprint(\"âœ… Deployment utilities ready\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T13:27:55.395668Z","iopub.execute_input":"2025-11-24T13:27:55.396246Z","iopub.status.idle":"2025-11-24T13:27:55.404233Z","shell.execute_reply.started":"2025-11-24T13:27:55.396220Z","shell.execute_reply":"2025-11-24T13:27:55.403384Z"}},"outputs":[{"name":"stdout","text":"âœ… Deployment utilities ready\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"\"\"\"\nDEPLOYMENT STEP 1: Create ADK Project\nRun this cell to create the ADK project structure\n\"\"\"\n\n!adk create mindmateAI --model gemini-2.5-flash --api_key $GOOGLE_API_KEY\n\nprint(\"\\nâœ… ADK project created\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T13:28:01.855596Z","iopub.execute_input":"2025-11-24T13:28:01.855893Z","iopub.status.idle":"2025-11-24T13:28:24.617960Z","shell.execute_reply.started":"2025-11-24T13:28:01.855872Z","shell.execute_reply":"2025-11-24T13:28:24.617016Z"}},"outputs":[{"name":"stdout","text":"\u001b[32m\nAgent created in /kaggle/working/mindmateAI:\n- .env\n- __init__.py\n- agent.py\n\u001b[0m\n\nâœ… ADK project created\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"\"\"\"\nDEPLOYMENT STEP 2: Launch ADK Web UI\nRun this cell to start the web interface\n\"\"\"\nurl_prefix = get_adk_proxy_url()\n\n# Launch web server\n!adk web --url_prefix {url_prefix}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T13:28:27.900678Z","iopub.execute_input":"2025-11-24T13:28:27.901026Z","iopub.status.idle":"2025-11-24T13:59:08.725062Z","shell.execute_reply.started":"2025-11-24T13:28:27.900995Z","shell.execute_reply":"2025-11-24T13:59:08.724017Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n        <div style=\"padding: 25px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); \n                    border-radius: 15px; box-shadow: 0 10px 25px rgba(0,0,0,0.2); margin: 25px 0;\">\n            <div style=\"color: white; font-size: 1.5em; font-weight: bold; margin-bottom: 15px;\">\n                ğŸ§  Mindmate AI - Launch Web Interface\n            </div>\n            <div style=\"color: #f0f0f0; margin-bottom: 20px; line-height: 1.8; font-size: 1.1em;\">\n                âœ… All 11 requirements met<br>\n                âœ… Personal & non-generic<br>\n                âœ… Stable & crash-proof<br>\n                âœ… Clean observability\n            </div>\n            <a href='https://kkb-production.jupyter-proxy.kaggle.net/k/281436134/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2IiwidHlwIjoiSldUIn0..mx_HPJ0ll8412pd_Bpr1VA.-XVG9ay-bEjKEhoZxdGo335-wXyhIo9Y7iBK_9g18RkjDnTnI19Q5oTR9bymiOxSb8guRC8XhzX802QBt7eVbufiKwKNe2CmTc_BsTx6PjZvIvuaGvxYoyUz2piLzsZ-GuLeZiCHxsmNJqULJCcO4CZzjFxTAJE0w9D-RWoYy_C6Y-JuzaQ9UQLJS2KsRMOfxY6MVuRLk2hXfPrtcENEMZgTClWTn1Z5lUmJBuInLX-61G5LWJxcyIMcjz321El8.l_Dd8_49wx1UXsHYfLTIAw/proxy/proxy/8000' target='_blank' style=\"\n                display: inline-block; background: white; color: #667eea; \n                padding: 15px 35px; text-decoration: none; border-radius: 30px; \n                font-weight: bold; font-size: 1.1em;\n                box-shadow: 0 5px 15px rgba(0,0,0,0.3);\">\n                Launch Web UI â†—\n            </a>\n        </div>\n        "},"metadata":{}},{"name":"stdout","text":"/usr/local/lib/python3.11/dist-packages/google/adk/cli/fast_api.py:130: UserWarning: [EXPERIMENTAL] InMemoryCredentialService: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n  credential_service = InMemoryCredentialService()\n/usr/local/lib/python3.11/dist-packages/google/adk/auth/credential_service/in_memory_credential_service.py:33: UserWarning: [EXPERIMENTAL] BaseCredentialService: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n  super().__init__()\n\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m138\u001b[0m]\n\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n\u001b[32m\n+-----------------------------------------------------------------------------+\n| ADK Web Server started                                                      |\n|                                                                             |\n| For local testing, access at http://127.0.0.1:8000.                         |\n+-----------------------------------------------------------------------------+\n\u001b[0m\n\u001b[32mINFO\u001b[0m:     Application startup complete.\n\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://127.0.0.1:8000\u001b[0m (Press CTRL+C to quit)\n\u001b[32mINFO\u001b[0m:     35.191.59.127:0 - \"\u001b[1mGET / HTTP/1.1\u001b[0m\" \u001b[33m307 Temporary Redirect\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.125:0 - \"\u001b[1mGET /dev-ui/ HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.124:0 - \"\u001b[1mGET /dev-ui/styles-EVMPSV3U.css HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.126:0 - \"\u001b[1mGET /dev-ui/polyfills-B6TNHZQ6.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.127:0 - \"\u001b[1mGET /dev-ui/chunk-2WH2EVR6.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.125:0 - \"\u001b[1mGET /dev-ui/main-OS2OH2S3.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.127:0 - \"\u001b[1mGET /dev-ui/assets/config/runtime-config.json HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.124:0 - \"\u001b[1mGET /dev-ui/adk_favicon.svg HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.126:0 - \"\u001b[1mGET /list-apps?relative_path=./ HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.125:0 - \"\u001b[1mGET /dev-ui/assets/ADK-512-color.svg HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.cli.adk_web_server:New session created: ea02a4ab-4981-4776-a4be-18f2e3a95938\n\u001b[32mINFO\u001b[0m:     35.191.59.124:0 - \"\u001b[1mPOST /apps/mindmateAI/users/user/sessions HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.126:0 - \"\u001b[1mGET /builder/app/mindmateAI?ts=1763991026832 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.127:0 - \"\u001b[1mGET /apps/mindmateAI/users/user/sessions HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.125:0 - \"\u001b[1mGET /apps/mindmateAI/users/user/sessions/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.124:0 - \"\u001b[1mGET /debug/trace/session/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.127:0 - \"\u001b[1mGET /apps/mindmateAI/eval_sets HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.126:0 - \"\u001b[1mGET /apps/mindmateAI/eval_results HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.125:0 - \"\u001b[1mGET /apps/mindmateAI/users/user/sessions HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'appName' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'appName' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'appName' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'userId' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'userId' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'userId' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'sessionId' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'sessionId' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'sessionId' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'newMessage' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'newMessage' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'newMessage' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'streaming' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'streaming' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'streaming' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'stateDelta' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'stateDelta' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'stateDelta' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'invocationId' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'invocationId' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'invocationId' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n\u001b[32mINFO\u001b[0m:     35.191.59.127:0 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.cli.utils.agent_loader:Found root_agent in mindmateAI.agent\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\n\u001b[32mINFO\u001b[0m:     35.191.59.126:0 - \"\u001b[1mGET /apps/mindmateAI/users/user/sessions/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.127:0 - \"\u001b[1mGET /debug/trace/session/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.127:0 - \"\u001b[1mGET /debug/trace/session/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.127:0 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\n\u001b[32mINFO\u001b[0m:     35.191.59.126:0 - \"\u001b[1mGET /apps/mindmateAI/users/user/sessions/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.127:0 - \"\u001b[1mGET /debug/trace/session/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.125:0 - \"\u001b[1mGET /debug/trace/session/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.94:0 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\n\u001b[32mINFO\u001b[0m:     35.191.59.93:0 - \"\u001b[1mGET /debug/trace/session/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.95:0 - \"\u001b[1mGET /apps/mindmateAI/users/user/sessions/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.92:0 - \"\u001b[1mGET /debug/trace/session/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.71.33:0 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\n\u001b[32mINFO\u001b[0m:     35.191.71.35:0 - \"\u001b[1mGET /apps/mindmateAI/users/user/sessions/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.71.33:0 - \"\u001b[1mGET /debug/trace/session/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.71.33:0 - \"\u001b[1mGET /debug/trace/session/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.71.24:0 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\n\u001b[32mINFO\u001b[0m:     35.191.71.25:0 - \"\u001b[1mGET /apps/mindmateAI/users/user/sessions/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.71.27:0 - \"\u001b[1mGET /debug/trace/session/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.71.26:0 - \"\u001b[1mGET /debug/trace/session/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.78:0 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\n\u001b[32mINFO\u001b[0m:     35.191.112.128:0 - \"\u001b[1mGET /apps/mindmateAI/users/user/sessions/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.112.129:0 - \"\u001b[1mGET /debug/trace/session/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.112.129:0 - \"\u001b[1mGET /debug/trace/session/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.78:0 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\n\u001b[32mINFO\u001b[0m:     35.191.71.30:0 - \"\u001b[1mGET /debug/trace/session/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.71.31:0 - \"\u001b[1mGET /apps/mindmateAI/users/user/sessions/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.71.28:0 - \"\u001b[1mGET /debug/trace/session/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.71.31:0 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\n\u001b[32mINFO\u001b[0m:     35.191.71.30:0 - \"\u001b[1mGET /apps/mindmateAI/users/user/sessions/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.71.28:0 - \"\u001b[1mGET /debug/trace/session/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.71.30:0 - \"\u001b[1mGET /debug/trace/session/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.79:0 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\n\u001b[32mINFO\u001b[0m:     35.191.59.110:0 - \"\u001b[1mGET /apps/mindmateAI/users/user/sessions/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.109:0 - \"\u001b[1mGET /debug/trace/session/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.108:0 - \"\u001b[1mGET /debug/trace/session/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.110:0 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\n\u001b[32mINFO\u001b[0m:     35.191.59.108:0 - \"\u001b[1mGET /apps/mindmateAI/users/user/sessions/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.109:0 - \"\u001b[1mGET /debug/trace/session/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.111:0 - \"\u001b[1mGET /debug/trace/session/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.76:0 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\n\u001b[32mINFO\u001b[0m:     35.191.112.108:0 - \"\u001b[1mGET /apps/mindmateAI/users/user/sessions/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.112.109:0 - \"\u001b[1mGET /debug/trace/session/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.112.110:0 - \"\u001b[1mGET /debug/trace/session/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.112.111:0 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\n\u001b[32mINFO\u001b[0m:     35.191.112.108:0 - \"\u001b[1mGET /debug/trace/session/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.112.110:0 - \"\u001b[1mGET /apps/mindmateAI/users/user/sessions/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.112.110:0 - \"\u001b[1mGET /debug/trace/session/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.76:0 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\n\u001b[32mINFO\u001b[0m:     35.191.59.76:0 - \"\u001b[1mGET /apps/mindmateAI/users/user/sessions/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.79:0 - \"\u001b[1mGET /debug/trace/session/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.76:0 - \"\u001b[1mGET /debug/trace/session/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.78:0 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\n\u001b[32mINFO\u001b[0m:     35.191.59.79:0 - \"\u001b[1mGET /apps/mindmateAI/users/user/sessions/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.76:0 - \"\u001b[1mGET /debug/trace/session/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.79:0 - \"\u001b[1mGET /debug/trace/session/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.79:0 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\n\u001b[32mINFO\u001b[0m:     35.191.59.79:0 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.evaluation.local_eval_sets_manager:Creating eval set file `/kaggle/working/mindmateAI/evalset285594.evalset.json`\nINFO:google_adk.google.adk.evaluation.local_eval_sets_manager:Eval set file doesn't exist, we will create a new one.\n\u001b[32mINFO\u001b[0m:     35.191.59.77:0 - \"\u001b[1mPOST /apps/mindmateAI/eval_sets/evalset285594 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.76:0 - \"\u001b[1mGET /apps/mindmateAI/eval_sets HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\n\u001b[32mINFO\u001b[0m:     35.191.59.78:0 - \"\u001b[1mGET /apps/mindmateAI/users/user/sessions/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.79:0 - \"\u001b[1mGET /debug/trace/session/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.76:0 - \"\u001b[1mGET /apps/mindmateAI/eval_sets/evalset285594/evals HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.78:0 - \"\u001b[1mGET /apps/mindmateAI/users/user/sessions/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\n\u001b[32mINFO\u001b[0m:     35.191.59.76:0 - \"\u001b[1mGET /debug/trace/session/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.77:0 - \"\u001b[1mGET /debug/trace/session/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.78:0 - \"\u001b[1mGET /apps/mindmateAI/users/user/sessions/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.79:0 - \"\u001b[1mGET /debug/trace/session/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'evalId' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'evalId' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'evalId' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'sessionId' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'sessionId' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'sessionId' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'userId' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'userId' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'userId' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n\u001b[32mINFO\u001b[0m:     35.191.59.78:0 - \"\u001b[1mPOST /apps/mindmateAI/eval_sets/evalset285594/add_session HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.79:0 - \"\u001b[1mPOST /apps/mindmateAI/eval_sets/evalset285594/add_session HTTP/1.1\u001b[0m\" \u001b[31m400 Bad Request\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.77:0 - \"\u001b[1mGET /apps/mindmateAI/eval_sets/evalset285594/evals HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.78:0 - \"\u001b[1mGET /debug/trace/session/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'evalIds' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'evalIds' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'evalIds' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'deprecated' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'deprecated' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'evalCaseIds' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'evalCaseIds' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'evalCaseIds' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'evalMetrics' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'evalMetrics' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'evalMetrics' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/google/adk/evaluation/metric_evaluator_registry.py:90: UserWarning: [EXPERIMENTAL] MetricEvaluatorRegistry: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n  metric_evaluator_registry = MetricEvaluatorRegistry()\n/usr/local/lib/python3.11/dist-packages/google/adk/evaluation/local_eval_service.py:79: UserWarning: [EXPERIMENTAL] UserSimulatorProvider: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n  user_simulator_provider: UserSimulatorProvider = UserSimulatorProvider(),\n/usr/local/lib/python3.11/dist-packages/google/adk/cli/adk_web_server.py:1123: UserWarning: [EXPERIMENTAL] LocalEvalService: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n  eval_service = LocalEvalService(\n/usr/local/lib/python3.11/dist-packages/google/adk/evaluation/user_simulator_provider.py:77: UserWarning: [EXPERIMENTAL] StaticUserSimulator: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n  return StaticUserSimulator(static_conversation=eval_case.conversation)\n/usr/local/lib/python3.11/dist-packages/google/adk/evaluation/static_user_simulator.py:39: UserWarning: [EXPERIMENTAL] UserSimulator: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n  super().__init__(\nINFO:google_adk.google.adk.plugins.plugin_manager:Plugin 'request_intercepter_plugin' registered.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\n\u001b[32mINFO\u001b[0m:     35.191.59.79:0 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\n\u001b[32mINFO\u001b[0m:     35.191.59.78:0 - \"\u001b[1mGET /debug/trace/session/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.76:0 - \"\u001b[1mGET /apps/mindmateAI/users/user/sessions/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\n\u001b[32mINFO\u001b[0m:     35.191.59.76:0 - \"\u001b[1mGET /debug/trace/session/ea02a4ab-4981-4776-a4be-18f2e3a95938 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nINFO:google_adk.google.adk.evaluation.local_eval_set_results_manager:Writing eval result to file: /kaggle/working/mindmateAI/.adk/eval_history/mindmateAI_evalset285594_1763992234.7048655.evalset_result.json\n\u001b[32mINFO\u001b[0m:     35.191.59.78:0 - \"\u001b[1mPOST /apps/mindmateAI/eval_sets/evalset285594/run_eval HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.77:0 - \"\u001b[1mGET /apps/mindmateAI/eval_results HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.70.246:0 - \"\u001b[1mGET /apps/mindmateAI/eval_results/mindmateAI_evalset285594_1763992234.7048655 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.70.246:0 - \"\u001b[1mGET /apps/mindmateAI/users/user/sessions/___eval___session___85b8cddb-05d8-4d51-9db1-7c86e84de564 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.70.247:0 - \"\u001b[1mGET /apps/mindmateAI/users/user/sessions/___eval___session___85b8cddb-05d8-4d51-9db1-7c86e84de564 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.70.245:0 - \"\u001b[1mGET /debug/trace/session/___eval___session___85b8cddb-05d8-4d51-9db1-7c86e84de564 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.70.247:0 - \"\u001b[1mGET /debug/trace/session/___eval___session___85b8cddb-05d8-4d51-9db1-7c86e84de564 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.79:0 - \"\u001b[1mGET /apps/mindmateAI/users/user/sessions/___eval___session___85b8cddb-05d8-4d51-9db1-7c86e84de564 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.71.9:0 - \"\u001b[1mGET /debug/trace/session/___eval___session___85b8cddb-05d8-4d51-9db1-7c86e84de564 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.71.9:0 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\n\u001b[32mINFO\u001b[0m:     35.191.71.11:0 - \"\u001b[1mGET /apps/mindmateAI/users/user/sessions/___eval___session___85b8cddb-05d8-4d51-9db1-7c86e84de564 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.71.10:0 - \"\u001b[1mGET /debug/trace/session/___eval___session___85b8cddb-05d8-4d51-9db1-7c86e84de564 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.71.8:0 - \"\u001b[1mGET /debug/trace/session/___eval___session___85b8cddb-05d8-4d51-9db1-7c86e84de564 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.76:0 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\n\u001b[32mINFO\u001b[0m:     35.191.59.79:0 - \"\u001b[1mGET /debug/trace/session/___eval___session___85b8cddb-05d8-4d51-9db1-7c86e84de564 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.78:0 - \"\u001b[1mGET /apps/mindmateAI/users/user/sessions/___eval___session___85b8cddb-05d8-4d51-9db1-7c86e84de564 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.79:0 - \"\u001b[1mGET /debug/trace/session/___eval___session___85b8cddb-05d8-4d51-9db1-7c86e84de564 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.78:0 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\n\u001b[32mINFO\u001b[0m:     35.191.59.79:0 - \"\u001b[1mGET /debug/trace/session/___eval___session___85b8cddb-05d8-4d51-9db1-7c86e84de564 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.77:0 - \"\u001b[1mGET /apps/mindmateAI/users/user/sessions/___eval___session___85b8cddb-05d8-4d51-9db1-7c86e84de564 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.77:0 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\n\u001b[32mINFO\u001b[0m:     35.191.59.79:0 - \"\u001b[1mGET /debug/trace/session/___eval___session___85b8cddb-05d8-4d51-9db1-7c86e84de564 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.78:0 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\n\u001b[32mINFO\u001b[0m:     35.191.59.77:0 - \"\u001b[1mGET /apps/mindmateAI/users/user/sessions/___eval___session___85b8cddb-05d8-4d51-9db1-7c86e84de564 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.79:0 - \"\u001b[1mGET /debug/trace/session/___eval___session___85b8cddb-05d8-4d51-9db1-7c86e84de564 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.77:0 - \"\u001b[1mGET /debug/trace/session/___eval___session___85b8cddb-05d8-4d51-9db1-7c86e84de564 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\n\u001b[32mINFO\u001b[0m:     35.191.59.76:0 - \"\u001b[1mGET /apps/mindmateAI/users/user/sessions/___eval___session___85b8cddb-05d8-4d51-9db1-7c86e84de564 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.77:0 - \"\u001b[1mGET /debug/trace/session/___eval___session___85b8cddb-05d8-4d51-9db1-7c86e84de564 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.59.76:0 - \"\u001b[1mGET /debug/trace/session/___eval___session___85b8cddb-05d8-4d51-9db1-7c86e84de564 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n^C\n\u001b[32mINFO\u001b[0m:     Shutting down\n\u001b[32mINFO\u001b[0m:     Waiting for application shutdown.\n\u001b[32m\n+-----------------------------------------------------------------------------+\n| ADK Web Server shutting down...                                             |\n+-----------------------------------------------------------------------------+\n\u001b[0m\n\u001b[32mINFO\u001b[0m:     Application shutdown complete.\n\u001b[32mINFO\u001b[0m:     Finished server process [\u001b[36m138\u001b[0m]\n\nAborted!\n","output_type":"stream"}],"execution_count":26}]}