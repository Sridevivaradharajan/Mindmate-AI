{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 1. Install audio tools (Quietly)\n!apt-get install -y -qq ffmpeg\n\n# 2. Install Python libraries (Quietly)\n!pip install -qq google-adk google-generativeai Pillow requests beautifulsoup4 PyPDF2 python-docx nbformat SpeechRecognition pydub librosa soundfile","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# CELL 2: IMPORTS & SETUP\n# ============================================================================\n\nimport os\nimport asyncio\nimport json\nimport logging\nimport time\nimport re\nimport traceback \nimport base64\nimport io\nfrom collections import deque, defaultdict\nfrom dataclasses import dataclass, field\nfrom typing import List, Dict, Any, Optional\nfrom datetime import datetime\n\n# Image processing\nfrom PIL import Image\n\n# Audio processing\nimport speech_recognition as sr\n\n# Document processing\nimport requests\nfrom bs4 import BeautifulSoup\nimport PyPDF2\n\n# Google AI\nimport google.generativeai as genai\n\n# ADK imports\nfrom google.adk.agents import Agent\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.sessions import InMemorySessionService\nfrom google.adk.tools import FunctionTool\n\nprint(\"‚úÖ All imports loaded\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"FALSE\"\n    \n    genai.configure(api_key=GOOGLE_API_KEY)\n    \n    print(\"‚úÖ Gemini API key setup complete.\")\nexcept Exception as e:\n    print(f\"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n    handlers=[logging.StreamHandler()]\n)\nlogger = logging.getLogger(\"Mindmate\")\n\n# ============================================================================\n# FILE VALIDATION UTILITY (NEW - ADD THIS)\n# ============================================================================\n\ndef safe_file_read(file_path: str, expected_extensions: list = None) -> Dict:\n    \"\"\"\n    Safely validate and read file with comprehensive error handling.\n    \n    Returns: {\"status\": \"success/error\", \"path\": str, \"error\": str}\n    \"\"\"\n    try:\n        # Check if path exists\n        if not file_path or not os.path.exists(file_path):\n            return {\n                \"status\": \"error\",\n                \"error\": f\"File not found: {file_path}\",\n                \"path\": None\n            }\n        \n        # Check if it's a file\n        if not os.path.isfile(file_path):\n            return {\n                \"status\": \"error\", \n                \"error\": f\"Path is not a file: {file_path}\",\n                \"path\": None\n            }\n        \n        # Check extension if specified\n        if expected_extensions:\n            ext = os.path.splitext(file_path)[1].lower()\n            if ext not in expected_extensions:\n                return {\n                    \"status\": \"error\",\n                    \"error\": f\"Invalid file type {ext}. Expected: {expected_extensions}\",\n                    \"path\": None\n                }\n        \n        # Check file size (limit to 50MB)\n        size = os.path.getsize(file_path)\n        if size > 50 * 1024 * 1024:\n            return {\n                \"status\": \"error\",\n                \"error\": f\"File too large: {size / (1024*1024):.1f}MB (max 50MB)\",\n                \"path\": None\n            }\n        \n        if size == 0:\n            return {\n                \"status\": \"error\",\n                \"error\": \"File is empty\",\n                \"path\": None\n            }\n        \n        return {\"status\": \"success\", \"path\": file_path, \"error\": None}\n        \n    except Exception as e:\n        return {\n            \"status\": \"error\",\n            \"error\": f\"File validation error: {str(e)}\",\n            \"path\": None\n        }\n\nprint(\"‚úÖ File validation utility ready\")\n\n# Metrics\nmetrics = defaultdict(int)\nlatencies = defaultdict(list)\n\ndef metric_inc(name: str, amt: int = 1):\n    metrics[name] += amt\n\ndef metric_time(name: str, duration: float):\n    latencies[name].append(duration)\n\nprint(\"‚úÖ Setup complete\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# CELL 3: USER DATA STRUCTURES\n# ============================================================================\n\n@dataclass\nclass UserJourney:\n    \"\"\"Tracks user's complete journey through MindMate.\"\"\"\n    user_id: str\n    name: str\n    created_at: float = field(default_factory=time.time)\n    emotion_history: List[Dict] = field(default_factory=list)\n    stress_history: List[int] = field(default_factory=list)\n    streaks: Dict[str, int] = field(default_factory=lambda: {\n        \"nutrition\": 0, \"tasks\": 0, \"games\": 0, \n        \"meditation\": 0, \"communication\": 0\n    })\n    badges: List[str] = field(default_factory=list)\n    total_points: int = 0\n    last_interaction: float = 0.0\n    game_scores: Dict = field(default_factory=dict)\n    communication_history: List[Dict] = field(default_factory=list)\n    meal_preferences: Dict = field(default_factory=dict)\n\n@dataclass  \nclass ConversationContext:\n    \"\"\"Tracks conversation context for MCP.\"\"\"\n    user_id: str\n    session_id: str\n    history: List[Dict] = field(default_factory=list)\n    emotional_state: Dict = field(default_factory=dict)\n    recent_topics: List[str] = field(default_factory=list)\n    last_agent: str = \"\"\n\n# Global stores\nuser_journeys: Dict[str, UserJourney] = {}\nconversation_contexts: Dict[str, ConversationContext] = {}\n\ndef get_user(user_id: str, name: str = \"Friend\") -> UserJourney:\n    \"\"\"Get or create user journey.\"\"\"\n    if user_id not in user_journeys:\n        user_journeys[user_id] = UserJourney(user_id=user_id, name=name)\n        metric_inc(\"new_users\")\n        logger.info(f\"New user created: {user_id}\")\n    return user_journeys[user_id]\n\ndef get_context(user_id: str, session_id: str = \"default\") -> ConversationContext:\n    \"\"\"Get or create conversation context.\"\"\"\n    key = f\"{user_id}_{session_id}\"\n    if key not in conversation_contexts:\n        conversation_contexts[key] = ConversationContext(user_id=user_id, session_id=session_id)\n    return conversation_contexts[key]\n\ndef get_greeting(user_id: str) -> str:\n    \"\"\"Generate personalized greeting.\"\"\"\n    user = get_user(user_id)\n    hour = datetime.now().hour\n    \n    if hour < 12:\n        time_greet = \"Good morning\"\n    elif hour < 17:\n        time_greet = \"Good afternoon\"\n    else:\n        time_greet = \"Good evening\"\n    \n    # Check if returning user\n    if user.last_interaction > 0:\n        time_since = time.time() - user.last_interaction\n        if time_since > 86400:  # More than a day\n            greeting = f\"{time_greet}, {user.name}! Welcome back üíô\"\n        else:\n            greeting = f\"{time_greet}, {user.name}!\"\n    else:\n        greeting = f\"{time_greet}, {user.name}! I'm MindMate, your wellness companion üíô\"\n    \n    user.last_interaction = time.time()\n    return greeting\n\nprint(\"‚úÖ User data structures ready\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# ============================================================================\n# CELL 4: AGENT 1 - MOOD AGENT\n# ============================================================================\n\ndef analyze_mood(user_id: str, message: str, stress_level: int = 5) -> Dict:\n    \"\"\"\n    Analyze user's emotional state and provide personalized support.\n    \n    Parameters:\n    - user_id: User identifier\n    - message: User's message expressing how they feel\n    - stress_level: Self-reported stress (1-10)\n    \n    Returns: Mood analysis with coping strategies\n    \"\"\"\n    start = time.time()\n    user = get_user(user_id)\n    lower = message.lower()\n    \n    # Emotion detection\n    emotion_map = {\n        \"distressed\": (2, [\"depressed\", \"hopeless\", \"terrible\", \"suicidal\", \"can't go on\"]),\n        \"anxious\": (3, [\"anxious\", \"stressed\", \"worried\", \"overwhelmed\", \"panic\"]),\n        \"sad\": (4, [\"sad\", \"down\", \"lonely\", \"upset\", \"disappointed\"]),\n        \"neutral\": (5, [\"okay\", \"meh\", \"alright\", \"so-so\"]),\n        \"stable\": (6, [\"fine\", \"decent\", \"not bad\"]),\n        \"positive\": (7, [\"good\", \"better\", \"nice\", \"pleased\"]),\n        \"very_positive\": (8, [\"great\", \"happy\", \"amazing\", \"wonderful\", \"fantastic\"]),\n        \"excellent\": (9, [\"excellent\", \"thrilled\", \"ecstatic\", \"best\"])\n    }\n    \n    score = 5\n    emotion = \"neutral\"\n    \n    for emo, (emo_score, keywords) in emotion_map.items():\n        if any(w in lower for w in keywords):\n            score = emo_score\n            emotion = emo\n            break\n    \n    # Adjust for stress level\n    score = max(1, min(10, score - (stress_level - 5) // 2))\n    \n    # Update user history\n    user.emotion_history.append({\n        \"timestamp\": time.time(),\n        \"emotion\": emotion,\n        \"score\": score,\n        \"stress\": stress_level\n    })\n    user.stress_history.append(stress_level)\n    \n    # Keep last 20 entries\n    if len(user.emotion_history) > 20:\n        user.emotion_history = user.emotion_history[-20:]\n    if len(user.stress_history) > 20:\n        user.stress_history = user.stress_history[-20:]\n    \n    # Generate coping strategy based on score\n    if score <= 2:\n        coping = f\"üíô {user.name}, I hear you're going through a really tough time. Please remember you're not alone. Consider reaching out to a mental health professional or crisis line. Would you like some grounding exercises?\"\n        assessment = \"needs_immediate_support\"\n    elif score <= 4:\n        coping = f\"üíô {user.name}, try this: 4-7-8 breathing - inhale 4 seconds, hold 7, exhale 8. Repeat 4 times. Would you like a stress relief game?\"\n        assessment = \"needs_support\"\n    elif score <= 6:\n        coping = f\"{user.name}, you're managing okay. A short walk or talking to someone you trust might help lift your mood.\"\n        assessment = \"stable\"\n    else:\n        coping = f\"Wonderful, {user.name}! Keep doing what's working for you. Gratitude journaling can help maintain this positive state.\"\n        assessment = \"thriving\"\n    \n    # Calculate trend\n    if len(user.emotion_history) >= 3:\n        recent_scores = [e[\"score\"] for e in user.emotion_history[-3:]]\n        if recent_scores[-1] > recent_scores[0]:\n            trend = \"improving üìà\"\n        elif recent_scores[-1] < recent_scores[0]:\n            trend = \"declining üìâ\"\n        else:\n            trend = \"stable ‚û°Ô∏è\"\n    else:\n        trend = \"not enough data\"\n    \n    # Award points\n    user.total_points += 5\n    metric_inc(\"mood_analyses\")\n    metric_time(\"mood_agent\", time.time() - start)\n    \n    return {\n        \"mood_score\": score,\n        \"emotion\": emotion,\n        \"stress_level\": stress_level,\n        \"assessment\": assessment,\n        \"coping_strategy\": coping,\n        \"trend\": trend,\n        \"points_earned\": 5,\n        \"total_points\": user.total_points,\n        \"greeting\": get_greeting(user_id)\n    }\n\nprint(\"‚úÖ Agent 1: Mood Agent ready\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# ============================================================================\n# CELL 5: AGENT 2 - STRESS BUSTER (GAMES)\n# ============================================================================\n\ndef play_stress_game(user_id: str, game_type: str = \"random\") -> Dict:\n    \"\"\"\n    Provide fun mental break games for stress relief.\n    \n    Parameters:\n    - user_id: User identifier\n    - game_type: \"riddle\", \"trivia\", \"brain_teaser\", \"pattern\", \"detective\", \"random\"\n    \n    Returns: Game content with question and answer\n    \"\"\"\n    import random\n    start = time.time()\n    user = get_user(user_id)\n    \n    games = {\n        \"riddle\": [\n            {\"q\": f\"ü§î {user.name}, I speak without a mouth and hear without ears. I have no body, but I come alive with the wind. What am I?\", \"a\": \"An ECHO! üîä\"},\n            {\"q\": f\"ü§î {user.name}, what has keys but no locks, space but no room, and you can enter but can't go inside?\", \"a\": \"A KEYBOARD! ‚å®Ô∏è\"},\n            {\"q\": \"ü§î The more you take, the more you leave behind. What am I?\", \"a\": \"FOOTSTEPS! üë£\"},\n            {\"q\": \"ü§î I have cities, but no houses live there. I have mountains, but no trees grow. I have water, but no fish swim. What am I?\", \"a\": \"A MAP! üó∫Ô∏è\"},\n            {\"q\": \"ü§î What can travel around the world while staying in a corner?\", \"a\": \"A STAMP! üìÆ\"},\n        ],\n        \"trivia\": [\n            {\"q\": \"üé¨ In Stranger Things, what tabletop game do the kids play?\", \"opts\": [\"A) Monopoly\", \"B) Dungeons & Dragons\", \"C) Risk\", \"D) Chess\"], \"a\": \"B) Dungeons & Dragons ‚úÖ\", \"fact\": \"The Duffer Brothers are huge D&D fans!\"},\n            {\"q\": \"üé¨ What is the highest-grossing film of all time (adjusted)?\", \"opts\": [\"A) Titanic\", \"B) Avatar\", \"C) Avengers: Endgame\", \"D) Gone with the Wind\"], \"a\": \"D) Gone with the Wind ‚úÖ\", \"fact\": \"When adjusted for inflation, it beats all modern films!\"},\n            {\"q\": \"üéµ Which artist has the most Grammy Awards?\", \"opts\": [\"A) Beyonc√©\", \"B) Taylor Swift\", \"C) Adele\", \"D) Stevie Wonder\"], \"a\": \"A) Beyonc√© ‚úÖ\", \"fact\": \"She has 32 Grammy Awards!\"},\n            {\"q\": \"üåç What is the smallest country in the world?\", \"opts\": [\"A) Monaco\", \"B) Vatican City\", \"C) San Marino\", \"D) Liechtenstein\"], \"a\": \"B) Vatican City ‚úÖ\", \"fact\": \"It's only 0.44 square kilometers!\"},\n        ],\n        \"brain_teaser\": [\n            {\"q\": f\"üß† {user.name}, a bus driver goes the wrong way down a one-way street, passes 10 police officers, but doesn't get a ticket. Why?\", \"a\": \"He was WALKING! üö∂\"},\n            {\"q\": \"üß† What can you hold in your right hand but never in your left hand?\", \"a\": \"Your LEFT HAND! ü§ö\"},\n            {\"q\": \"üß† A man lives on the 10th floor. Every day he takes the elevator down to go to work. When he returns, he takes the elevator to the 7th floor and walks up 3 flights. Why?\", \"a\": \"He's too SHORT to reach the 10th floor button! üìè\"},\n            {\"q\": \"üß† If you have me, you want to share me. If you share me, you no longer have me. What am I?\", \"a\": \"A SECRET! ü§´\"},\n        ],\n        \"pattern\": [\n            {\"q\": \"üî¢ What comes next? 2, 4, 8, 16, ?\", \"a\": \"32 (each number doubles)\"},\n            {\"q\": \"üî¢ What comes next? 1, 1, 2, 3, 5, 8, ?\", \"a\": \"13 (Fibonacci sequence - add previous two)\"},\n            {\"q\": \"üî¢ What comes next? 1, 4, 9, 16, 25, ?\", \"a\": \"36 (square numbers: 1¬≤, 2¬≤, 3¬≤...)\"},\n            {\"q\": \"üî¢ What comes next? A, C, F, J, ?\", \"a\": \"O (gaps increase: +2, +3, +4, +5)\"},\n        ],\n        \"detective\": [\n            {\"q\": f\"üîç {user.name}, a man is found dead in a locked room with only a puddle of water and broken glass. How did he die?\", \"hint\": \"Think about what was IN the glass...\", \"a\": \"üéØ He was a fish! The glass was his fishbowl that broke!\"},\n            {\"q\": \"üîç A woman shoots her husband, then holds him underwater for 5 minutes, then hangs him. Later, they go out for dinner. How?\", \"hint\": \"Think photography...\", \"a\": \"üéØ She's a PHOTOGRAPHER! She shot a photo, developed it in water, and hung it to dry!\"},\n        ]\n    }\n    \n    # Select game type\n    if game_type == \"random\" or game_type not in games:\n        # Avoid repeating recent games\n        recent = user.game_scores.get(\"recent_types\", [])\n        available = [t for t in games.keys() if t not in recent[-2:]]\n        game_type = random.choice(available if available else list(games.keys()))\n    \n    # Select random game from category\n    selected = random.choice(games[game_type])\n    \n    # Build response\n    result = {\n        \"game_type\": game_type,\n        \"question\": selected[\"q\"],\n        \"answer\": selected[\"a\"],\n        \"hint\": selected.get(\"hint\"),\n        \"options\": selected.get(\"opts\", []),\n        \"fun_fact\": selected.get(\"fact\"),\n    }\n    \n    # Update user stats\n    user.streaks[\"games\"] = user.streaks.get(\"games\", 0) + 1\n    user.total_points += 10\n    \n    if \"recent_types\" not in user.game_scores:\n        user.game_scores[\"recent_types\"] = []\n    user.game_scores[\"recent_types\"].append(game_type)\n    \n    total_played = user.game_scores.get(\"total_played\", 0) + 1\n    user.game_scores[\"total_played\"] = total_played\n    \n    # Award badges\n    if total_played == 5 and \"üéÆ Game Starter\" not in user.badges:\n        user.badges.append(\"üéÆ Game Starter\")\n        result[\"new_badge\"] = \"üéÆ Game Starter\"\n    elif total_played == 20 and \"üéÆüéÆ Game Master\" not in user.badges:\n        user.badges.append(\"üéÆüéÆ Game Master\")\n        result[\"new_badge\"] = \"üéÆüéÆ Game Master\"\n    elif total_played == 50 and \"üéÆüéÆüéÆ Game Legend\" not in user.badges:\n        user.badges.append(\"üéÆüéÆüéÆ Game Legend\")\n        result[\"new_badge\"] = \"üéÆüéÆüéÆ Game Legend\"\n    \n    result[\"stats\"] = {\n        \"streak\": user.streaks[\"games\"],\n        \"total_games\": total_played,\n        \"points_earned\": 10,\n        \"total_points\": user.total_points\n    }\n    result[\"message\"] = f\"üéØ Game #{total_played}! Take a brain break, {user.name}! üß†‚ú®\"\n    \n    metric_inc(\"games_played\")\n    metric_time(\"stress_buster\", time.time() - start)\n    \n    return result\n\nprint(\"‚úÖ Agent 2: Stress Buster ready\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# CELL 6: AGENT 3 - INTERPERSONAL COACH (Text + FULL Audio Analysis)\n# ============================================================================\n\ndef analyze_audio_features(audio_path: str) -> Dict:\n    \"\"\"\n    Analyze vocal characteristics: tone, pace, volume, clarity, pitch.\n    Uses librosa for advanced audio analysis.\n    \"\"\"\n    try:\n        import librosa\n        import numpy as np\n        \n        # Load audio\n        y, sr_rate = librosa.load(audio_path, sr=None)\n        duration = librosa.get_duration(y=y, sr=sr_rate)\n        \n        if duration < 0.5:\n            return {\"status\": \"error\", \"message\": \"Audio too short (min 0.5 seconds)\"}\n        \n        # 1. VOLUME/ENERGY ANALYSIS\n        rms = librosa.feature.rms(y=y)[0]\n        avg_volume = float(np.mean(rms))\n        volume_variation = float(np.std(rms))\n        \n        if avg_volume > 0.15:\n            volume_level = \"loud\"\n            volume_note = \"Speaking loudly - may come across as aggressive\"\n        elif avg_volume < 0.03:\n            volume_level = \"soft\"\n            volume_note = \"Speaking softly - may seem unconfident or passive\"\n        else:\n            volume_level = \"moderate\"\n            volume_note = \"Good volume - clear and audible\"\n        \n        volume_consistency = \"varied\" if volume_variation > 0.05 else \"steady\"\n        \n        # 2. SPEAKING PACE ANALYSIS\n        onset_frames = librosa.onset.onset_detect(y=y, sr=sr_rate, backtrack=False)\n        num_onsets = len(onset_frames)\n        pace_per_sec = num_onsets / duration if duration > 0 else 0\n        \n        if pace_per_sec > 4:\n            pace_level = \"fast\"\n            pace_note = \"Speaking quickly - may indicate nervousness or excitement\"\n        elif pace_per_sec < 2:\n            pace_level = \"slow\"\n            pace_note = \"Speaking slowly - sounds thoughtful but may lose attention\"\n        else:\n            pace_level = \"moderate\"\n            pace_note = \"Good speaking pace - easy to follow\"\n        \n        # 3. PITCH ANALYSIS\n        pitches, magnitudes = librosa.piptrack(y=y, sr=sr_rate)\n        pitch_values = pitches[magnitudes > np.median(magnitudes)]\n        \n        if len(pitch_values) > 0:\n            avg_pitch = float(np.mean(pitch_values))\n            pitch_variation = float(np.std(pitch_values))\n            \n            if avg_pitch > 220:\n                pitch_level = \"high\"\n                pitch_note = \"Higher pitch - may indicate stress or excitement\"\n            elif avg_pitch < 100:\n                pitch_level = \"low\"\n                pitch_note = \"Lower pitch - sounds calm and authoritative\"\n            else:\n                pitch_level = \"medium\"\n                pitch_note = \"Natural pitch range\"\n            \n            if pitch_variation > 50:\n                pitch_variety = \"expressive\"\n                pitch_variety_note = \"Good vocal variety - engaging to listen to\"\n            else:\n                pitch_variety = \"monotone\"\n                pitch_variety_note = \"Monotone delivery - may sound disengaged\"\n        else:\n            avg_pitch = 0\n            pitch_level = \"unclear\"\n            pitch_note = \"Could not analyze pitch\"\n            pitch_variety = \"unclear\"\n            pitch_variety_note = \"\"\n        \n        # 4. CLARITY ANALYSIS (based on zero-crossing rate)\n        zcr = librosa.feature.zero_crossing_rate(y)[0]\n        avg_zcr = float(np.mean(zcr))\n        \n        if avg_zcr > 0.15:\n            clarity_level = \"clear\"\n            clarity_note = \"Clear enunciation - easy to understand\"\n        elif avg_zcr < 0.05:\n            clarity_level = \"unclear\"\n            clarity_note = \"Mumbled or unclear speech - work on articulation\"\n        else:\n            clarity_level = \"moderate\"\n            clarity_note = \"Acceptable clarity - could improve enunciation\"\n        \n        # 5. PAUSES ANALYSIS (silence detection)\n        intervals = librosa.effects.split(y, top_db=30)\n        num_segments = len(intervals)\n        pause_count = num_segments - 1\n        avg_pause = (duration - sum((intervals[:, 1] - intervals[:, 0]) / sr_rate)) / max(pause_count, 1)\n        \n        if avg_pause > 1.5:\n            pause_level = \"many_long\"\n            pause_note = \"Long pauses - may indicate uncertainty or search for words\"\n        elif avg_pause > 0.5:\n            pause_level = \"natural\"\n            pause_note = \"Natural pausing - allows listener to process\"\n        else:\n            pause_level = \"few\"\n            pause_note = \"Few pauses - may sound rushed or nervous\"\n        \n        # 6. OVERALL CONFIDENCE SCORE (0-10)\n        confidence_score = 5  # baseline\n        \n        # Volume contributes\n        if volume_level == \"moderate\": confidence_score += 2\n        elif volume_level == \"loud\": confidence_score += 1\n        elif volume_level == \"soft\": confidence_score -= 2\n        \n        # Pace contributes\n        if pace_level == \"moderate\": confidence_score += 2\n        elif pace_level == \"fast\": confidence_score -= 1\n        elif pace_level == \"slow\": confidence_score -= 1\n        \n        # Pitch variety contributes\n        if pitch_variety == \"expressive\": confidence_score += 2\n        elif pitch_variety == \"monotone\": confidence_score -= 2\n        \n        # Clarity contributes\n        if clarity_level == \"clear\": confidence_score += 2\n        elif clarity_level == \"unclear\": confidence_score -= 2\n        \n        # Pauses contribute\n        if pause_level == \"natural\": confidence_score += 1\n        elif pause_level == \"many_long\": confidence_score -= 2\n        \n        confidence_score = max(1, min(10, confidence_score))\n        \n        # 7. EMOTIONAL TONE DETECTION (basic)\n        if avg_volume > 0.15 and pace_per_sec > 4:\n            emotional_tone = \"agitated/stressed\"\n        elif avg_volume < 0.05 and pitch_level == \"low\":\n            emotional_tone = \"calm/sad\"\n        elif pitch_variety == \"expressive\" and volume_level == \"moderate\":\n            emotional_tone = \"engaged/enthusiastic\"\n        elif pitch_variety == \"monotone\" and pace_level == \"slow\":\n            emotional_tone = \"bored/disengaged\"\n        else:\n            emotional_tone = \"neutral/controlled\"\n        \n        return {\n            \"status\": \"success\",\n            \"duration_seconds\": round(duration, 2),\n            \"volume\": {\n                \"level\": volume_level,\n                \"consistency\": volume_consistency,\n                \"note\": volume_note,\n                \"score\": 8 if volume_level == \"moderate\" else 5 if volume_level == \"loud\" else 4\n            },\n            \"pace\": {\n                \"level\": pace_level,\n                \"syllables_per_sec\": round(pace_per_sec, 2),\n                \"note\": pace_note,\n                \"score\": 8 if pace_level == \"moderate\" else 6\n            },\n            \"pitch\": {\n                \"level\": pitch_level,\n                \"variety\": pitch_variety,\n                \"note\": pitch_note,\n                \"variety_note\": pitch_variety_note,\n                \"score\": 8 if pitch_variety == \"expressive\" else 4\n            },\n            \"clarity\": {\n                \"level\": clarity_level,\n                \"note\": clarity_note,\n                \"score\": 9 if clarity_level == \"clear\" else 6 if clarity_level == \"moderate\" else 3\n            },\n            \"pauses\": {\n                \"level\": pause_level,\n                \"average_seconds\": round(avg_pause, 2),\n                \"note\": pause_note,\n                \"score\": 8 if pause_level == \"natural\" else 5\n            },\n            \"confidence_score\": confidence_score,\n            \"emotional_tone\": emotional_tone,\n            \"overall_score\": round((\n                (8 if volume_level == \"moderate\" else 5) +\n                (8 if pace_level == \"moderate\" else 6) +\n                (8 if pitch_variety == \"expressive\" else 4) +\n                (9 if clarity_level == \"clear\" else 6) +\n                (8 if pause_level == \"natural\" else 5)\n            ) / 5, 1)\n        }\n        \n    except ImportError:\n        return {\n            \"status\": \"limited\",\n            \"message\": \"librosa not available - only basic transcription provided\"\n        }\n    except Exception as e:\n        logger.error(f\"Audio feature analysis error: {e}\\n{traceback.format_exc()}\")\n        return {\n            \"status\": \"error\",\n            \"message\": f\"Could not analyze audio features: {str(e)}\"\n        }\n\n\ndef analyze_interpersonal(\n    user_id: str,\n    text: str = None,\n    audio_path: str = None,\n    relationship: str = \"colleague\"\n) -> Dict:\n    \"\"\"\n    Comprehensive interpersonal skills coach with FULL audio analysis.\n    Analyzes text OR audio (with transcription + vocal tone analysis).\n    \n    Parameters:\n    - user_id: User identifier\n    - text: Text to analyze (what user said or wants to say)\n    - audio_path: Path to audio file for FULL analysis (transcription + tone/pace/clarity)\n    - relationship: \"boss\", \"colleague\", \"partner\", \"family\", \"friend\"\n    \n    Returns: Communication analysis with coaching\n    \"\"\"\n    start = time.time()\n    user = get_user(user_id)\n    \n    # Audio analysis\n    transcript = None\n    audio_features = None\n    \n    if audio_path:\n        try:\n            # ============================================================\n            # CHANGE 1: Add file validation\n            # ============================================================\n            valid_audio_extensions = ['.wav', '.mp3', '.m4a', '.mp4', '.ogg', '.flac']\n            file_ext = os.path.splitext(audio_path)[1].lower()\n            \n            if file_ext not in valid_audio_extensions:\n                return {\n                    \"status\": \"error\",\n                    \"message\": f\"Unsupported audio format: {file_ext}. Please upload: WAV, MP3, M4A, MP4, OGG, or FLAC\"\n                }\n            \n            # Check if file exists and is readable\n            if not os.path.exists(audio_path):\n                return {\n                    \"status\": \"error\",\n                    \"message\": f\"Audio file not found: {audio_path}\"\n                }\n            \n            if os.path.getsize(audio_path) == 0:\n                return {\n                    \"status\": \"error\",\n                    \"message\": \"Audio file is empty. Please upload a valid audio recording.\"\n                }\n            \n            # File size limit (50MB)\n            if os.path.getsize(audio_path) > 50 * 1024 * 1024:\n                size_mb = os.path.getsize(audio_path) / (1024 * 1024)\n                return {\n                    \"status\": \"error\",\n                    \"message\": f\"Audio file too large ({size_mb:.1f}MB). Maximum size is 50MB.\"\n                }\n            \n            recognizer = sr.Recognizer()\n            \n            # ============================================================\n            # CHANGE 2: Improved audio conversion with better error handling\n            # ============================================================\n            if not audio_path.endswith('.wav'):\n                try:\n                    from pydub import AudioSegment\n                    import tempfile\n                    \n                    logger.info(f\"Converting audio file: {audio_path} ({file_ext})\")\n                    \n                    # Load audio file\n                    audio = AudioSegment.from_file(audio_path)\n                    \n                    # Create temporary wav file\n                    with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp:\n                        wav_path = tmp.name\n                    \n                    # Export to WAV format\n                    audio.export(wav_path, format=\"wav\")\n                    audio_path = wav_path\n                    \n                    logger.info(f\"Audio converted successfully to: {wav_path}\")\n                    \n                except Exception as e:\n                    logger.error(f\"Audio conversion failed: {e}\\n{traceback.format_exc()}\")\n                    \n                    # Provide helpful error message\n                    if \"ffmpeg\" in str(e).lower() or \"avconv\" in str(e).lower():\n                        return {\n                            \"status\": \"error\", \n                            \"message\": f\"Could not convert {file_ext} audio. FFmpeg is required for {file_ext} files. Please upload WAV format instead, or ensure FFmpeg is installed.\"\n                        }\n                    else:\n                        return {\n                            \"status\": \"error\", \n                            \"message\": f\"Audio conversion failed: {str(e)}. Please try uploading a WAV file instead, or type your message directly.\"\n                        }\n            \n            # ============================================================\n            # STEP 1: Transcribe speech to text\n            # ============================================================\n            try:\n                with sr.AudioFile(audio_path) as source:\n                    audio_data = recognizer.record(source)\n                    transcript = recognizer.recognize_google(audio_data)\n                    text = transcript\n                    logger.info(f\"Audio transcribed successfully: {len(text)} characters\")\n            except sr.UnknownValueError:\n                return {\n                    \"status\": \"error\", \n                    \"message\": \"Could not understand the audio. Please ensure: (1) Clear speech, (2) Minimal background noise, (3) Good microphone quality. Try recording again or type your message instead.\"\n                }\n            except sr.RequestError as e:\n                logger.error(f\"Speech recognition service error: {e}\")\n                return {\n                    \"status\": \"error\",\n                    \"message\": f\"Speech recognition service is temporarily unavailable. Please try again in a moment, or type your message instead.\"\n                }\n            \n            # ============================================================\n            # STEP 2: Analyze vocal features (tone, pace, clarity, etc.)\n            # ============================================================\n            audio_features = analyze_audio_features(audio_path)\n            \n            if audio_features.get(\"status\") == \"error\":\n                logger.warning(f\"Audio feature analysis failed: {audio_features.get('message')}\")\n                # Continue with just transcription, don't fail completely\n                audio_features = None\n            \n        except Exception as e:\n            logger.error(f\"Audio processing error: {e}\\n{traceback.format_exc()}\")\n            return {\n                \"status\": \"error\", \n                \"message\": f\"Audio processing failed. Please try uploading a WAV file or typing your message. Technical details: {str(e)}\"\n            }\n    \n    if not text:\n        return {\n            \"status\": \"needs_input\",\n            \"message\": f\"üé§ {user.name}, I can analyze your communication style!\",\n            \"features\": [\n                \"üìù TEXT: Analyze word choice, tone, assertiveness\",\n                \"üéôÔ∏è AUDIO: Analyze speech + volume + pace + clarity + pitch + confidence\"\n            ],\n            \"options\": [\n                \"Type: 'Analyze: [what you want to say]'\",\n                \"Upload audio file (WAV recommended, also supports MP3, M4A, MP4, OGG, FLAC)\"\n            ],\n            \"examples\": [\n                \"Analyze: You always ignore my suggestions\",\n                \"Analyze: I feel frustrated when meetings run late\"\n            ],\n            \"audio_tips\": \"üìå For best results with audio: Use WAV format, speak clearly, minimize background noise\"\n        }\n    \n    lower = text.lower()\n    \n    # Initialize analysis\n    analysis = {\n        \"style\": \"neutral\",\n        \"tone_score\": 6,\n        \"clarity_score\": 7,\n        \"confidence_score\": 6,\n        \"empathy_score\": 5,\n        \"issues\": [],\n        \"strengths\": [],\n        \"filler_words\": []\n    }\n    \n    # ========== PATTERN DETECTION ==========\n    \n    # Aggressive patterns\n    aggressive = {\n        r\"\\byou always\\b\": \"Absolute blame ('you always')\",\n        r\"\\byou never\\b\": \"Absolute blame ('you never')\",\n        r\"\\byou should\\b\": \"Commanding tone\",\n        r\"\\bwhy didn'?t you\\b\": \"Accusatory question\",\n        r\"\\bwhat'?s wrong with you\\b\": \"Personal attack\",\n        r\"\\byou need to\\b\": \"Demanding language\",\n        r\"\\byou'?re (being )?(stupid|lazy|useless)\\b\": \"Direct insult\",\n    }\n    \n    # Passive patterns\n    passive = {\n        r\"\\bmaybe we could\\b\": \"Overly tentative\",\n        r\"\\bi guess\\b\": \"Lacks confidence\",\n        r\"\\bsorry,? but\\b\": \"Unnecessary apologizing\",\n        r\"\\bif that'?s okay\\b\": \"Excessive permission-seeking\",\n        r\"\\bjust think\\b\": \"'Just' minimizes your opinion\",\n        r\"\\bi'?m no expert\\b\": \"Self-deprecating\",\n        r\"\\bkind of\\b|\\bsort of\\b\": \"Hedging language\",\n    }\n    \n    # Assertive patterns (positive!)\n    assertive = {\n        r\"\\bi feel\\b.*\\bwhen\\b\": \"‚úÖ Great 'I feel when' statement!\",\n        r\"\\bi think\\b\": \"‚úÖ Owning your opinion\",\n        r\"\\bi believe\\b\": \"‚úÖ Confident stance\",\n        r\"\\bi need\\b\": \"‚úÖ Clear need expression\",\n        r\"\\bi'?d like\\b\": \"‚úÖ Polite but direct\",\n        r\"\\blet'?s\\b\": \"‚úÖ Collaborative language\",\n        r\"\\bwhat do you think\\b\": \"‚úÖ Inviting dialogue\",\n    }\n    \n    # Empathetic patterns (positive!)\n    empathetic = {\n        r\"\\bi understand\\b\": \"üíô Shows understanding\",\n        r\"\\bi hear you\\b\": \"üíô Active listening\",\n        r\"\\bthat must be\\b\": \"üíô Emotional validation\",\n        r\"\\bhow do you feel\\b\": \"üíô Checking emotions\",\n        r\"\\bi appreciate\\b\": \"üíô Showing gratitude\",\n    }\n    \n    # Count patterns\n    aggressive_count = 0\n    passive_count = 0\n    assertive_count = 0\n    empathetic_count = 0\n    \n    for pattern, desc in aggressive.items():\n        if re.search(pattern, lower):\n            analysis[\"issues\"].append(f\"‚ùå {desc}\")\n            aggressive_count += 1\n    \n    for pattern, desc in passive.items():\n        if re.search(pattern, lower):\n            analysis[\"issues\"].append(f\"‚ö†Ô∏è {desc}\")\n            passive_count += 1\n    \n    for pattern, desc in assertive.items():\n        if re.search(pattern, lower):\n            analysis[\"strengths\"].append(desc)\n            assertive_count += 1\n    \n    for pattern, desc in empathetic.items():\n        if re.search(pattern, lower):\n            analysis[\"strengths\"].append(desc)\n            empathetic_count += 1\n    \n    # Check filler words in TEXT\n    fillers = [\"um\", \"uh\", \"like\", \"you know\", \"basically\", \"literally\", \"actually\", \"honestly\"]\n    found_fillers = [f for f in fillers if f\" {f} \" in f\" {lower} \"]\n    analysis[\"filler_words\"] = found_fillers\n    \n    # Determine style and scores\n    if aggressive_count >= 2:\n        analysis[\"style\"] = \"‚ùå AGGRESSIVE\"\n        analysis[\"tone_score\"] = 3\n        analysis[\"confidence_score\"] = 7\n        analysis[\"empathy_score\"] = 2\n    elif aggressive_count == 1:\n        analysis[\"style\"] = \"‚ö†Ô∏è SOMEWHAT AGGRESSIVE\"\n        analysis[\"tone_score\"] = 5\n    elif passive_count >= 2:\n        analysis[\"style\"] = \"‚ö†Ô∏è PASSIVE\"\n        analysis[\"tone_score\"] = 5\n        analysis[\"confidence_score\"] = 3\n    elif assertive_count >= 2 and empathetic_count >= 1:\n        analysis[\"style\"] = \"‚úÖ ASSERTIVE & EMPATHETIC (Ideal!)\"\n        analysis[\"tone_score\"] = 9\n        analysis[\"confidence_score\"] = 8\n        analysis[\"empathy_score\"] = 8\n    elif assertive_count >= 1:\n        analysis[\"style\"] = \"‚úÖ ASSERTIVE\"\n        analysis[\"tone_score\"] = 8\n        analysis[\"confidence_score\"] = 7\n    \n    # Adjust clarity for fillers (text-based)\n    analysis[\"clarity_score\"] = max(3, 10 - len(found_fillers) * 2)\n    \n    # IF AUDIO: Override scores with vocal analysis\n    if audio_features and audio_features.get(\"status\") == \"success\":\n        # Use audio analysis for clarity, confidence, tone\n        analysis[\"clarity_score\"] = audio_features[\"clarity\"][\"score\"]\n        analysis[\"confidence_score\"] = audio_features[\"confidence_score\"]\n        \n        # Adjust tone based on emotional tone from voice\n        emotional_tone = audio_features.get(\"emotional_tone\", \"neutral\")\n        if \"agitated\" in emotional_tone or \"stressed\" in emotional_tone:\n            analysis[\"tone_score\"] = min(analysis[\"tone_score\"], 4)\n            analysis[\"issues\"].append(\"üéôÔ∏è Voice sounds agitated/stressed\")\n        elif \"calm\" in emotional_tone:\n            analysis[\"tone_score\"] = max(analysis[\"tone_score\"], 7)\n            analysis[\"strengths\"].append(\"üéôÔ∏è Calm vocal tone\")\n        elif \"engaged\" in emotional_tone or \"enthusiastic\" in emotional_tone:\n            analysis[\"strengths\"].append(\"üéôÔ∏è Engaged and enthusiastic voice\")\n    \n    # Overall score\n    analysis[\"overall_score\"] = round(\n        (analysis[\"tone_score\"] + analysis[\"clarity_score\"] + \n         analysis[\"confidence_score\"] + analysis[\"empathy_score\"]) / 4\n    )\n    \n    # ========== GENERATE COACHING ==========\n    \n    coaching = []\n    rewritten = text\n    \n    if \"AGGRESSIVE\" in analysis[\"style\"]:\n        coaching = [\n            f\"1Ô∏è‚É£ {user.name}, replace 'You always/never' with 'When [situation]...'\",\n            \"2Ô∏è‚É£ Pause 3 seconds before responding when upset\",\n            \"3Ô∏è‚É£ Focus on behavior, not the person's character\",\n            \"4Ô∏è‚É£ Use format: 'I feel [emotion] when [situation] because [reason]'\",\n        ]\n        # Rewrite aggressive message\n        rewritten = re.sub(r\"\\byou always\\b\", \"when this happens, I feel\", rewritten, flags=re.IGNORECASE)\n        rewritten = re.sub(r\"\\byou never\\b\", \"when this doesn't happen, I feel\", rewritten, flags=re.IGNORECASE)\n        rewritten = re.sub(r\"\\byou should\\b\", \"I'd appreciate if you could\", rewritten, flags=re.IGNORECASE)\n        rewritten = re.sub(r\"\\bwhy didn'?t you\\b\", \"I noticed\", rewritten, flags=re.IGNORECASE)\n        \n    elif \"PASSIVE\" in analysis[\"style\"]:\n        coaching = [\n            \"1Ô∏è‚É£ Remove qualifiers: 'maybe' ‚Üí state directly\",\n            \"2Ô∏è‚É£ Only apologize when you've done something wrong\",\n            \"3Ô∏è‚É£ Replace 'I guess' with 'I think' or 'I believe'\",\n            f\"4Ô∏è‚É£ {user.name}, your needs matter - state them clearly!\",\n        ]\n        rewritten = re.sub(r\"\\bi guess\\b\", \"I think\", rewritten, flags=re.IGNORECASE)\n        rewritten = re.sub(r\"\\bmaybe we could\\b\", \"I suggest we\", rewritten, flags=re.IGNORECASE)\n        rewritten = re.sub(r\"\\bsorry,? but\\b\", \"\", rewritten, flags=re.IGNORECASE)\n        \n    elif \"ASSERTIVE\" in analysis[\"style\"]:\n        coaching = [\n            f\"1Ô∏è‚É£ Excellent work, {user.name}! Your 'I' statements are effective\",\n            \"2Ô∏è‚É£ To enhance: Add clarifying questions like 'What's your perspective?'\",\n            \"3Ô∏è‚É£ Validate others: 'I hear what you're saying, and...'\",\n        ]\n    \n    # ADD AUDIO-SPECIFIC COACHING\n    if audio_features and audio_features.get(\"status\") == \"success\":\n        audio_coaching = []\n        \n        # Volume coaching\n        if audio_features[\"volume\"][\"level\"] == \"loud\":\n            audio_coaching.append(\"üîä Lower your volume slightly to sound less aggressive\")\n        elif audio_features[\"volume\"][\"level\"] == \"soft\":\n            audio_coaching.append(\"üîä Speak louder to sound more confident\")\n        \n        # Pace coaching\n        if audio_features[\"pace\"][\"level\"] == \"fast\":\n            audio_coaching.append(\"‚è±Ô∏è Slow down your speech - take breaths between sentences\")\n        elif audio_features[\"pace\"][\"level\"] == \"slow\":\n            audio_coaching.append(\"‚è±Ô∏è Increase pace slightly to maintain listener engagement\")\n        \n        # Pitch coaching\n        if audio_features[\"pitch\"][\"variety\"] == \"monotone\":\n            audio_coaching.append(\"üéµ Vary your pitch - emphasize key words for impact\")\n        \n        # Clarity coaching\n        if audio_features[\"clarity\"][\"level\"] == \"unclear\":\n            audio_coaching.append(\"üó£Ô∏è Enunciate clearly - open your mouth more when speaking\")\n        \n        # Pause coaching\n        if audio_features[\"pauses\"][\"level\"] == \"many_long\":\n            audio_coaching.append(\"‚è∏Ô∏è Reduce long pauses - prepare your thoughts beforehand\")\n        elif audio_features[\"pauses\"][\"level\"] == \"few\":\n            audio_coaching.append(\"‚è∏Ô∏è Add strategic pauses to let ideas sink in\")\n        \n        if audio_coaching:\n            coaching.extend([\"\", \"üéôÔ∏è VOCAL COACHING:\"] + audio_coaching)\n    \n    # Relationship-specific tips\n    relationship_tips = {\n        \"boss\": \"üíº With your boss: Lead with solutions, not just problems. 'I noticed X, I suggest Y.'\",\n        \"colleague\": \"ü§ù With colleagues: Emphasize collaboration. 'How can we solve this together?'\",\n        \"partner\": \"üíï With your partner: Choose calm moments, avoid discussing issues when tired.\",\n        \"family\": \"üë®‚Äçüë©‚Äçüëß With family: Acknowledge their perspective first, then share yours.\",\n        \"friend\": \"üëã With friends: Be direct but kind. Good friends appreciate honesty.\",\n    }\n    \n    # Update user stats\n    user.streaks[\"communication\"] = user.streaks.get(\"communication\", 0) + 1\n    user.total_points += 15\n    user.communication_history.append({\n        \"timestamp\": time.time(),\n        \"score\": analysis[\"overall_score\"],\n        \"style\": analysis[\"style\"],\n        \"had_audio\": audio_path is not None\n    })\n    \n    # Build result\n    result = {\n        \"status\": \"analyzed\",\n        \"original_message\": text,\n        \"transcribed_from_audio\": transcript is not None,\n        \"analysis\": {\n            \"style\": analysis[\"style\"],\n            \"scores\": {\n                \"tone\": f\"{analysis['tone_score']}/10\",\n                \"clarity\": f\"{analysis['clarity_score']}/10\",\n                \"confidence\": f\"{analysis['confidence_score']}/10\",\n                \"empathy\": f\"{analysis['empathy_score']}/10\",\n                \"overall\": f\"{analysis['overall_score']}/10\"\n            },\n            \"issues\": analysis[\"issues\"],\n            \"strengths\": analysis[\"strengths\"],\n            \"filler_words\": analysis[\"filler_words\"]\n        },\n        \"coaching\": coaching,\n        \"rewritten_message\": rewritten if rewritten != text else None,\n        \"relationship_tip\": relationship_tips.get(relationship, \"\"),\n        \"stats\": {\n            \"streak\": user.streaks[\"communication\"],\n            \"points_earned\": 15,\n            \"total_points\": user.total_points\n        }\n    }\n    \n    # Add audio analysis if available\n    if audio_features and audio_features.get(\"status\") == \"success\":\n        result[\"vocal_analysis\"] = {\n            \"duration\": f\"{audio_features['duration_seconds']}s\",\n            \"volume\": {\n                \"level\": audio_features[\"volume\"][\"level\"],\n                \"note\": audio_features[\"volume\"][\"note\"],\n                \"score\": f\"{audio_features['volume']['score']}/10\"\n            },\n            \"pace\": {\n                \"level\": audio_features[\"pace\"][\"level\"],\n                \"rate\": f\"{audio_features['pace']['syllables_per_sec']} syllables/sec\",\n                \"note\": audio_features[\"pace\"][\"note\"],\n                \"score\": f\"{audio_features['pace']['score']}/10\"\n            },\n            \"pitch\": {\n                \"level\": audio_features[\"pitch\"][\"level\"],\n                \"variety\": audio_features[\"pitch\"][\"variety\"],\n                \"note\": audio_features[\"pitch\"][\"note\"],\n                \"score\": f\"{audio_features['pitch']['score']}/10\"\n            },\n            \"clarity\": {\n                \"level\": audio_features[\"clarity\"][\"level\"],\n                \"note\": audio_features[\"clarity\"][\"note\"],\n                \"score\": f\"{audio_features['clarity']['score']}/10\"\n            },\n            \"pauses\": {\n                \"pattern\": audio_features[\"pauses\"][\"level\"],\n                \"average\": f\"{audio_features['pauses']['average_seconds']}s\",\n                \"note\": audio_features[\"pauses\"][\"note\"]\n            },\n            \"confidence_score\": f\"{audio_features['confidence_score']}/10\",\n            \"emotional_tone\": audio_features[\"emotional_tone\"],\n            \"overall_vocal_score\": f\"{audio_features['overall_score']}/10\"\n        }\n        result[\"message\"] = f\"üéôÔ∏è Analyzed {audio_features['duration_seconds']}s of speech with full vocal analysis!\"\n    \n    if rewritten != text:\n        result[\"correction_example\"] = f\"\\n‚ùå Original: '{text}'\\n‚úÖ Try: '{rewritten}'\"\n    \n    metric_inc(\"communication_analyses\")\n    metric_time(\"interpersonal_coach\", time.time() - start)\n    \n    return result\n\nprint(\"‚úÖ Agent 3: Interpersonal Coach with FULL audio analysis ready\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# ============================================================================\n# CELL 7: AGENT 4 - MEAL PLANNER (with Image Support)\n# ============================================================================\n\ndef analyze_food_image(image_path: str) -> Dict:\n    \"\"\"Use Gemini Vision to detect food items in image with robust error handling.\"\"\"\n    try:\n        # CHANGE 1: Add validation first\n        validation = safe_file_read(image_path, ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp'])\n        if validation[\"status\"] == \"error\":\n            return {\"status\": \"error\", \"message\": validation[\"error\"], \"items\": []}\n        \n        # CHANGE 2: Add image verification\n        try:\n            image = Image.open(image_path)\n            image.verify()  # Verify it's actually an image\n            image = Image.open(image_path)  # Reopen after verify\n        except Exception as img_err:\n            return {\n                \"status\": \"error\", \n                \"message\": f\"Invalid image file: {str(img_err)}\", \n                \"items\": []\n            }\n        \n        # Rest remains the same\n        model = genai.GenerativeModel('gemini-2.5-flash')\n        \n        response = model.generate_content([\n            \"List all food items, ingredients, or groceries visible in this image. \"\n            \"Return ONLY a comma-separated list. Example: chicken, rice, broccoli. \"\n            \"If no food visible, return: none\",\n            image\n        ])\n        \n        result_text = response.text.strip().lower()\n        \n        if result_text == \"none\" or not result_text:\n            return {\"status\": \"no_food\", \"items\": []}\n        \n        items = [item.strip() for item in result_text.split(',') if item.strip()]\n        return {\"status\": \"success\", \"items\": items}\n        \n    except Exception as e:\n        logger.error(f\"Image analysis error: {e}\\n{traceback.format_exc()}\")  # CHANGE 3: Add traceback\n        return {\n            \"status\": \"error\", \n            \"message\": f\"Image processing failed: {str(e)}\", \n            \"items\": []\n        }\n\n\ndef plan_meals(\n    user_id: str,\n    ingredients: str = None,\n    image_path: str = None,\n    days: int = 3\n) -> Dict:\n    \"\"\"\n    Create meal plans from ingredients (text or image).\n    \n    Parameters:\n    - user_id: User identifier\n    - ingredients: Comma-separated list of ingredients\n    - image_path: Path to image of groceries/fridge\n    - days: Number of days to plan (1-7)\n    \n    Returns: Meal plans with recipes\n    \"\"\"\n    start = time.time()\n    user = get_user(user_id)\n    groceries = []\n    image_note = \"\"\n    \n    # Process image if provided\n    if image_path:\n        logger.info(f\"Processing food image: {image_path}\")\n        \n        # CHANGE: Add validation before analysis\n        validation = safe_file_read(image_path, ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp'])\n        if validation[\"status\"] == \"error\":\n            return {\n                \"status\": \"error\",\n                \"message\": f\"Image error: {validation['error']}\"\n            }\n        \n        image_result = analyze_food_image(image_path)\n        \n        if image_result[\"status\"] == \"success\":\n            groceries.extend(image_result[\"items\"])\n            image_note = f\"üì∏ Detected from image: {', '.join(image_result['items'])}\"\n        elif image_result[\"status\"] == \"no_food\":\n            image_note = \"üì∏ No food items detected in image\"\n        else:\n            image_note = f\"‚ö†Ô∏è Image error: {image_result.get('message', 'Unknown error')}\"\n    \n    # Process text ingredients\n    if ingredients:\n        text_items = [g.strip().lower() for g in re.split(r'[,;]', ingredients) if len(g.strip()) > 2]\n        groceries.extend(text_items)\n    \n    # Remove duplicates\n    groceries = list(set(groceries))\n    \n    if not groceries:\n        return {\n            \"status\": \"needs_input\",\n            \"message\": f\"üç≥ {user.name}, I need ingredients to plan meals!\",\n            \"image_note\": image_note if image_note else None,\n            \"options\": [\n                \"üìù List ingredients: 'Meal plan: chicken, rice, broccoli'\",\n                \"üì∏ Upload a photo of your fridge/groceries\",\n            ],\n            \"example\": \"Meal plan: chicken breast, rice, broccoli, eggs, onion\"\n        }\n    \n    # Categorize ingredients\n    categories = {\n        \"proteins\": [\"chicken\", \"beef\", \"pork\", \"fish\", \"salmon\", \"tuna\", \"shrimp\", \"egg\", \"tofu\", \"turkey\", \"lamb\"],\n        \"carbs\": [\"rice\", \"pasta\", \"bread\", \"potato\", \"noodle\", \"quinoa\", \"oat\", \"tortilla\"],\n        \"vegetables\": [\"broccoli\", \"spinach\", \"carrot\", \"tomato\", \"onion\", \"pepper\", \"lettuce\", \"cucumber\", \"mushroom\", \"garlic\", \"celery\", \"cabbage\"],\n        \"fruits\": [\"apple\", \"banana\", \"orange\", \"berry\", \"grape\", \"mango\", \"lemon\"],\n        \"dairy\": [\"milk\", \"cheese\", \"yogurt\", \"butter\", \"cream\"]\n    }\n    \n    categorized = {cat: [] for cat in categories}\n    for g in groceries:\n        for cat, keywords in categories.items():\n            if any(k in g for k in keywords):\n                categorized[cat].append(g)\n                break\n    \n    # Generate meal plans\n    meal_plans = []\n    days = min(max(1, days), 7)  # Clamp 1-7\n    \n    for day in range(1, days + 1):\n        day_meals = {\"day\": f\"Day {day}\", \"meals\": {}}\n        \n        # Breakfast\n        if categorized[\"proteins\"] or categorized[\"dairy\"]:\n            if \"egg\" in str(categorized[\"proteins\"]):\n                day_meals[\"meals\"][\"breakfast\"] = {\n                    \"dish\": f\"Scrambled eggs with {categorized['vegetables'][0] if categorized['vegetables'] else 'toast'}\",\n                    \"time\": \"15 min\", \"calories\": \"300-400\"\n                }\n            elif categorized[\"dairy\"]:\n                day_meals[\"meals\"][\"breakfast\"] = {\n                    \"dish\": f\"Greek yogurt with {categorized['fruits'][0] if categorized['fruits'] else 'granola'}\",\n                    \"time\": \"5 min\", \"calories\": \"250-350\"\n                }\n        \n        # Lunch\n        if categorized[\"proteins\"] and categorized[\"vegetables\"]:\n            p = categorized[\"proteins\"][day % len(categorized[\"proteins\"])]\n            v = categorized[\"vegetables\"][day % len(categorized[\"vegetables\"])]\n            day_meals[\"meals\"][\"lunch\"] = {\n                \"dish\": f\"Grilled {p} salad with {v}\",\n                \"time\": \"20 min\", \"calories\": \"400-500\"\n            }\n        \n        # Dinner\n        if categorized[\"proteins\"]:\n            p = categorized[\"proteins\"][(day + 1) % len(categorized[\"proteins\"])]\n            c = categorized[\"carbs\"][0] if categorized[\"carbs\"] else \"rice\"\n            v = categorized[\"vegetables\"][(day + 1) % len(categorized[\"vegetables\"])] if categorized[\"vegetables\"] else \"vegetables\"\n            day_meals[\"meals\"][\"dinner\"] = {\n                \"dish\": f\"{p.title()} stir-fry with {c} and {v}\",\n                \"time\": \"30 min\", \"calories\": \"500-600\"\n            }\n        \n        meal_plans.append(day_meals)\n    \n    # Generate detailed recipes\n    recipes = []\n    \n    if \"chicken\" in str(groceries):\n        recipes.append({\n            \"name\": \"üçó Quick Chicken Stir-Fry\",\n            \"time\": \"25 min\",\n            \"servings\": 4,\n            \"ingredients\": [\n                \"2 chicken breasts, cubed\",\n                f\"2 cups {categorized['vegetables'][0] if categorized['vegetables'] else 'mixed vegetables'}\",\n                f\"1 cup {categorized['carbs'][0] if categorized['carbs'] else 'rice'}\",\n                \"2 tbsp oil, 2 cloves garlic, 3 tbsp soy sauce\"\n            ],\n            \"steps\": [\n                \"1Ô∏è‚É£ Cook rice/carbs according to package\",\n                \"2Ô∏è‚É£ Heat oil in wok over high heat\",\n                \"3Ô∏è‚É£ Add chicken, cook 6-8 min until golden\",\n                \"4Ô∏è‚É£ Add garlic and vegetables, stir 4-5 min\",\n                \"5Ô∏è‚É£ Add soy sauce, toss and serve over rice\"\n            ]\n        })\n    \n    if \"egg\" in str(groceries):\n        recipes.append({\n            \"name\": \"üç≥ Veggie Omelette\",\n            \"time\": \"10 min\",\n            \"servings\": 1,\n            \"ingredients\": [\n                \"3 eggs\",\n                f\"1/4 cup diced {categorized['vegetables'][0] if categorized['vegetables'] else 'vegetables'}\",\n                \"2 tbsp cheese, salt, pepper, 1 tbsp butter\"\n            ],\n            \"steps\": [\n                \"1Ô∏è‚É£ Beat eggs with salt and pepper\",\n                \"2Ô∏è‚É£ Melt butter in pan over medium heat\",\n                \"3Ô∏è‚É£ Pour eggs, let set 1-2 min\",\n                \"4Ô∏è‚É£ Add veggies and cheese to half\",\n                \"5Ô∏è‚É£ Fold and serve\"\n            ]\n        })\n    \n    # Shopping suggestions\n    missing = []\n    if not categorized[\"proteins\"]: missing.append(\"protein (chicken, fish, eggs, tofu)\")\n    if not categorized[\"carbs\"]: missing.append(\"carbs (rice, pasta, bread)\")\n    if not categorized[\"vegetables\"]: missing.append(\"vegetables\")\n    \n    # Update user stats\n    user.streaks[\"nutrition\"] = user.streaks.get(\"nutrition\", 0) + 1\n    user.total_points += 25\n    \n    metric_inc(\"meal_plans\")\n    metric_time(\"meal_planner\", time.time() - start)\n    \n    return {\n        \"status\": \"complete\",\n        \"ingredients_found\": groceries,\n        \"categories\": {k: v for k, v in categorized.items() if v},\n        \"meal_plans\": meal_plans,\n        \"recipes\": recipes,\n        \"days_planned\": days,\n        \"shopping_suggestions\": missing,\n        \"image_analysis\": image_note if image_note else None,\n        \"stats\": {\n            \"streak\": user.streaks[\"nutrition\"],\n            \"points_earned\": 25,\n            \"total_points\": user.total_points\n        }\n    }\n\nprint(\"‚úÖ Agent 4: Meal Planner ready\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# ============================================================================\n# CELL 8: AGENT 5 - TASK PLANNER\n# ============================================================================\n\ndef plan_tasks(user_id: str, tasks_text: str) -> Dict:\n    \"\"\"\n    Organize and prioritize tasks with time estimates.\n    \n    Parameters:\n    - user_id: User identifier\n    - tasks_text: Comma-separated list of tasks\n    \n    Returns: Prioritized task list with estimates\n    \"\"\"\n    start = time.time()\n    user = get_user(user_id)\n    \n    # Parse tasks\n    tasks = [t.strip() for t in re.split(r'[,;]', tasks_text) if len(t.strip()) > 2]\n    \n    if not tasks:\n        return {\n            \"status\": \"needs_input\",\n            \"message\": f\"üìã {user.name}, please list your tasks!\",\n            \"example\": \"Tasks: finish report, call client, workout, send emails\"\n        }\n    \n    # Analyze and schedule tasks\n    scheduled = []\n    total_time = 0\n    \n    time_estimates = {\n        \"quick\": ([\"call\", \"email\", \"text\", \"message\", \"reply\"], 15),\n        \"medium\": ([\"meeting\", \"review\", \"check\", \"update\"], 30),\n        \"long\": ([\"write\", \"report\", \"presentation\", \"project\", \"analysis\"], 60),\n        \"extended\": ([\"research\", \"develop\", \"build\", \"create\", \"design\"], 90)\n    }\n    \n    for i, task in enumerate(tasks):\n        lower = task.lower()\n        \n        # Estimate time\n        est = 30  # default\n        for duration, (keywords, minutes) in time_estimates.items():\n            if any(k in lower for k in keywords):\n                est = minutes\n                break\n        \n        # Calculate priority\n        priority = 10 - i  # Base priority by order\n        if any(w in lower for w in [\"urgent\", \"asap\", \"important\", \"deadline\", \"critical\"]):\n            priority += 5\n        if any(w in lower for w in [\"optional\", \"maybe\", \"if time\"]):\n            priority -= 3\n        \n        scheduled.append({\n            \"task\": task,\n            \"estimate_min\": est,\n            \"priority\": max(1, min(15, priority)),\n            \"category\": \"urgent\" if priority > 10 else \"normal\" if priority > 5 else \"low\"\n        })\n        total_time += est\n    \n    # Sort by priority\n    scheduled.sort(key=lambda x: x[\"priority\"], reverse=True)\n    \n    # Generate strategy\n    if total_time > 240:  # > 4 hours\n        strategy = \"üçÖ Pomodoro Technique: 25 min focused work ‚Üí 5 min break ‚Üí repeat\"\n        motivation = f\"{user.name}, that's {total_time//60}+ hours of work. Break it into sessions!\"\n    elif total_time > 120:  # > 2 hours\n        strategy = \"üìÖ Time Blocking: Schedule 90-min focus blocks with 15-min breaks\"\n        motivation = f\"Solid list! About {total_time//60} hours. You've got this!\"\n    else:\n        strategy = \"‚ö° Batch Processing: Group similar tasks together\"\n        motivation = f\"Quick wins ahead! About {total_time} minutes total.\"\n    \n    # Update user stats\n    user.streaks[\"tasks\"] = user.streaks.get(\"tasks\", 0) + 1\n    user.total_points += 15\n    \n    metric_inc(\"tasks_planned\")\n    metric_time(\"task_planner\", time.time() - start)\n    \n    return {\n        \"status\": \"planned\",\n        \"tasks\": scheduled,\n        \"summary\": {\n            \"total_tasks\": len(scheduled),\n            \"total_time\": f\"{total_time//60}h {total_time%60}m\" if total_time >= 60 else f\"{total_time}m\",\n            \"urgent_tasks\": len([t for t in scheduled if t[\"category\"] == \"urgent\"]),\n        },\n        \"top_3_priorities\": [t[\"task\"] for t in scheduled[:3]],\n        \"strategy\": strategy,\n        \"motivation\": motivation,\n        \"stats\": {\n            \"streak\": user.streaks[\"tasks\"],\n            \"points_earned\": 15,\n            \"total_points\": user.total_points\n        }\n    }\n\nprint(\"‚úÖ Agent 5: Task Planner ready\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# ============================================================================\n# CELL 9: AGENT 6 - NUTRITION ADVISOR\n# ============================================================================\n\ndef get_nutrition_advice(user_id: str, goal: str) -> Dict:\n    \"\"\"\n    Provide nutrition advice based on wellness goals.\n    \n    Parameters:\n    - user_id: User identifier\n    - goal: User's goal or concern (stress, energy, weight, sleep, etc.)\n    \n    Returns: Personalized nutrition guidance\n    \"\"\"\n    start = time.time()\n    user = get_user(user_id)\n    lower = goal.lower()\n    \n    # Detect goal from text\n    advice_db = {\n        \"stress\": {\n            \"keywords\": [\"stress\", \"anxiety\", \"anxious\", \"calm\", \"relax\", \"nervous\"],\n            \"goal_name\": \"Stress Management\",\n            \"foods\": [\"Dark chocolate (85%+)\", \"Walnuts\", \"Salmon\", \"Blueberries\", \"Green tea\", \"Chamomile tea\"],\n            \"tips\": [\n                \"üç´ Magnesium in dark chocolate helps reduce cortisol\",\n                \"üêü Omega-3s in salmon reduce inflammation and anxiety\",\n                \"ü´ñ L-theanine in green tea promotes calm without drowsiness\",\n                \"ü•ú B-vitamins in nuts support nervous system health\"\n            ],\n            \"avoid\": [\"Excessive caffeine\", \"Alcohol\", \"Refined sugars\", \"Processed foods\"]\n        },\n        \"energy\": {\n            \"keywords\": [\"energy\", \"tired\", \"fatigue\", \"exhausted\", \"sluggish\", \"alert\"],\n            \"goal_name\": \"Energy Boost\",\n            \"foods\": [\"Oatmeal\", \"Eggs\", \"Bananas\", \"Greek yogurt\", \"Almonds\", \"Sweet potato\"],\n            \"tips\": [\n                \"ü•ö Protein at breakfast sustains energy all morning\",\n                \"üçå Complex carbs provide steady fuel without crashes\",\n                \"üíß Dehydration is a major cause of fatigue - drink more water!\",\n                \"ü•ú Healthy fats keep you satisfied and energized\"\n            ],\n            \"avoid\": [\"Sugar-heavy breakfast\", \"Skipping meals\", \"Energy drinks\", \"Large heavy lunches\"]\n        },\n        \"sleep\": {\n            \"keywords\": [\"sleep\", \"insomnia\", \"rest\", \"tired at night\", \"can't sleep\"],\n            \"goal_name\": \"Better Sleep\",\n            \"foods\": [\"Cherries\", \"Warm milk\", \"Turkey\", \"Kiwi\", \"Almonds\", \"Chamomile tea\"],\n            \"tips\": [\n                \"üçí Cherries are natural source of melatonin\",\n                \"ü•õ Warm milk contains tryptophan for relaxation\",\n                \"ü•ù Two kiwis before bed improves sleep quality\",\n                \"‚è∞ Avoid eating 2-3 hours before bedtime\"\n            ],\n            \"avoid\": [\"Caffeine after 2pm\", \"Alcohol before bed\", \"Heavy/spicy dinners\", \"Chocolate at night\"]\n        },\n        \"weight\": {\n            \"keywords\": [\"weight\", \"diet\", \"lose\", \"fat\", \"calories\", \"slim\"],\n            \"goal_name\": \"Weight Management\",\n            \"foods\": [\"Lean proteins\", \"Leafy greens\", \"Berries\", \"Legumes\", \"Whole grains\", \"Greek yogurt\"],\n            \"tips\": [\n                \"ü•ó Fill half your plate with vegetables\",\n                \"üçó Protein keeps you full longer - include at every meal\",\n                \"‚è±Ô∏è Eat slowly - it takes 20 min to feel full\",\n                \"üíß Drink water before meals to reduce overeating\"\n            ],\n            \"avoid\": [\"Liquid calories\", \"Processed snacks\", \"Large portions\", \"Eating while distracted\"]\n        },\n        \"focus\": {\n            \"keywords\": [\"focus\", \"concentrate\", \"brain\", \"memory\", \"think\", \"mental\"],\n            \"goal_name\": \"Mental Focus\",\n            \"foods\": [\"Fatty fish\", \"Blueberries\", \"Eggs\", \"Broccoli\", \"Pumpkin seeds\", \"Dark chocolate\"],\n            \"tips\": [\n                \"üêü DHA in fatty fish is essential for brain function\",\n                \"ü´ê Antioxidants in blueberries improve memory\",\n                \"ü•ö Choline in eggs supports neurotransmitter production\",\n                \"ü•¶ Vitamin K in broccoli enhances cognitive function\"\n            ],\n            \"avoid\": [\"Excessive sugar\", \"Trans fats\", \"Alcohol\", \"Highly processed foods\"]\n        }\n    }\n    \n    # Find matching goal\n    selected = None\n    for key, data in advice_db.items():\n        if any(kw in lower for kw in data[\"keywords\"]):\n            selected = data\n            break\n    \n    # Default to general wellness\n    if not selected:\n        selected = {\n            \"goal_name\": \"General Wellness\",\n            \"foods\": [\"Colorful vegetables\", \"Lean proteins\", \"Whole grains\", \"Healthy fats\", \"Water\"],\n            \"tips\": [\n                \"üåà Eat the rainbow - variety ensures all nutrients\",\n                \"ü•© Include protein at every meal\",\n                \"üíß Aim for 8 glasses of water daily\",\n                \"üçΩÔ∏è Practice mindful eating - no screens at meals\"\n            ],\n            \"avoid\": [\"Processed foods\", \"Excessive sugar\", \"Trans fats\", \"Skipping meals\"]\n        }\n    \n    # Update user stats\n    user.total_points += 10\n    \n    metric_inc(\"nutrition_advice\")\n    metric_time(\"nutrition_agent\", time.time() - start)\n    \n    return {\n        \"status\": \"success\",\n        \"goal\": selected[\"goal_name\"],\n        \"recommended_foods\": selected[\"foods\"],\n        \"tips\": selected[\"tips\"],\n        \"foods_to_limit\": selected.get(\"avoid\", []),\n        \"quick_meal\": f\"Try: {selected['foods'][0]} + {selected['foods'][1]} for your next meal\",\n        \"stats\": {\n            \"points_earned\": 10,\n            \"total_points\": user.total_points\n        },\n        \"encouragement\": f\"{user.name}, small changes lead to big results! üí™\"\n    }\n\nprint(\"‚úÖ Agent 6: Nutrition Advisor ready\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# MODIFIED AGENT 7 - SUMMARIZER \n# ============================================================================\n\ndef extract_from_url(url: str) -> Dict:\n    \"\"\"Extract text from URL.\"\"\"\n    try:\n        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n        response = requests.get(url, headers=headers, timeout=15)\n        response.raise_for_status()\n        \n        soup = BeautifulSoup(response.content, 'html.parser')\n        for tag in soup(['script', 'style', 'nav', 'footer', 'header']):\n            tag.decompose()\n        \n        main = soup.find('main') or soup.find('article') or soup.find('body')\n        paragraphs = main.find_all(['p', 'h1', 'h2', 'h3', 'li']) if main else []\n        text = '\\n'.join([p.get_text().strip() for p in paragraphs if p.get_text().strip()])\n        \n        title = soup.find('title')\n        \n        return {\n            \"status\": \"success\", \"type\": \"url\", \"source\": url,\n            \"title\": title.get_text().strip() if title else \"Untitled\",\n            \"content\": text[:15000], \"word_count\": len(text.split())\n        }\n    except Exception as e:\n        return {\"status\": \"error\", \"message\": str(e)}\n\n\ndef extract_from_pdf(pdf_path: str) -> Dict:\n    \"\"\"Extract text from PDF with robust error handling.\"\"\"\n    try:\n        # Add validation\n        validation = safe_file_read(pdf_path, ['.pdf'])\n        if validation[\"status\"] == \"error\":\n            return {\"status\": \"error\", \"message\": validation[\"error\"]}\n        \n        text = \"\"\n        with open(pdf_path, 'rb') as f:\n            try:\n                reader = PyPDF2.PdfReader(f)\n                num_pages = len(reader.pages)\n                \n                # Check for empty PDF\n                if num_pages == 0:\n                    return {\"status\": \"error\", \"message\": \"PDF has no pages\"}\n                \n                # Limit to first 50 pages to avoid timeouts\n                for i, page in enumerate(reader.pages[:50]):\n                    try:\n                        page_text = page.extract_text()\n                        if page_text:\n                            text += page_text + \"\\n\"\n                    except Exception as page_err:\n                        logger.warning(f\"Could not extract page {i}: {page_err}\")\n                        continue\n                \n                # Check if any text was extracted\n                if not text.strip():\n                    return {\"status\": \"error\", \"message\": \"Could not extract any text from PDF\"}\n                \n                return {\n                    \"status\": \"success\", \n                    \"type\": \"pdf\", \n                    \"source\": pdf_path,\n                    \"content\": text[:15000], \n                    \"word_count\": len(text.split()),\n                    \"pages\": min(num_pages, 50)\n                }\n            except Exception as read_err:\n                return {\"status\": \"error\", \"message\": f\"PDF reading error: {str(read_err)}\"}\n                \n    except Exception as e:\n        logger.error(f\"PDF extraction error: {e}\\n{traceback.format_exc()}\")\n        return {\"status\": \"error\", \"message\": f\"PDF processing failed: {str(e)}\"}\n\n\ndef summarize_content(\n    user_id: str,\n    text: str = None,\n    url: str = None,\n    pdf_path: str = None,\n    output_format: str = \"all\"\n) -> Dict:\n    \"\"\"\n    Enhanced summarizer supporting TEXT, URL, and PDF only.\n    \n    REMOVED FORMATS: DOCX, IPYNB (not working reliably)\n    \n    Parameters:\n    - user_id: User identifier\n    - text: Text to analyze (direct input)\n    - url: URL to fetch and summarize\n    - pdf_path: Path to PDF file\n    - output_format: \"summary\", \"quiz\", \"findings\", \"mindmap\", \"all\"\n    \n    Returns: Comprehensive analysis with AI-generated insights\n    \"\"\"\n    start = time.time()\n    user = get_user(user_id)\n    \n    # Extract content from available sources\n    extracted = None\n    \n    if url:\n        extracted = extract_from_url(url)\n    elif pdf_path:\n        extracted = extract_from_pdf(pdf_path)\n    elif text and len(text) >= 50:\n        extracted = {\"status\": \"success\", \"type\": \"text\", \"content\": text, \"word_count\": len(text.split())}\n    else:\n        return {\n            \"status\": \"needs_input\",\n            \"message\": f\"üìÑ {user.name}, I can summarize content in these formats:\",\n            \"supported_formats\": [\n                \"‚úÖ Direct text (paste or type)\",\n                \"‚úÖ URL (any website)\",\n                \"‚úÖ PDF (documents up to 50 pages)\"\n            ],\n            \"removed_formats\": [\n                \"‚ùå DOCX (removed - not working)\",\n                \"‚ùå IPYNB (removed - not working)\"\n            ],\n            \"examples\": [\n                \"Summarize: [paste your text here]\",\n                \"Summarize: https://example.com/article\",\n                \"Upload a PDF file\"\n            ]\n        }\n    \n    if extracted.get(\"status\") == \"error\":\n        return extracted\n    \n    content = extracted[\"content\"]\n    word_count = extracted.get(\"word_count\", 0)\n    \n    # Calculate reading time\n    reading_time = max(1, word_count // 200)  # Average 200 words per minute\n    \n    # Use Gemini for AI summarization\n    try:\n        model = genai.GenerativeModel('gemini-2.5-flash')\n        \n        # Enhanced prompt for general content\n        prompt = f\"\"\"Analyze this content comprehensively. Return ONLY valid JSON:\n{{\n    \"summary\": \"3-4 sentence summary\",\n    \"key_points\": [\"point1\", \"point2\", \"point3\", \"point4\", \"point5\"],\n    \"action_items\": [\"actionable task 1\", \"actionable task 2\"],\n    \"key_entities\": {{\n        \"people\": [\"person1\", \"person2\"],\n        \"organizations\": [\"org1\", \"org2\"],\n        \"locations\": [\"place1\", \"place2\"]\n    }},\n    \"sentiment\": \"positive/negative/neutral/mixed\",\n    \"main_topics\": [\"topic1\", \"topic2\", \"topic3\"],\n    \"difficulty_level\": \"easy/moderate/complex\",\n    \"mind_map\": {{\n        \"central_topic\": \"main topic\",\n        \"branches\": [\"subtopic1\", \"subtopic2\", \"subtopic3\"]\n    }},\n    \"quiz\": [\n        {{\"question\": \"What is the main idea?\", \"options\": [\"A) Option\", \"B) Option\", \"C) Option\", \"D) Option\"], \"answer\": \"A\"}},\n        {{\"question\": \"According to the text...\", \"options\": [\"A) Option\", \"B) Option\", \"C) Option\", \"D) Option\"], \"answer\": \"C\"}}\n    ],\n    \"key_findings\": [\"finding1\", \"finding2\", \"finding3\"]\n}}\n\nContent: {content[:8000]}\"\"\"\n        \n        # Add max_output_tokens to ensure complete JSON\n        response = model.generate_content(\n            prompt,\n            generation_config=genai.types.GenerationConfig(\n                max_output_tokens=2048,\n                temperature=0.3\n            )\n        )\n        response_text = response.text.strip()\n        \n        # Clean JSON from markdown\n        if '```json' in response_text:\n            response_text = response_text.split('```json')[1].split('```')[0]\n        elif '```' in response_text:\n            response_text = response_text.split('```')[1].split('```')[0]\n        \n        response_text = response_text.strip()\n        \n        # Try to parse JSON\n        try:\n            ai_result = json.loads(response_text)\n        except json.JSONDecodeError as je:\n            logger.error(f\"JSON parsing error: {je}\")\n            logger.error(f\"Response text: {response_text[:500]}\")\n            raise Exception(\"Invalid JSON from AI\")\n        \n    except Exception as e:\n        logger.error(f\"AI summarization failed: {e}\")\n        # Enhanced fallback\n        sentences = [s.strip() for s in content.split('.') if len(s.strip()) > 20]\n        \n        ai_result = {\n            \"summary\": '. '.join(sentences[:3]) + '.',\n            \"key_points\": sentences[:5],\n            \"main_topics\": [\"General content\"],\n            \"sentiment\": \"neutral\",\n            \"difficulty_level\": \"moderate\",\n            \"quiz\": [],\n            \"key_findings\": sentences[:3],\n            \"action_items\": [],\n            \"error_note\": \"Using fallback analysis\"\n        }\n    \n    # Build enhanced result\n    result = {\n        \"status\": \"complete\",\n        \"source_type\": extracted.get(\"type\"),\n        \"source\": extracted.get(\"source\", \"text input\"),\n        \"metadata\": {\n            \"word_count\": word_count,\n            \"reading_time\": f\"{reading_time} min\",\n            \"processing_time\": f\"{time.time() - start:.2f}s\",\n            \"difficulty\": ai_result.get(\"difficulty_level\", \"moderate\"),\n            \"sentiment\": ai_result.get(\"sentiment\", \"neutral\")\n        }\n    }\n    \n    # Add content based on output_format\n    if output_format in [\"summary\", \"all\"]:\n        result[\"summary\"] = ai_result.get(\"summary\")\n        result[\"key_points\"] = ai_result.get(\"key_points\", [])\n        result[\"main_topics\"] = ai_result.get(\"main_topics\", [])\n    \n    if output_format in [\"quiz\", \"all\"]:\n        result[\"quiz\"] = ai_result.get(\"quiz\", [])\n    \n    if output_format in [\"findings\", \"all\"]:\n        result[\"key_findings\"] = ai_result.get(\"key_findings\", [])\n    \n    if output_format in [\"mindmap\", \"all\"]:\n        result[\"mind_map\"] = ai_result.get(\"mind_map\", {})\n    \n    if output_format in [\"all\"]:\n        result[\"action_items\"] = ai_result.get(\"action_items\", [])\n        result[\"key_entities\"] = ai_result.get(\"key_entities\", {})\n    \n    # Update user stats\n    user.total_points += 30\n    \n    # Award badges for document processing\n    docs_processed = user_journeys[user_id].game_scores.get(\"docs_processed\", 0) + 1\n    user_journeys[user_id].game_scores[\"docs_processed\"] = docs_processed\n    \n    if docs_processed == 5 and \"üìö Knowledge Seeker\" not in user.badges:\n        user.badges.append(\"üìö Knowledge Seeker\")\n        result[\"new_badge\"] = \"üìö Knowledge Seeker\"\n    elif docs_processed == 20 and \"üìöüìö Research Master\" not in user.badges:\n        user.badges.append(\"üìöüìö Research Master\")\n        result[\"new_badge\"] = \"üìöüìö Research Master\"\n    \n    metric_inc(\"summaries\")\n    metric_time(\"summarizer\", time.time() - start)\n    \n    result[\"stats\"] = {\n        \"points_earned\": 30,\n        \"total_points\": user.total_points,\n        \"documents_processed\": docs_processed\n    }\n    \n    return result\n\nprint(\"‚úÖ Agent 7: Summarizer (Text/URL/PDF only) ready\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef safe_tool_wrapper(func):\n    \"\"\"Decorator to wrap tool functions with comprehensive error handling.\"\"\"\n    def wrapper(*args, **kwargs):\n        try:\n            result = func(*args, **kwargs)\n            # Check if result is an error dict\n            if isinstance(result, dict) and result.get(\"status\") == \"error\":\n                # Make error message more user-friendly\n                user_message = result.get(\"message\", \"An error occurred\")\n                return {\n                    \"status\": \"error\",\n                    \"message\": f\"I encountered an issue: {user_message}. Please try again or use a different format.\",\n                    \"original_error\": user_message\n                }\n            return result\n        except Exception as e:\n            logger.error(f\"Tool {func.__name__} error: {e}\\n{traceback.format_exc()}\")\n            return {\n                \"status\": \"error\",\n                \"message\": f\"I'm sorry, something went wrong while processing your request. Please try again.\",\n                \"function\": func.__name__\n            }\n    wrapper.__name__ = func.__name__\n    wrapper.__doc__ = func.__doc__\n    return wrapper\n\nprint(\"‚úÖ Safe tool wrapper defined\")\n\n# Create wrapped versions of all agent functions\nwrapped_analyze_mood = safe_tool_wrapper(analyze_mood)\nwrapped_play_stress_game = safe_tool_wrapper(play_stress_game)\nwrapped_analyze_interpersonal = safe_tool_wrapper(analyze_interpersonal)\nwrapped_plan_meals = safe_tool_wrapper(plan_meals)\nwrapped_plan_tasks = safe_tool_wrapper(plan_tasks)\nwrapped_get_nutrition_advice = safe_tool_wrapper(get_nutrition_advice)\nwrapped_summarize_content = safe_tool_wrapper(summarize_content)\n\nprint(\"‚úÖ All agent functions wrapped with error handlers\")\n\n# Create ADK FunctionTools from wrapped functions\nmood_tool = FunctionTool(wrapped_analyze_mood)\ngame_tool = FunctionTool(wrapped_play_stress_game)\ninterpersonal_tool = FunctionTool(wrapped_analyze_interpersonal)\nmeal_tool = FunctionTool(wrapped_plan_meals)\ntask_tool = FunctionTool(wrapped_plan_tasks)\nnutrition_tool = FunctionTool(wrapped_get_nutrition_advice)\nsummarize_tool = FunctionTool(wrapped_summarize_content)\n\nALL_TOOLS = [\n    mood_tool,\n    game_tool,\n    interpersonal_tool,\n    meal_tool,\n    task_tool,\n    nutrition_tool,\n    summarize_tool\n]\n\nprint(\"‚úÖ All 7 agents wrapped as ADK tools\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# CELL 12: CREATE ADK AGENT WITH SYSTEM INSTRUCTIONS\n# ============================================================================\n\nSYSTEM_INSTRUCTION = \"\"\"You are MindMate AI, a compassionate wellness companion with 7 specialized agents.\n\nüîß AVAILABLE TOOLS:\n\n1. analyze_mood(user_id, message, stress_level=5)\n   - Emotional support & mood tracking\n   - Use when user expresses feelings\n   \n2. play_stress_game(user_id, game_type=\"random\")\n   - Fun mental break games (riddles, trivia, brain teasers, patterns, detective)\n   - Use when user says: \"stressed\", \"overwhelmed\", \"need a break\", \"game\", \"refresh\"\n   \n3. analyze_interpersonal(user_id, text=None, audio_path=None, relationship=\"colleague\")\n   - Text OR audio communication analysis with interpersonal coaching\n   - Use when user says: \"Analyze:\", \"you always\", \"you never\", or uploads audio\n   - Relationships: boss, colleague, partner, family, friend\n   **FILE HANDLING**: Audio files are handled automatically when uploaded\n   \n4. plan_meals(user_id, ingredients=None, image_path=None, days=3)\n   - Create meal plans from ingredients (text or image)\n   - Use when user says: \"meal plan\", \"recipe\", \"groceries\", or uploads food image\n   **FILE HANDLING**: Images are handled automatically when uploaded\n   \n5. plan_tasks(user_id, tasks_text)\n   - Organize & prioritize to-do lists\n   - Use when user says: \"tasks:\", \"to do\", \"organize\"\n   \n6. get_nutrition_advice(user_id, goal)\n   - Dietary guidance for specific goals (stress, energy, sleep, weight, focus)\n   - Use when user asks: \"what should I eat\", \"nutrition for\", \"food for\"\n   \n7. summarize_content(user_id, text=None, url=None, pdf_path=None, output_format=\"all\")\n   - Summarize PDF, URL, or text with quiz & key findings\n   - Use when user says: \"summarize\", or provides URL/file path\n   **FILE HANDLING**: Document paths are handled automatically when uploaded\n\nüéØ ROUTING LOGIC:\n- Emotional words ‚Üí analyze_mood\n- \"stressed\", \"break\", \"game\" ‚Üí play_stress_game\n- \"analyze:\", \"you always\" OR audio file ‚Üí analyze_interpersonal\n- \"meal plan:\", ingredients OR food image ‚Üí plan_meals\n- \"tasks:\" ‚Üí plan_tasks\n- \"what should I eat\" ‚Üí get_nutrition_advice\n- \"summarize\", URL/path OR document file ‚Üí summarize_content\n\nüíô ERROR HANDLING (CRITICAL):\n- If any tool returns status=\"error\", respond with empathy:\n  \"I'm sorry, I had trouble processing that [file/request]. [Suggest alternative]\"\n- NEVER show technical error details to users\n- Always offer alternatives (e.g., \"You can also try typing the information directly\")\n- Stay positive and supportive even when errors occur\n- Common issues: file format problems, file size limits, unclear audio\n\nüíô PERSONALITY:\n- Warm, empathetic, and supportive\n- Always use user's name when available\n- Celebrate progress with points/streaks\n- Provide encouragement\n- End responses mentioning earned points\n\nüö® URGENT PRIORITY:\nIf stress_level > 8 or user says \"overwhelmed\"/\"can't take it\", immediately offer play_stress_game.\n\nRemember: You're a supportive friend focused on wellness, not a therapist. Always encourage professional help for serious concerns. When things go wrong, reassure the user and help them find another way.\"\"\"\n\n# Create ADK Agent\nmindmate_agent = Agent(\n    name=\"mindmate\",\n    model=\"gemini-2.5-flash\",\n    description=\"MindMate AI - Your wellness companion with mood tracking, stress relief, meal planning, task organization, and more\",\n    instruction=SYSTEM_INSTRUCTION,\n    tools=ALL_TOOLS\n)\n\nprint(\"‚úÖ MindMate ADK Agent created\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# CELL 13: CREATE RUNNER & SESSION SERVICE\n# ============================================================================\n\nsession_service = InMemorySessionService()\nrunner = InMemoryRunner(agent=mindmate_agent, app_name=\"mindmate\")\n\nprint(\"‚úÖ ADK Runner ready\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# ============================================================================\n# CELL 14: TESTING FUNCTIONS\n# ============================================================================\n\nasync def test_agent(message: str, user_id: str = \"test_user\", user_name: str = \"Alex\"):\n    \"\"\"Quick test function for the agent.\"\"\"\n    print(f\"\\n{'='*60}\")\n    print(f\"üìù Input: {message}\")\n    print(f\"{'='*60}\")\n    \n    # Create session\n    session = await session_service.create_session(\n        app_name=\"mindmate\",\n        user_id=user_id\n    )\n    \n    # Run agent\n    response = await runner.run(\n        user_id=user_id,\n        session_id=session.id,\n        new_message=message\n    )\n    \n    # Extract response\n    if hasattr(response, 'content'):\n        result = response.content\n    elif isinstance(response, list) and response:\n        result = response[-1]\n    else:\n        result = response\n    \n    print(f\"\\nü§ñ Response:\\n{result}\")\n    print(f\"{'='*60}\\n\")\n    return result\n\n\nasync def run_all_tests():\n    \"\"\"Run comprehensive tests on all agents.\"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"üß™ RUNNING COMPREHENSIVE TESTS\")\n    print(\"=\"*70)\n    \n    tests = [\n        (\"Mood Agent\", \"I'm feeling really anxious about my presentation tomorrow\"),\n        (\"Stress Buster\", \"I need a mental break, give me a game\"),\n        (\"Interpersonal Coach\", \"Analyze: You always ignore my suggestions in meetings\"),\n        (\"Meal Planner\", \"Meal plan: chicken, rice, broccoli, eggs, spinach\"),\n        (\"Task Planner\", \"Tasks: finish quarterly report, call 3 clients, workout, review budget, send team update\"),\n        (\"Nutrition Advisor\", \"What should I eat to reduce my stress levels?\"),\n        (\"Summarizer\", \"Summarize: Meditation has been scientifically proven to reduce stress by up to 30%. Research shows regular practice improves focus, emotional regulation, and overall well-being. Studies with over 10000 participants demonstrate significant benefits.\")\n    ]\n    \n    results = {}\n    for name, message in tests:\n        print(f\"\\n[TEST] {name}\")\n        try:\n            result = await test_agent(message, f\"test_{name.lower().replace(' ', '_')}\")\n            results[name] = \"‚úÖ PASS\"\n        except Exception as e:\n            results[name] = f\"‚ùå FAIL: {e}\"\n            logger.error(f\"Test {name} failed: {e}\")\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"üìä TEST RESULTS\")\n    print(\"=\"*70)\n    for name, status in results.items():\n        print(f\"  {name}: {status}\")\n    \n    passed = sum(1 for s in results.values() if \"PASS\" in s)\n    print(f\"\\n‚úÖ {passed}/{len(results)} tests passed\")\n    return results\n\nprint(\"‚úÖ Test functions ready\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# CELL 15: DIRECT FUNCTION TESTS (Without ADK)\n# ============================================================================\n\ndef test_direct_functions():\n    \"\"\"Test all agent functions directly.\"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"üîß DIRECT FUNCTION TESTS\")\n    print(\"=\"*70)\n    \n    test_user = \"direct_test\"\n    \n    print(\"\\n[1] Mood Agent\")\n    result = analyze_mood(test_user, \"I'm feeling stressed about deadlines\", 7)\n    print(f\"   ‚úì Score: {result['mood_score']}/10, Emotion: {result['emotion']}, Assessment: {result['assessment']}\")\n    \n    print(\"\\n[2] Stress Buster\")\n    result = play_stress_game(test_user, \"riddle\")\n    print(f\"   ‚úì Game: {result['game_type']}, Streak: {result['stats']['streak']}, Total: {result['stats']['total_games']}\")\n    \n    print(\"\\n[3] Interpersonal Coach\")\n    result = analyze_interpersonal(test_user, \"You never listen to what I say!\", relationship=\"partner\")\n    print(f\"   ‚úì Style: {result['analysis']['style']}, Overall: {result['analysis']['scores']['overall']}\")\n    \n    print(\"\\n[4] Meal Planner\")\n    result = plan_meals(test_user, \"chicken, rice, broccoli, eggs\", days=3)\n    print(f\"   ‚úì Status: {result['status']}, Days: {result['days_planned']}, Recipes: {len(result['recipes'])}\")\n    \n    print(\"\\n[5] Task Planner\")\n    result = plan_tasks(test_user, \"finish report, call client, workout, send emails\")\n    print(f\"   ‚úì Tasks: {result['summary']['total_tasks']}, Time: {result['summary']['total_time']}\")\n    \n    print(\"\\n[6] Nutrition Advisor\")\n    result = get_nutrition_advice(test_user, \"I need more energy during the day\")\n    print(f\"   ‚úì Goal: {result['goal']}, Foods: {len(result['recommended_foods'])}\")\n    \n    print(\"\\n[7] Summarizer\")\n    result = summarize_content(test_user, text=\"Artificial intelligence is transforming healthcare through machine learning algorithms that can detect diseases earlier than human doctors. Recent studies show AI can identify certain cancers with 95% accuracy. This technology is revolutionizing medical diagnostics and treatment planning.\")\n    # FIX: word_count is now in metadata\n    print(f\"   ‚úì Status: {result['status']}, Word Count: {result.get('metadata', {}).get('word_count', 0)}, Quiz Questions: {len(result.get('quiz', []))}\")\n    \n    print(\"\\n‚úÖ All direct function tests complete!\")\n\n\ndef test_document_processing():\n    \"\"\"Test document processing with error handling.\"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"üìÑ DOCUMENT PROCESSING TEST\")\n    print(\"=\"*70)\n    \n    # Test 1: Text summarization\n    print(\"\\n[1] Text Summarization\")\n    test_text = \"\"\"\n    Artificial intelligence is revolutionizing healthcare. Machine learning algorithms \n    can now detect diseases earlier than human doctors. Recent studies show AI can \n    identify certain cancers with 95% accuracy. This technology is transforming medical \n    diagnostics and treatment planning. Doctors can now provide more personalized care.\n    \"\"\"\n    result = summarize_content(\"test_doc\", text=test_text)\n    print(f\"   ‚úì Status: {result.get('status')}\")\n    print(f\"   ‚úì Summary: {result.get('summary', 'N/A')[:100]}...\")\n    print(f\"   ‚úì Key Points: {len(result.get('key_points', []))}\")\n    print(f\"   ‚úì Quiz Questions: {len(result.get('quiz', []))}\")\n    print(f\"   ‚úì Reading Time: {result.get('metadata', {}).get('reading_time', 'N/A')}\")\n    print(f\"   ‚úì Sentiment: {result.get('metadata', {}).get('sentiment', 'N/A')}\")\n    print(f\"   ‚úì Difficulty: {result.get('metadata', {}).get('difficulty', 'N/A')}\")\n    \n    # Test 2: URL summarization\n    print(\"\\n[2] URL Summarization\")\n    try:\n        result = summarize_content(\"test_doc\", url=\"https://www.wikipedia.org\")\n        print(f\"   ‚úì Status: {result.get('status')}\")\n        print(f\"   ‚úì Word Count: {result.get('metadata', {}).get('word_count', 0)}\")\n    except Exception as e:\n        print(f\"   ‚ö†Ô∏è URL test skipped: {e}\")\n    \n    print(\"\\n‚úÖ Document processing tests complete!\")\n\n\n# Call both test functions\ntest_direct_functions()\ntest_document_processing()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# CELL 16: SIMPLE CHAT INTERFACE\n# ============================================================================\n\nasync def chat(message: str, user_name: str = \"Friend\", stress_level: int = 5):\n    \"\"\"\n    Simple chat interface for MindMate.\n    \n    Usage:\n        await chat(\"I need a break\")\n        await chat(\"Meal plan: chicken, rice, broccoli\", \"Sarah\")\n    \"\"\"\n    user_id = f\"chat_{user_name.lower().replace(' ', '_')}\"\n    user = get_user(user_id, user_name)\n    \n    print(f\"\\n{get_greeting(user_id)}\")\n    print(f\"üìù You: {message}\\n\")\n    \n    # Create session\n    session = await session_service.create_session(app_name=\"mindmate\", user_id=user_id)\n    \n    # Run through ADK\n    response = await runner.run(user_id=user_id, session_id=session.id, new_message=message)\n    \n    # Extract response\n    if hasattr(response, 'content'):\n        result = response.content\n    elif isinstance(response, list) and response:\n        result = response[-1]\n    else:\n        result = str(response)\n    \n    print(f\"ü§ñ MindMate:\\n{result}\\n\")\n    print(f\"{'‚îÄ'*40}\")\n    print(f\"üìä Your stats: {user.total_points} points | {len(user.badges)} badges\")\n    \n    if user.badges:\n        print(f\"üèÜ Badges: {', '.join(user.badges[-3:])}\")\n    \n    return result\n\nprint(\"‚úÖ Chat interface ready\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# ============================================================================\n# CELL 17: FILE UPLOAD WIDGETS\n# ============================================================================\n\ndef setup_image_upload():\n    \"\"\"Setup image upload widget for meal planning.\"\"\"\n    try:\n        from ipywidgets import FileUpload, Button, Output, VBox\n        from IPython.display import display\n        \n        upload = FileUpload(accept='image/*', multiple=False, description='Upload Food Image')\n        process_btn = Button(description='üì∏ Analyze Image', button_style='success')\n        output = Output()\n        \n        def process_image(btn):\n            with output:\n                output.clear_output()\n                if not upload.value:\n                    print(\"‚ö†Ô∏è Please upload an image first\")\n                    return\n                \n                file_info = list(upload.value.values())[0]\n                content = file_info['content']\n                \n                # Save temporarily\n                temp_path = \"/tmp/uploaded_food.jpg\"\n                with open(temp_path, 'wb') as f:\n                    f.write(content)\n                \n                print(\"üîÑ Analyzing image...\")\n                result = plan_meals(\"widget_user\", image_path=temp_path, days=3)\n                \n                if result.get('status') == 'complete':\n                    print(f\"\\n{result.get('image_analysis', '')}\")\n                    print(f\"\\nüìã MEAL PLANS:\")\n                    for plan in result.get('meal_plans', []):\n                        print(f\"\\n  {plan['day']}:\")\n                        for meal_type, dish in plan.get('meals', {}).items():\n                            print(f\"    ‚Ä¢ {meal_type}: {dish['dish']}\")\n                    print(f\"\\nüèÜ Points earned: {result['stats']['points_earned']}\")\n                else:\n                    print(result.get('message', 'Analysis failed'))\n        \n        process_btn.on_click(process_image)\n        display(VBox([upload, process_btn, output]))\n        return upload\n        \n    except ImportError:\n        print(\"‚ö†Ô∏è ipywidgets not available. Use direct function:\")\n        print(\"   plan_meals('user', image_path='/path/to/image.jpg')\")\n        return None\n\ndef setup_audio_upload():\n    \"\"\"Setup audio upload widget for communication analysis.\"\"\"\n    try:\n        from ipywidgets import FileUpload, Button, Output, VBox\n        from IPython.display import display\n        \n        upload = FileUpload(accept='audio/*', multiple=False, description='Upload Audio')\n        process_btn = Button(description='üé§ Analyze Audio', button_style='info')\n        output = Output()\n        \n        def process_audio(btn):\n            with output:\n                output.clear_output()\n                if not upload.value:\n                    print(\"‚ö†Ô∏è Please upload an audio file first\")\n                    return\n                \n                file_info = list(upload.value.values())[0]\n                content = file_info['content']\n                \n                # Save temporarily\n                temp_path = \"/tmp/uploaded_audio.wav\"\n                with open(temp_path, 'wb') as f:\n                    f.write(content)\n                \n                print(\"üîÑ Transcribing and analyzing...\")\n                result = analyze_interpersonal(\"widget_user\", audio_path=temp_path)\n                \n                if result.get('status') == 'analyzed':\n                    print(f\"\\nüìù Transcript: {result['original_message']}\")\n                    print(f\"\\nüé§ ANALYSIS:\")\n                    print(f\"   Style: {result['analysis']['style']}\")\n                    print(f\"   Overall Score: {result['analysis']['scores']['overall']}\")\n                    if result.get('coaching'):\n                        print(f\"\\nüí° COACHING:\")\n                        for tip in result['coaching'][:3]:\n                            print(f\"   {tip}\")\n                else:\n                    print(result.get('message', 'Analysis failed'))\n        \n        process_btn.on_click(process_audio)\n        display(VBox([upload, process_btn, output]))\n        return upload\n        \n    except ImportError:\n        print(\"‚ö†Ô∏è ipywidgets not available. Use direct function:\")\n        print(\"   analyze_interpersonal('user', audio_path='/path/to/audio.wav')\")\n        return None\n\ndef setup_document_upload():\n    \"\"\"Setup document upload widget for summarization (PDF only).\"\"\"\n    try:\n        from ipywidgets import FileUpload, Dropdown, Button, Output, VBox, HBox\n        from IPython.display import display\n        \n        upload = FileUpload(accept='.pdf,.txt', multiple=False, description='Upload Document')\n        format_dropdown = Dropdown(options=['all', 'summary', 'quiz', 'findings'], value='all', description='Output:')\n        process_btn = Button(description='üìÑ Summarize', button_style='primary')\n        output = Output()\n        \n        def process_doc(btn):\n            with output:\n                output.clear_output()\n                if not upload.value:\n                    print(\"‚ö†Ô∏è Please upload a document first\")\n                    return\n                \n                import os\n                file_info = list(upload.value.values())[0]\n                filename = file_info['metadata']['name']\n                content = file_info['content']\n                ext = os.path.splitext(filename)[1].lower()\n                \n                # Save temporarily\n                temp_path = f\"/tmp/upload_{filename}\"\n                with open(temp_path, 'wb') as f:\n                    f.write(content)\n                \n                print(f\"üîÑ Processing {filename}...\")\n                \n                # Call appropriate summarizer\n                kwargs = {\"user_id\": \"widget_user\", \"output_format\": format_dropdown.value}\n                if ext == '.pdf':\n                    kwargs[\"pdf_path\"] = temp_path\n                elif ext == '.txt':\n                    with open(temp_path, 'r') as f:\n                        kwargs[\"text\"] = f.read()\n                else:\n                    print(f\"‚ùå Unsupported file type: {ext}. Supported: PDF, TXT\")\n                    return\n                \n                result = summarize_content(**kwargs)\n                \n                if result.get('status') == 'complete':\n                    print(f\"\\nüìä SUMMARY RESULTS\")\n                    print(f\"   Source: {result['source_type'].upper()}\")\n                    print(f\"   Words: {result['metadata']['word_count']}\")\n                    if result.get('summary'):\n                        print(f\"\\nüìã SUMMARY:\\n   {result['summary']}\")\n                    if result.get('key_points'):\n                        print(f\"\\nüîë KEY POINTS:\")\n                        for i, pt in enumerate(result['key_points'][:5], 1):\n                            print(f\"   {i}. {pt}\")\n                    if result.get('quiz'):\n                        print(f\"\\n‚ùì QUIZ: {len(result['quiz'])} questions generated\")\n                else:\n                    print(result.get('message', 'Processing failed'))\n        \n        process_btn.on_click(process_doc)\n        display(VBox([HBox([upload, format_dropdown]), process_btn, output]))\n        return upload\n        \n    except ImportError:\n        print(\"‚ö†Ô∏è ipywidgets not available. Use direct functions instead.\")\n        return None\n\nprint(\"File upload widgets ready\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# ============================================================================\n# CELL 19: SYSTEM STATUS & METRICS\n# ============================================================================\n\ndef get_system_status():\n    \"\"\"Get complete system status.\"\"\"\n    return {\n        \"status\": \"üü¢ OPERATIONAL\",\n        \"version\": \"1.0 Final\",\n        \"agents\": {\n            \"1\": \"Mood Agent - Emotional support\",\n            \"2\": \"Stress Buster - Fun games\",\n            \"3\": \"Interpersonal Coach - Text + Audio analysis\",\n            \"4\": \"Meal Planner - Recipes + Image detection\",\n            \"5\": \"Task Planner - Organization\",\n            \"6\": \"Nutrition Advisor - Dietary guidance\",\n            \"7\": \"Summarizer - Text/URL/PDF only\"\n        },\n        \"features\": {\n            \"mood_tracking\": \"‚úÖ Emotion history & trends\",\n            \"stress_relief\": \"‚úÖ Immediate game triggers\",\n            \"communication_coaching\": \"‚úÖ Text + Audio file analysis\",\n            \"meal_planning\": \"‚úÖ Text ingredients + Image detection\",\n            \"task_management\": \"‚úÖ Priority & time estimates\",\n            \"nutrition_guidance\": \"‚úÖ Goal-based advice\",\n            \"content_summarization\": \"‚úÖ Text, URL, PDF\"\n        },\n        \"metrics\": {\n            \"total_users\": len(user_journeys),\n            \"total_requests\": metrics.get(\"total_requests\", 0),\n            \"mood_analyses\": metrics.get(\"mood_analyses\", 0),\n            \"games_played\": metrics.get(\"games_played\", 0),\n            \"communication_analyses\": metrics.get(\"communication_analyses\", 0),\n            \"meal_plans\": metrics.get(\"meal_plans\", 0),\n            \"tasks_planned\": metrics.get(\"tasks_planned\", 0),\n            \"nutrition_advice\": metrics.get(\"nutrition_advice\", 0),\n            \"summaries\": metrics.get(\"summaries\", 0)\n        },\n        \"gamification\": {\n            \"total_points_awarded\": sum(u.total_points for u in user_journeys.values()),\n            \"total_badges\": sum(len(u.badges) for u in user_journeys.values())\n        }\n    }\n\ndef display_status():\n    \"\"\"Display system status in formatted output.\"\"\"\n    status = get_system_status()\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"üìä MINDMATE AI - SYSTEM STATUS\")\n    print(\"=\"*70)\n    print(f\"\\nüü¢ Status: {status['status']}\")\n    print(f\"üì¶ Version: {status['version']}\")\n    print(f\"üë• Total Users: {status['metrics']['total_users']}\")\n    \n    print(f\"\\nü§ñ AGENTS ({len(status['agents'])}):\")\n    for num, desc in status['agents'].items():\n        print(f\"   {num}. {desc}\")\n    \n    print(f\"\\nüìà USAGE METRICS:\")\n    for metric, count in status['metrics'].items():\n        if metric != 'total_users':\n            print(f\"   {metric.replace('_', ' ').title()}: {count}\")\n    \n    print(f\"\\nüéÆ GAMIFICATION:\")\n    print(f\"   Total Points Awarded: {status['gamification']['total_points_awarded']}\")\n    print(f\"   Total Badges Earned: {status['gamification']['total_badges']}\")\n    \n    print(\"\\n\" + \"=\"*70)\n\ndisplay_status()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":" analyze_interpersonal(\"user1\", \"You never listen to me\", relationship=\"partner\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":" play_stress_game(\"user1\", \"brain teaser\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plan_meals(\"user1\", \"chicken, cheese, mushroom\", days=5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nDEPLOYMENT UTILITIES\n- Generate ADK Web UI URL for Kaggle\n- Export deployment configuration\n\"\"\"\ndef get_adk_proxy_url():\n    \"\"\"Generate ADK Web UI URL for Kaggle\"\"\"\n    try:\n        from IPython.core.display import display, HTML\n        from jupyter_server.serverapp import list_running_servers\n        \n        PROXY_HOST = \"https://kkb-production.jupyter-proxy.kaggle.net\"\n        ADK_PORT = \"8000\"\n        \n        servers = list(list_running_servers())\n        if not servers:\n            print(\"‚ö†Ô∏è No Jupyter servers found\")\n            return None\n        \n        baseURL = servers[0]['base_url']\n        path_parts = baseURL.split('/')\n        kernel = path_parts[2]\n        token = path_parts[3]\n        \n        url_prefix = f\"/k/{kernel}/{token}/proxy/proxy/{ADK_PORT}\"\n        url = f\"{PROXY_HOST}{url_prefix}\"\n        \n        html = f\"\"\"\n        <div style=\"padding: 25px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); \n                    border-radius: 15px; box-shadow: 0 10px 25px rgba(0,0,0,0.2); margin: 25px 0;\">\n            <div style=\"color: white; font-size: 1.5em; font-weight: bold; margin-bottom: 15px;\">\n                üß† Mindmate AI - Launch Web Interface\n            </div>\n            <div style=\"color: #f0f0f0; margin-bottom: 20px; line-height: 1.8; font-size: 1.1em;\">\n                ‚úÖ All 11 requirements met<br>\n                ‚úÖ Personal & non-generic<br>\n                ‚úÖ Stable & crash-proof<br>\n                ‚úÖ Clean observability\n            </div>\n            <a href='{url}' target='_blank' style=\"\n                display: inline-block; background: white; color: #667eea; \n                padding: 15px 35px; text-decoration: none; border-radius: 30px; \n                font-weight: bold; font-size: 1.1em;\n                box-shadow: 0 5px 15px rgba(0,0,0,0.3);\">\n                Launch Web UI ‚Üó\n            </a>\n        </div>\n        \"\"\"\n        display(HTML(html))\n        return url_prefix\n        \n    except Exception as e:\n        logger.error(f\"URL generation error: {e}\")\n        print(\"‚ö†Ô∏è Run in Kaggle notebook for Web UI access\")\n        return None\n\nprint(\"‚úÖ Deployment utilities ready\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nDEPLOYMENT STEP 1: Create ADK Project\nRun this cell to create the ADK project structure\n\"\"\"\n\n!adk create mindmateAI --model gemini-2.5-flash --api_key $GOOGLE_API_KEY\n\nprint(\"\\n‚úÖ ADK project created\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nDEPLOYMENT STEP 2: Launch ADK Web UI\nRun this cell to start the web interface\n\"\"\"\nurl_prefix = get_adk_proxy_url()\n\n# Launch web server\n!adk web --url_prefix {url_prefix}","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}